{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9e2b2-e35f-49a5-8e0e-e1b376b12d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#######################################################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# for visualizing the representation\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cate_models import *\n",
    "\n",
    "#######################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22a7866-b00f-4c23-8407-59845a41ee28",
   "metadata": {},
   "source": [
    "### 2.3 Counterfactual Inference and Domain Adaptation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1992a425-9741-4585-8a73-2699d9f1aef0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TARNet or CFRMMD depending on alpha ##\n",
    "class TARNet(nn.Module):\n",
    "    def __init__(self, df, covariate_cols=['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10',\n",
    "                                           'X11','X12','X13','X14','X15','X16','X17','X18','X19','X20',\n",
    "                                           'X21','X22','X23','X24','X25'],\n",
    "                                           treatment_col='T', label_col='Y', ite_label='ITE',alpha=0, lambda_=0,beta=1,\n",
    "                                           weight_decay=0.01,\n",
    "                                           lr=0.001, verbose=False, target_reg=False):\n",
    "        super(TARNet, self).__init__() \n",
    "        \n",
    "        # Data parameters\n",
    "        self.df = df\n",
    "        self.covariate_cols = covariate_cols\n",
    "        self.treatment_col = treatment_col\n",
    "        self.label_col = label_col\n",
    "        self.ite_label = ite_label\n",
    "        self.lr = lr\n",
    "        self.df, self.test_df = train_test_split(self.df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Loss hyperparameters\n",
    "        self.lambda_ = lambda_\n",
    "        self.alpha = alpha\n",
    "        self.target_reg = target_reg\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.u = max(1e-6, min(1 - 1e-6, sum(self.df[self.treatment_col].values) / len(self.df[self.treatment_col].values)))\n",
    "        print(f'u: {self.u}')\n",
    "        self.input_dim = len(covariate_cols)\n",
    "        self.output_dim = 1 # for each arm we predict a single value, Y_hat\n",
    "        self.hidden_dim = 200\n",
    "        \n",
    "        # Device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        self.to(self.device)\n",
    "\n",
    "        # Layers:\n",
    "        # \"CFR is implemented as a feed-forward\n",
    "        # neural network with 3 fully-connected exponential-linear\n",
    "        # layers for the representation and 3 for the hypothesis. Layer\n",
    "        # sizes were 200 for all layers used for Jobs and 200 and 100\n",
    "        # for the representation and hypothesis used for IHDP.\"\"\n",
    "        \n",
    "        self.representation_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            #nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.control_arm = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        )\n",
    "        self.treatment_arm = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            #nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.epsilon = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "        # The model is trained using Adam's (Kingma & Ba, 2014). \n",
    "        # self.optimizer = optim.Adam(\n",
    "        #                        list(self.representation_layers.parameters())+\n",
    "        #                        list(self.control_arm.parameters())+\n",
    "        #                        list(self.treatment_arm.parameters()), lr=self.lr)\n",
    "        self.optimizer_representation = optim.Adam(list(self.representation_layers.parameters()) + [self.epsilon], lr=lr, weight_decay=weight_decay)\n",
    "        self.optimizer_control = optim.Adam(list(self.control_arm.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "        self.optimizer_treatment = optim.Adam(list(self.treatment_arm.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "        # For continuous data we use mean squared loss and for binary data, we'd use log-loss.\n",
    "        self.prediction_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, X, t):\n",
    "\n",
    "        representation = self.representation_layers(X)\n",
    "        control_out = self.control_arm(representation)\n",
    "        treatment_out = self.treatment_arm(representation)\n",
    "        y_pred = t * treatment_out + (1 - t) * control_out\n",
    "        \n",
    "        return y_pred, representation, control_out, treatment_out\n",
    "        \n",
    "    def fit(self, epochs=10, batch_size=64):\n",
    "        # Set to training mode\n",
    "        self.representation_layers.train()\n",
    "        self.treatment_arm.train()\n",
    "        self.control_arm.train()\n",
    "\n",
    "        # Get data\n",
    "        losses = []\n",
    "        val_losses = []\n",
    "        print('data:')\n",
    "        \n",
    "        X = torch.tensor(self.df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.df[self.label_col].values, dtype=torch.float32)\n",
    "        t = torch.tensor(self.df[self.treatment_col].values, dtype=torch.float32)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "        \n",
    "        print(f'data shapes: {X.shape}, {y.shape}, {t.shape}')\n",
    "        \n",
    "        print('starting training')\n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses = []\n",
    "\n",
    "            # Shuffle data\n",
    "            indices = torch.randperm(len(X))\n",
    "            X = X[indices]\n",
    "            y = y[indices]\n",
    "            t = t[indices]\n",
    "\n",
    "            batch_size = 64\n",
    "            # Batch data\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                X_batch = X[i:i + batch_size]\n",
    "                y_batch = y[i:i + batch_size]\n",
    "                t_batch = t[i:i + batch_size]\n",
    "\n",
    "               \n",
    "                # Zero gradients\n",
    "                #self.optimizer.zero_grad()\n",
    "                self.optimizer_representation.zero_grad()\n",
    "                self.optimizer_control.zero_grad()\n",
    "                self.optimizer_treatment.zero_grad()\n",
    "\n",
    "                y_pred, representation, _, _ = self.forward(X_batch, t_batch)\n",
    "                \n",
    "\n",
    "                # Calculate weights\n",
    "                weights = (t_batch / (2 * self.u)) + ((1 - t_batch) / (2 * (1 - self.u)))\n",
    "                # print(weights)\n",
    "                \n",
    "                # Calculate prediction loss\n",
    "                loss_pred = torch.mean(weights * self.prediction_loss(y_pred, y_batch))\n",
    "                #print(f'loss_prediction: {loss}')\n",
    "                #loss = loss_pred.clone()\n",
    "                \n",
    "                control_condition = (t_batch==0)\n",
    "                \n",
    "                representation_control = representation[control_condition]\n",
    "                representation_treatment = representation[~control_condition]\n",
    "\n",
    "                #loss_pred = loss_y0 + loss_y1  # Prediction loss\n",
    "\n",
    "                # Squared Linear MMD = IPM loss example -- idk what they even use in the paper\n",
    "                loss_ipm = self.alpha * torch.norm(representation_control.mean() - representation_treatment.mean(), p=2) ** 2 \n",
    "                #loss = loss.clone() + loss_ipm\n",
    "                \n",
    "                # Regularizing loss\n",
    "                # Ignore regularization for now\n",
    "                #regularizing_term = self.lambda_ * torch.norm(self.weights, p=2) \n",
    "                #loss += regularizing_term\n",
    "                \n",
    "                if self.target_reg:\n",
    "                    target = y_batch - y_pred + self.epsilon*(t_batch/ self.u + (1-t_batch)/(1-self.u))\n",
    "                    loss_target = self.beta * torch.mean(target)\n",
    "                    loss_pred += loss_target\n",
    "\n",
    "                # Backpropagate **only** prediction loss (updates all optimizers)\n",
    "                loss_pred.backward(retain_graph=True)\n",
    "                #self.optimizer_representation.step()\n",
    "                self.optimizer_control.step()\n",
    "                self.optimizer_treatment.step()\n",
    "\n",
    "                # Backpropagate **only** IPM loss (updates only representation layers)\n",
    "                #self.optimizer_representation.zero_grad()  # Zero out before IPM step\n",
    "                #loss = loss_pred.clone() + loss_ipm\n",
    "                loss_ipm.backward()\n",
    "                self.optimizer_representation.step()\n",
    "                \n",
    "                # Backpropagate both prediction loss (through all layers) and IPM loss (through representation layers)\n",
    "                # loss.backward()  \n",
    "                # self.optimizer.step()\n",
    "                \n",
    "                loss = loss_pred + loss_ipm\n",
    "                \n",
    "                epoch_losses.append(loss.item())\n",
    "            \n",
    "            avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            \n",
    "            losses.append(avg_loss)\n",
    "\n",
    "            if epoch % 10 == 0 and self.verbose:\n",
    "                print('')\n",
    "                print(f'Epoch: {epoch}, Loss: {loss_pred.item()}')\n",
    "                \n",
    "            \n",
    "            # Calculate test set loss\n",
    "            test_X = torch.tensor(self.test_df[self.covariate_cols].astype(float).values, dtype=torch.float32).to(self.device)\n",
    "            test_y = torch.tensor(self.test_df[self.label_col].values, dtype=torch.float32).to(self.device)\n",
    "            test_t = torch.tensor(self.test_df[self.treatment_col].values, dtype=torch.float32).to(self.device)\n",
    "\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                test_y_pred, _, _, _ = self.forward(test_X, test_t)\n",
    "                test_loss = self.prediction_loss(test_y_pred, test_y).item()\n",
    "                val_losses.append(test_loss)\n",
    "                print(f'Test set loss: {test_loss}')\n",
    "                \n",
    "        print('done training')\n",
    "        \n",
    "\n",
    "        return losses, val_losses\n",
    "        \n",
    "           \n",
    "    def predict_train(self, use_ite=False):\n",
    "        X = torch.tensor(self.df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.df[self.label_col].values, dtype=torch.float32)\n",
    "        t = torch.tensor(self.df[self.treatment_col].values, dtype=torch.float32)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "        if use_ite:\n",
    "            ite = torch.tensor(self.df[self.ite_label].astype(float).values, dtype=torch.float32)\n",
    "        else:\n",
    "            ite = None\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # No gradients needed for prediction\n",
    "            return self.forward(X,t), X, y, t, ite\n",
    "    \n",
    "    def predict_test(self, use_ite=False):\n",
    "        X = torch.tensor(self.test_df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.test_df[self.label_col].values, dtype=torch.float32)\n",
    "        t = torch.tensor(self.test_df[self.treatment_col].values, dtype=torch.float32)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "        if use_ite:\n",
    "            ite = torch.tensor(self.test_df[self.ite_label].astype(float).values, dtype=torch.float32)\n",
    "        else:\n",
    "            ite = None\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # No gradients needed for prediction\n",
    "            return self.forward(X,t), X, y, t, ite\n",
    "    \n",
    "    # plot the t-sne\n",
    "    def plot_representation_space(self, representation=None, t=None, n_components=2):\n",
    "        \"\"\"Plot the representation space\"\"\"\n",
    "        \n",
    "        if representation is None:\n",
    "            representation = torch.tensor(self.df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "            t = torch.tensor(self.df[self.treatment_col].values, dtype=torch.float32)\n",
    "        # Index on what is control versus treatment\n",
    "        representation_control = representation[t == 0]\n",
    "        representation_treatment = representation[t == 1]\n",
    "\n",
    "        # Run separate t-SNE on control and treatment representations\n",
    "        tsne_control = TSNE(n_components=n_components, random_state=42)\n",
    "        X_tsne_control = tsne_control.fit_transform(representation_control.detach().numpy())\n",
    "        \n",
    "        tsne_treatment = TSNE(n_components=n_components, random_state=42)\n",
    "        X_tsne_treatment = tsne_treatment.fit_transform(representation_treatment.detach().numpy())\n",
    "\n",
    "        # Plot t-SNE\n",
    "        plt.scatter(X_tsne_control[:, 0], X_tsne_control[:, 1], color='blue', label='Control')\n",
    "        plt.scatter(X_tsne_treatment[:, 0], X_tsne_treatment[:, 1], color='red', label='Treatment')\n",
    "        plt.title(\"t-SNE Visualization\")\n",
    "        plt.xlabel(\"Dimension 1\")\n",
    "        plt.ylabel(\"Dimension 2\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def compute_PEHE_ATE_metrics(self, control_output, treatment_output, t, ite=None):\n",
    "        \"\"\"Compute comparison metrics\"\"\"\n",
    "        ite_pred = treatment_output - control_output \n",
    "        if ite is not None:\n",
    "            ite_true = ite \n",
    "        else:\n",
    "            ite_true = torch.where(t == 1, y, -y)\n",
    "        #print(ite_pred, ite_true)\n",
    "        pehe = torch.mean((ite_pred - ite_true) ** 2)\n",
    "        #print(pehe)\n",
    "    \n",
    "        ate_pred = torch.mean(ite_pred)  \n",
    "        ate_true = torch.mean(ite_true)  \n",
    "        ate_error = torch.abs(ate_pred - ate_true)\n",
    "        \n",
    "        return pehe.item(), ate_error.item(), ite_pred, ate_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "25b1fe47-d24d-4059-b099-5b64c5c004bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IHDP_data = pd.read_csv(\"ihdp_project2.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d188b5b-a12d-460e-b898-e1044b6e541c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>...</th>\n",
       "      <th>X24</th>\n",
       "      <th>X25</th>\n",
       "      <th>T</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y_cf</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y0</th>\n",
       "      <th>ITE</th>\n",
       "      <th>ps</th>\n",
       "      <th>CATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.316588</td>\n",
       "      <td>0.596582</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.371086</td>\n",
       "      <td>-1.189018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.221720</td>\n",
       "      <td>6.221720</td>\n",
       "      <td>6.221720</td>\n",
       "      <td>1.938568</td>\n",
       "      <td>4.283151</td>\n",
       "      <td>0.096134</td>\n",
       "      <td>4.651689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.186891</td>\n",
       "      <td>0.196818</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>0.161703</td>\n",
       "      <td>-1.379396</td>\n",
       "      <td>0.467138</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.899687</td>\n",
       "      <td>5.741144</td>\n",
       "      <td>5.741144</td>\n",
       "      <td>3.899687</td>\n",
       "      <td>1.841458</td>\n",
       "      <td>0.346382</td>\n",
       "      <td>4.029681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.532750</td>\n",
       "      <td>0.196818</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>1.934016</td>\n",
       "      <td>-1.354634</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.405894</td>\n",
       "      <td>6.709281</td>\n",
       "      <td>6.709281</td>\n",
       "      <td>2.405894</td>\n",
       "      <td>4.303386</td>\n",
       "      <td>0.071968</td>\n",
       "      <td>4.644078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.294972</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.121017</td>\n",
       "      <td>-1.023402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.469327</td>\n",
       "      <td>6.868562</td>\n",
       "      <td>6.868562</td>\n",
       "      <td>1.469327</td>\n",
       "      <td>5.399234</td>\n",
       "      <td>0.294487</td>\n",
       "      <td>4.635409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.548057</td>\n",
       "      <td>-0.202946</td>\n",
       "      <td>-0.360898</td>\n",
       "      <td>-0.879606</td>\n",
       "      <td>0.183534</td>\n",
       "      <td>-0.360940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.558776</td>\n",
       "      <td>6.471721</td>\n",
       "      <td>6.471721</td>\n",
       "      <td>0.558776</td>\n",
       "      <td>5.912945</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>4.509761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        X1        X2        X3        X4        X5        X6   \n",
       "0           0  0.316588  0.596582 -0.360898 -0.879606  0.371086 -1.189018  \\\n",
       "1           1  0.186891  0.196818 -0.360898  0.161703 -1.379396  0.467138   \n",
       "2           2  0.532750  0.196818 -0.360898 -0.879606  1.934016 -1.354634   \n",
       "3           3  0.294972 -0.202946 -0.360898 -0.879606  0.121017 -1.023402   \n",
       "4           4 -0.548057 -0.202946 -0.360898 -0.879606  0.183534 -0.360940   \n",
       "\n",
       "    X7   X8   X9  ...  X24  X25  T         Y      Y_cf        Y1        Y0   \n",
       "0  1.0  0.0  1.0  ...  0.0  0.0  1  6.221720  6.221720  6.221720  1.938568  \\\n",
       "1  0.0  0.0  1.0  ...  0.0  1.0  0  3.899687  5.741144  5.741144  3.899687   \n",
       "2  0.0  0.0  0.0  ...  0.0  0.0  0  2.405894  6.709281  6.709281  2.405894   \n",
       "3  0.0  0.0  1.0  ...  0.0  1.0  0  1.469327  6.868562  6.868562  1.469327   \n",
       "4  0.0  1.0  0.0  ...  0.0  0.0  0  0.558776  6.471721  6.471721  0.558776   \n",
       "\n",
       "        ITE        ps      CATE  \n",
       "0  4.283151  0.096134  4.651689  \n",
       "1  1.841458  0.346382  4.029681  \n",
       "2  4.303386  0.071968  4.644078  \n",
       "3  5.399234  0.294487  4.635409  \n",
       "4  5.912945  0.138918  4.509761  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IHDP_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c479b456-800b-4f01-a69f-281aa95b5088",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21.16135528087616,\n",
       " 4.945757460594177,\n",
       " 3.415143835544586,\n",
       " 3.144415283203125,\n",
       " 3.029424047470093,\n",
       " 2.930993342399597,\n",
       " 2.9251203775405883,\n",
       " 3.014260697364807,\n",
       " 2.9409242153167723,\n",
       " 2.8844500303268434,\n",
       " 2.818005323410034,\n",
       " 2.8120114326477053,\n",
       " 2.7839060068130492,\n",
       " 2.833407688140869,\n",
       " 2.7490846633911135,\n",
       " 2.6919788837432863,\n",
       " 2.718809390068054,\n",
       " 2.706429672241211,\n",
       " 2.702699971199036,\n",
       " 2.7133095264434814]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tarnet_model = TARNet(df=IHDP_data, alpha = 1, target_reg=True)\n",
    "tarnet_model.fit(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "83850322-26ee-4420-abcb-6cb27a741433",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4435852766036987\n",
      "Alpha: 0.0, LR: 0.0001, WD: 0, PEHE: 1.6023746571194155, ATE: 0.26496315002441406, test loss 1.4435852766036987\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3012627363204956\n",
      "Alpha: 0.0, LR: 0.001, WD: 0, PEHE: 1.614505921835862, ATE: 0.4429154396057129, test loss 1.3012627363204956\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2749632596969604\n",
      "Alpha: 0.0, LR: 0.01, WD: 0, PEHE: 1.670854060677874, ATE: 0.622016429901123, test loss 1.2749632596969604\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4123042821884155\n",
      "Alpha: 0.0, LR: 0.0001, WD: 1e-05, PEHE: 1.637635841267938, ATE: 0.4250450134277344, test loss 1.4123042821884155\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3239058256149292\n",
      "Alpha: 0.0, LR: 0.001, WD: 1e-05, PEHE: 1.6392239355656677, ATE: 0.5208702087402344, test loss 1.3239058256149292\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2736093997955322\n",
      "Alpha: 0.0, LR: 0.01, WD: 1e-05, PEHE: 1.654248810016953, ATE: 0.5762553215026855, test loss 1.2736093997955322\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4414196014404297\n",
      "Alpha: 0.0, LR: 0.0001, WD: 0.0001, PEHE: 1.584327820445996, ATE: 0.1777973175048828, test loss 1.4414196014404297\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.31083083152771\n",
      "Alpha: 0.0, LR: 0.001, WD: 0.0001, PEHE: 1.648704326422156, ATE: 0.5535202026367188, test loss 1.31083083152771\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3034411668777466\n",
      "Alpha: 0.0, LR: 0.01, WD: 0.0001, PEHE: 1.8329537677876115, ATE: 0.9749860763549805, test loss 1.3034411668777466\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4187871217727661\n",
      "Alpha: 0.0, LR: 0.0001, WD: 0.001, PEHE: 1.5820168576939861, ATE: 0.2088150978088379, test loss 1.4187871217727661\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3097691535949707\n",
      "Alpha: 0.0, LR: 0.001, WD: 0.001, PEHE: 1.5960282142841384, ATE: 0.36732006072998047, test loss 1.3097691535949707\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.399922251701355\n",
      "Alpha: 0.0, LR: 0.01, WD: 0.001, PEHE: 1.5502689774226306, ATE: 0.0002498626708984375, test loss 1.399922251701355\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4478814601898193\n",
      "Alpha: 0.0, LR: 0.0001, WD: 0.01, PEHE: 1.5957463794388085, ATE: 0.23172760009765625, test loss 1.4478814601898193\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3359383344650269\n",
      "Alpha: 0.0, LR: 0.001, WD: 0.01, PEHE: 1.5785082361189509, ATE: 0.28433656692504883, test loss 1.3359383344650269\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.326275110244751\n",
      "Alpha: 0.0, LR: 0.01, WD: 0.01, PEHE: 1.6312574802972573, ATE: 0.5067586898803711, test loss 1.326275110244751\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4210028648376465\n",
      "Alpha: 11.11111111111111, LR: 0.0001, WD: 0, PEHE: 1.5992540796325372, ATE: 0.278475284576416, test loss 1.4210028648376465\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3782130479812622\n",
      "Alpha: 11.11111111111111, LR: 0.001, WD: 0, PEHE: 1.557209365694272, ATE: 0.11638832092285156, test loss 1.3782130479812622\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.5032076835632324\n",
      "Alpha: 11.11111111111111, LR: 0.01, WD: 0, PEHE: 1.5678893414638055, ATE: 0.1888442039489746, test loss 1.5032076835632324\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4413180351257324\n",
      "Alpha: 11.11111111111111, LR: 0.0001, WD: 1e-05, PEHE: 1.5936601650874314, ATE: 0.23263025283813477, test loss 1.4413180351257324\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3125320672988892\n",
      "Alpha: 11.11111111111111, LR: 0.001, WD: 1e-05, PEHE: 1.6030886194216962, ATE: 0.39449024200439453, test loss 1.3125320672988892\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.272498607635498\n",
      "Alpha: 11.11111111111111, LR: 0.01, WD: 1e-05, PEHE: 1.7124765519813157, ATE: 0.7263393402099609, test loss 1.272498607635498\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4378873109817505\n",
      "Alpha: 11.11111111111111, LR: 0.0001, WD: 0.0001, PEHE: 1.5875784366484027, ATE: 0.2048201560974121, test loss 1.4378873109817505\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.293360948562622\n",
      "Alpha: 11.11111111111111, LR: 0.001, WD: 0.0001, PEHE: 1.6638419851415505, ATE: 0.5925383567810059, test loss 1.293360948562622\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.398114800453186\n",
      "Alpha: 11.11111111111111, LR: 0.01, WD: 0.0001, PEHE: 1.5529969958972063, ATE: 0.0342864990234375, test loss 1.398114800453186\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4226281642913818\n",
      "Alpha: 11.11111111111111, LR: 0.0001, WD: 0.001, PEHE: 1.5901212332949075, ATE: 0.22836828231811523, test loss 1.4226281642913818\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3000328540802002\n",
      "Alpha: 11.11111111111111, LR: 0.001, WD: 0.001, PEHE: 1.6528990333308282, ATE: 0.5637407302856445, test loss 1.3000328540802002\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3143012523651123\n",
      "Alpha: 11.11111111111111, LR: 0.01, WD: 0.001, PEHE: 1.6030925606165267, ATE: 0.40608882904052734, test loss 1.3143012523651123\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4171913862228394\n",
      "Alpha: 11.11111111111111, LR: 0.0001, WD: 0.01, PEHE: 1.595711790922766, ATE: 0.2692451477050781, test loss 1.4171913862228394\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3055918216705322\n",
      "Alpha: 11.11111111111111, LR: 0.001, WD: 0.01, PEHE: 1.6206130452566567, ATE: 0.4590282440185547, test loss 1.3055918216705322\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3062533140182495\n",
      "Alpha: 11.11111111111111, LR: 0.01, WD: 0.01, PEHE: 1.6849835317469133, ATE: 0.6563143730163574, test loss 1.3062533140182495\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4183777570724487\n",
      "Alpha: 22.22222222222222, LR: 0.0001, WD: 0, PEHE: 1.5934010291914873, ATE: 0.25115251541137695, test loss 1.4183777570724487\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.331774115562439\n",
      "Alpha: 22.22222222222222, LR: 0.001, WD: 0, PEHE: 1.5889047760083956, ATE: 0.3361802101135254, test loss 1.331774115562439\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4228976964950562\n",
      "Alpha: 22.22222222222222, LR: 0.01, WD: 0, PEHE: 1.7619695040935621, ATE: 0.804175853729248, test loss 1.4228976964950562\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4081058502197266\n",
      "Alpha: 22.22222222222222, LR: 0.0001, WD: 1e-05, PEHE: 1.5828036459612074, ATE: 0.22100162506103516, test loss 1.4081058502197266\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.334883689880371\n",
      "Alpha: 22.22222222222222, LR: 0.001, WD: 1e-05, PEHE: 1.6194108799589042, ATE: 0.4576683044433594, test loss 1.334883689880371\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3170692920684814\n",
      "Alpha: 22.22222222222222, LR: 0.01, WD: 1e-05, PEHE: 1.7822220810089204, ATE: 0.8789820671081543, test loss 1.3170692920684814\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4334009885787964\n",
      "Alpha: 22.22222222222222, LR: 0.0001, WD: 0.0001, PEHE: 1.5910790445531722, ATE: 0.23400115966796875, test loss 1.4334009885787964\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3005352020263672\n",
      "Alpha: 22.22222222222222, LR: 0.001, WD: 0.0001, PEHE: 1.632650705014689, ATE: 0.5023994445800781, test loss 1.3005352020263672\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2896029949188232\n",
      "Alpha: 22.22222222222222, LR: 0.01, WD: 0.0001, PEHE: 1.76720931278329, ATE: 0.8487210273742676, test loss 1.2896029949188232\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4451855421066284\n",
      "Alpha: 22.22222222222222, LR: 0.0001, WD: 0.001, PEHE: 1.601651817250295, ATE: 0.25603580474853516, test loss 1.4451855421066284\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3217501640319824\n",
      "Alpha: 22.22222222222222, LR: 0.001, WD: 0.001, PEHE: 1.6156161870660717, ATE: 0.44140100479125977, test loss 1.3217501640319824\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.271868109703064\n",
      "Alpha: 22.22222222222222, LR: 0.01, WD: 0.001, PEHE: 1.6820735573486503, ATE: 0.6521921157836914, test loss 1.271868109703064\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4230822324752808\n",
      "Alpha: 22.22222222222222, LR: 0.0001, WD: 0.01, PEHE: 1.5783323397259, ATE: 0.18871164321899414, test loss 1.4230822324752808\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.337394118309021\n",
      "Alpha: 22.22222222222222, LR: 0.001, WD: 0.01, PEHE: 1.5738036410618406, ATE: 0.24756813049316406, test loss 1.337394118309021\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2733789682388306\n",
      "Alpha: 22.22222222222222, LR: 0.01, WD: 0.01, PEHE: 1.725687072588063, ATE: 0.7562589645385742, test loss 1.2733789682388306\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4670206308364868\n",
      "Alpha: 33.33333333333333, LR: 0.0001, WD: 0, PEHE: 1.5766765632614508, ATE: 0.11887168884277344, test loss 1.4670206308364868\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3019901514053345\n",
      "Alpha: 33.33333333333333, LR: 0.001, WD: 0, PEHE: 1.633638601905122, ATE: 0.5055928230285645, test loss 1.3019901514053345\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2902886867523193\n",
      "Alpha: 33.33333333333333, LR: 0.01, WD: 0, PEHE: 1.7842820445632415, ATE: 0.8834881782531738, test loss 1.2902886867523193\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4100724458694458\n",
      "Alpha: 33.33333333333333, LR: 0.0001, WD: 1e-05, PEHE: 1.6104150022799966, ATE: 0.34053564071655273, test loss 1.4100724458694458\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3163784742355347\n",
      "Alpha: 33.33333333333333, LR: 0.001, WD: 1e-05, PEHE: 1.5964090193699905, ATE: 0.37041807174682617, test loss 1.3163784742355347\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.270885705947876\n",
      "Alpha: 33.33333333333333, LR: 0.01, WD: 1e-05, PEHE: 1.6970242766586598, ATE: 0.6898231506347656, test loss 1.270885705947876\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4446552991867065\n",
      "Alpha: 33.33333333333333, LR: 0.0001, WD: 0.0001, PEHE: 1.6110919571245843, ATE: 0.3013424873352051, test loss 1.4446552991867065\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2938711643218994\n",
      "Alpha: 33.33333333333333, LR: 0.001, WD: 0.0001, PEHE: 1.6736566195317781, ATE: 0.6223354339599609, test loss 1.2938711643218994\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3052363395690918\n",
      "Alpha: 33.33333333333333, LR: 0.01, WD: 0.0001, PEHE: 1.701992883539619, ATE: 0.6952090263366699, test loss 1.3052363395690918\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.409331202507019\n",
      "Alpha: 33.33333333333333, LR: 0.0001, WD: 0.001, PEHE: 1.5888783666103727, ATE: 0.24491262435913086, test loss 1.409331202507019\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3202489614486694\n",
      "Alpha: 33.33333333333333, LR: 0.001, WD: 0.001, PEHE: 1.603060658968842, ATE: 0.39385080337524414, test loss 1.3202489614486694\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.387395977973938\n",
      "Alpha: 33.33333333333333, LR: 0.01, WD: 0.001, PEHE: 1.610825338815795, ATE: 0.43805408477783203, test loss 1.387395977973938\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4256571531295776\n",
      "Alpha: 33.33333333333333, LR: 0.0001, WD: 0.01, PEHE: 1.5881786577872476, ATE: 0.2200922966003418, test loss 1.4256571531295776\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3286044597625732\n",
      "Alpha: 33.33333333333333, LR: 0.001, WD: 0.01, PEHE: 1.6006038122476587, ATE: 0.3840007781982422, test loss 1.3286044597625732\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3933969736099243\n",
      "Alpha: 33.33333333333333, LR: 0.01, WD: 0.01, PEHE: 1.5693106420789236, ATE: 0.2447037696838379, test loss 1.3933969736099243\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.413692831993103\n",
      "Alpha: 44.44444444444444, LR: 0.0001, WD: 0, PEHE: 1.5893994209552504, ATE: 0.2425251007080078, test loss 1.413692831993103\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3057869672775269\n",
      "Alpha: 44.44444444444444, LR: 0.001, WD: 0, PEHE: 1.6593907644668866, ATE: 0.5809130668640137, test loss 1.3057869672775269\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2769910097122192\n",
      "Alpha: 44.44444444444444, LR: 0.01, WD: 0, PEHE: 1.6506699184674314, ATE: 0.5611515045166016, test loss 1.2769910097122192\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.443214774131775\n",
      "Alpha: 44.44444444444444, LR: 0.0001, WD: 1e-05, PEHE: 1.5937320483823545, ATE: 0.23120355606079102, test loss 1.443214774131775\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3083597421646118\n",
      "Alpha: 44.44444444444444, LR: 0.001, WD: 1e-05, PEHE: 1.6307139074813148, ATE: 0.496335506439209, test loss 1.3083597421646118\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3158864974975586\n",
      "Alpha: 44.44444444444444, LR: 0.01, WD: 1e-05, PEHE: 1.5765395556955135, ATE: 0.28533077239990234, test loss 1.3158864974975586\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.452782154083252\n",
      "Alpha: 44.44444444444444, LR: 0.0001, WD: 0.0001, PEHE: 1.5990294731625432, ATE: 0.23927974700927734, test loss 1.452782154083252\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2897707223892212\n",
      "Alpha: 44.44444444444444, LR: 0.001, WD: 0.0001, PEHE: 1.6586436842284962, ATE: 0.5843725204467773, test loss 1.2897707223892212\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3086497783660889\n",
      "Alpha: 44.44444444444444, LR: 0.01, WD: 0.0001, PEHE: 1.6167053388446906, ATE: 0.4581012725830078, test loss 1.3086497783660889\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4097312688827515\n",
      "Alpha: 44.44444444444444, LR: 0.0001, WD: 0.001, PEHE: 1.6145522165889101, ATE: 0.3467411994934082, test loss 1.4097312688827515\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3275890350341797\n",
      "Alpha: 44.44444444444444, LR: 0.001, WD: 0.001, PEHE: 1.5897770148290176, ATE: 0.3271913528442383, test loss 1.3275890350341797\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3128793239593506\n",
      "Alpha: 44.44444444444444, LR: 0.01, WD: 0.001, PEHE: 1.5903414760235355, ATE: 0.35402917861938477, test loss 1.3128793239593506\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4579473733901978\n",
      "Alpha: 44.44444444444444, LR: 0.0001, WD: 0.01, PEHE: 1.5937663058774472, ATE: 0.2279067039489746, test loss 1.4579473733901978\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.326339602470398\n",
      "Alpha: 44.44444444444444, LR: 0.001, WD: 0.01, PEHE: 1.633254798960354, ATE: 0.5037679672241211, test loss 1.326339602470398\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3015341758728027\n",
      "Alpha: 44.44444444444444, LR: 0.01, WD: 0.01, PEHE: 1.5895860917786961, ATE: 0.351102352142334, test loss 1.3015341758728027\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4532864093780518\n",
      "Alpha: 55.55555555555556, LR: 0.0001, WD: 0, PEHE: 1.5928212619994788, ATE: 0.21069574356079102, test loss 1.4532864093780518\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3101969957351685\n",
      "Alpha: 55.55555555555556, LR: 0.001, WD: 0, PEHE: 1.6195636928196084, ATE: 0.45652246475219727, test loss 1.3101969957351685\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3210011720657349\n",
      "Alpha: 55.55555555555556, LR: 0.01, WD: 0, PEHE: 1.5887983104404866, ATE: 0.34601783752441406, test loss 1.3210011720657349\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.398567795753479\n",
      "Alpha: 55.55555555555556, LR: 0.0001, WD: 1e-05, PEHE: 1.6040606112741231, ATE: 0.3186030387878418, test loss 1.398567795753479\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3095378875732422\n",
      "Alpha: 55.55555555555556, LR: 0.001, WD: 1e-05, PEHE: 1.611974524109728, ATE: 0.42738771438598633, test loss 1.3095378875732422\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2866588830947876\n",
      "Alpha: 55.55555555555556, LR: 0.01, WD: 1e-05, PEHE: 1.6478272524310218, ATE: 0.5422663688659668, test loss 1.2866588830947876\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3810808658599854\n",
      "Alpha: 55.55555555555556, LR: 0.0001, WD: 0.0001, PEHE: 1.5911282685637589, ATE: 0.28482484817504883, test loss 1.3810808658599854\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.311165452003479\n",
      "Alpha: 55.55555555555556, LR: 0.001, WD: 0.0001, PEHE: 1.592542452643087, ATE: 0.35559988021850586, test loss 1.311165452003479\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3069205284118652\n",
      "Alpha: 55.55555555555556, LR: 0.01, WD: 0.0001, PEHE: 1.7504991092107578, ATE: 0.8103928565979004, test loss 1.3069205284118652\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4091111421585083\n",
      "Alpha: 55.55555555555556, LR: 0.0001, WD: 0.001, PEHE: 1.5977223576157238, ATE: 0.28766822814941406, test loss 1.4091111421585083\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.300238013267517\n",
      "Alpha: 55.55555555555556, LR: 0.001, WD: 0.001, PEHE: 1.6185901106296268, ATE: 0.4552440643310547, test loss 1.300238013267517\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2947168350219727\n",
      "Alpha: 55.55555555555556, LR: 0.01, WD: 0.001, PEHE: 1.6444375924377195, ATE: 0.5359883308410645, test loss 1.2947168350219727\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.402382254600525\n",
      "Alpha: 55.55555555555556, LR: 0.0001, WD: 0.01, PEHE: 1.604640775035565, ATE: 0.3229846954345703, test loss 1.402382254600525\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3088295459747314\n",
      "Alpha: 55.55555555555556, LR: 0.001, WD: 0.01, PEHE: 1.6226037036687504, ATE: 0.46601343154907227, test loss 1.3088295459747314\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.459115743637085\n",
      "Alpha: 55.55555555555556, LR: 0.01, WD: 0.01, PEHE: 1.7115938504091865, ATE: 0.7247934341430664, test loss 1.459115743637085\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4078718423843384\n",
      "Alpha: 66.66666666666666, LR: 0.0001, WD: 0, PEHE: 1.6190836382179785, ATE: 0.37160825729370117, test loss 1.4078718423843384\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3124010562896729\n",
      "Alpha: 66.66666666666666, LR: 0.001, WD: 0, PEHE: 1.6172604014601302, ATE: 0.4468693733215332, test loss 1.3124010562896729\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3114402294158936\n",
      "Alpha: 66.66666666666666, LR: 0.01, WD: 0, PEHE: 1.5791254177426621, ATE: 0.29301023483276367, test loss 1.3114402294158936\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4663265943527222\n",
      "Alpha: 66.66666666666666, LR: 0.0001, WD: 1e-05, PEHE: 1.6021601608500364, ATE: 0.2508258819580078, test loss 1.4663265943527222\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3287792205810547\n",
      "Alpha: 66.66666666666666, LR: 0.001, WD: 1e-05, PEHE: 1.6657973724549697, ATE: 0.5944328308105469, test loss 1.3287792205810547\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3175585269927979\n",
      "Alpha: 66.66666666666666, LR: 0.01, WD: 1e-05, PEHE: 1.573655020443588, ATE: 0.25660133361816406, test loss 1.3175585269927979\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4195483922958374\n",
      "Alpha: 66.66666666666666, LR: 0.0001, WD: 0.0001, PEHE: 1.6297084379085518, ATE: 0.40761709213256836, test loss 1.4195483922958374\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.323434829711914\n",
      "Alpha: 66.66666666666666, LR: 0.001, WD: 0.0001, PEHE: 1.5908345502259582, ATE: 0.33495664596557617, test loss 1.323434829711914\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3161444664001465\n",
      "Alpha: 66.66666666666666, LR: 0.01, WD: 0.0001, PEHE: 1.5753362962665587, ATE: 0.27452850341796875, test loss 1.3161444664001465\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.400177240371704\n",
      "Alpha: 66.66666666666666, LR: 0.0001, WD: 0.001, PEHE: 1.5896565095082793, ATE: 0.2584691047668457, test loss 1.400177240371704\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2967596054077148\n",
      "Alpha: 66.66666666666666, LR: 0.001, WD: 0.001, PEHE: 1.6418281140147521, ATE: 0.531611442565918, test loss 1.2967596054077148\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2850226163864136\n",
      "Alpha: 66.66666666666666, LR: 0.01, WD: 0.001, PEHE: 1.6642128603348143, ATE: 0.6040902137756348, test loss 1.2850226163864136\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4152717590332031\n",
      "Alpha: 66.66666666666666, LR: 0.0001, WD: 0.01, PEHE: 1.6154654359511402, ATE: 0.35120344161987305, test loss 1.4152717590332031\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3122279644012451\n",
      "Alpha: 66.66666666666666, LR: 0.001, WD: 0.01, PEHE: 1.6307232645765202, ATE: 0.4901161193847656, test loss 1.3122279644012451\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3328102827072144\n",
      "Alpha: 66.66666666666666, LR: 0.01, WD: 0.01, PEHE: 1.5975541732748382, ATE: 0.3860511779785156, test loss 1.3328102827072144\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4358288049697876\n",
      "Alpha: 77.77777777777777, LR: 0.0001, WD: 0, PEHE: 1.6064810056112617, ATE: 0.29335594177246094, test loss 1.4358288049697876\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3348267078399658\n",
      "Alpha: 77.77777777777777, LR: 0.001, WD: 0, PEHE: 1.5806369241345402, ATE: 0.294217586517334, test loss 1.3348267078399658\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.476166844367981\n",
      "Alpha: 77.77777777777777, LR: 0.01, WD: 0, PEHE: 1.6166233423988918, ATE: 0.4573216438293457, test loss 1.476166844367981\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4377377033233643\n",
      "Alpha: 77.77777777777777, LR: 0.0001, WD: 1e-05, PEHE: 1.5737050167135886, ATE: 0.1311030387878418, test loss 1.4377377033233643\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3242285251617432\n",
      "Alpha: 77.77777777777777, LR: 0.001, WD: 1e-05, PEHE: 1.66120866515988, ATE: 0.5841341018676758, test loss 1.3242285251617432\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4063297510147095\n",
      "Alpha: 77.77777777777777, LR: 0.01, WD: 1e-05, PEHE: 1.7678260924349636, ATE: 0.7252521514892578, test loss 1.4063297510147095\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.465321660041809\n",
      "Alpha: 77.77777777777777, LR: 0.0001, WD: 0.0001, PEHE: 1.6028131579514713, ATE: 0.25725555419921875, test loss 1.465321660041809\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3188904523849487\n",
      "Alpha: 77.77777777777777, LR: 0.001, WD: 0.0001, PEHE: 1.5929796189502838, ATE: 0.35282421112060547, test loss 1.3188904523849487\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3068537712097168\n",
      "Alpha: 77.77777777777777, LR: 0.01, WD: 0.0001, PEHE: 1.6268781665327139, ATE: 0.4910268783569336, test loss 1.3068537712097168\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.448288083076477\n",
      "Alpha: 77.77777777777777, LR: 0.0001, WD: 0.001, PEHE: 1.587009011582555, ATE: 0.18093395233154297, test loss 1.448288083076477\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.299133539199829\n",
      "Alpha: 77.77777777777777, LR: 0.001, WD: 0.001, PEHE: 1.6273074273768313, ATE: 0.4841938018798828, test loss 1.299133539199829\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.381379246711731\n",
      "Alpha: 77.77777777777777, LR: 0.01, WD: 0.001, PEHE: 1.5692313348724531, ATE: 0.22372865676879883, test loss 1.381379246711731\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4389925003051758\n",
      "Alpha: 77.77777777777777, LR: 0.0001, WD: 0.01, PEHE: 1.587734012927507, ATE: 0.2089829444885254, test loss 1.4389925003051758\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2931984663009644\n",
      "Alpha: 77.77777777777777, LR: 0.001, WD: 0.01, PEHE: 1.6671169705832183, ATE: 0.603912353515625, test loss 1.2931984663009644\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.284790277481079\n",
      "Alpha: 77.77777777777777, LR: 0.01, WD: 0.01, PEHE: 1.6175167467291016, ATE: 0.46202945709228516, test loss 1.284790277481079\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4472987651824951\n",
      "Alpha: 88.88888888888889, LR: 0.0001, WD: 0, PEHE: 1.601029916925776, ATE: 0.25298547744750977, test loss 1.4472987651824951\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3167643547058105\n",
      "Alpha: 88.88888888888889, LR: 0.001, WD: 0, PEHE: 1.5996543868628836, ATE: 0.3747286796569824, test loss 1.3167643547058105\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3021162748336792\n",
      "Alpha: 88.88888888888889, LR: 0.01, WD: 0, PEHE: 1.5974088817752143, ATE: 0.3847637176513672, test loss 1.3021162748336792\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4471447467803955\n",
      "Alpha: 88.88888888888889, LR: 0.0001, WD: 1e-05, PEHE: 1.587082322810459, ATE: 0.1845240592956543, test loss 1.4471447467803955\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3130518198013306\n",
      "Alpha: 88.88888888888889, LR: 0.001, WD: 1e-05, PEHE: 1.603469606359496, ATE: 0.3937077522277832, test loss 1.3130518198013306\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3812791109085083\n",
      "Alpha: 88.88888888888889, LR: 0.01, WD: 1e-05, PEHE: 1.5567371908028143, ATE: 0.08910083770751953, test loss 1.3812791109085083\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4552085399627686\n",
      "Alpha: 88.88888888888889, LR: 0.0001, WD: 0.0001, PEHE: 1.5921460476646343, ATE: 0.22045612335205078, test loss 1.4552085399627686\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.291872262954712\n",
      "Alpha: 88.88888888888889, LR: 0.001, WD: 0.0001, PEHE: 1.649595676358918, ATE: 0.555628776550293, test loss 1.291872262954712\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2797249555587769\n",
      "Alpha: 88.88888888888889, LR: 0.01, WD: 0.0001, PEHE: 1.7637727862750956, ATE: 0.8403763771057129, test loss 1.2797249555587769\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3922357559204102\n",
      "Alpha: 88.88888888888889, LR: 0.0001, WD: 0.001, PEHE: 1.5942408983755318, ATE: 0.2847161293029785, test loss 1.3922357559204102\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2986164093017578\n",
      "Alpha: 88.88888888888889, LR: 0.001, WD: 0.001, PEHE: 1.6414712085970178, ATE: 0.5269298553466797, test loss 1.2986164093017578\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2772998809814453\n",
      "Alpha: 88.88888888888889, LR: 0.01, WD: 0.001, PEHE: 1.733324712340606, ATE: 0.7746744155883789, test loss 1.2772998809814453\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.409118890762329\n",
      "Alpha: 88.88888888888889, LR: 0.0001, WD: 0.01, PEHE: 1.588460034216774, ATE: 0.23822879791259766, test loss 1.409118890762329\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2943443059921265\n",
      "Alpha: 88.88888888888889, LR: 0.001, WD: 0.01, PEHE: 1.678076037610793, ATE: 0.6317811012268066, test loss 1.2943443059921265\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2962367534637451\n",
      "Alpha: 88.88888888888889, LR: 0.01, WD: 0.01, PEHE: 1.687611964714601, ATE: 0.6656942367553711, test loss 1.2962367534637451\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4508804082870483\n",
      "Alpha: 100.0, LR: 0.0001, WD: 0, PEHE: 1.5935659863323546, ATE: 0.22990894317626953, test loss 1.4508804082870483\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3109463453292847\n",
      "Alpha: 100.0, LR: 0.001, WD: 0, PEHE: 1.6207544913970366, ATE: 0.4615654945373535, test loss 1.3109463453292847\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2930155992507935\n",
      "Alpha: 100.0, LR: 0.01, WD: 0, PEHE: 1.6006002373140964, ATE: 0.39768457412719727, test loss 1.2930155992507935\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4502803087234497\n",
      "Alpha: 100.0, LR: 0.0001, WD: 1e-05, PEHE: 1.607470821038666, ATE: 0.27877044677734375, test loss 1.4502803087234497\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.286516785621643\n",
      "Alpha: 100.0, LR: 0.001, WD: 1e-05, PEHE: 1.6813362014397146, ATE: 0.6448836326599121, test loss 1.286516785621643\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4009560346603394\n",
      "Alpha: 100.0, LR: 0.01, WD: 1e-05, PEHE: 1.554835403538052, ATE: 0.0861811637878418, test loss 1.4009560346603394\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.416922688484192\n",
      "Alpha: 100.0, LR: 0.0001, WD: 0.0001, PEHE: 1.5900558592622904, ATE: 0.25034570693969727, test loss 1.416922688484192\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.331380009651184\n",
      "Alpha: 100.0, LR: 0.001, WD: 0.0001, PEHE: 1.579564863476162, ATE: 0.28656482696533203, test loss 1.331380009651184\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2790671586990356\n",
      "Alpha: 100.0, LR: 0.01, WD: 0.0001, PEHE: 1.6310509483523854, ATE: 0.5065498352050781, test loss 1.2790671586990356\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4069578647613525\n",
      "Alpha: 100.0, LR: 0.0001, WD: 0.001, PEHE: 1.5982360533916258, ATE: 0.28990936279296875, test loss 1.4069578647613525\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3104499578475952\n",
      "Alpha: 100.0, LR: 0.001, WD: 0.001, PEHE: 1.5964492678253168, ATE: 0.37096643447875977, test loss 1.3104499578475952\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2894407510757446\n",
      "Alpha: 100.0, LR: 0.01, WD: 0.001, PEHE: 1.807906809253404, ATE: 0.9270644187927246, test loss 1.2894407510757446\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.4173372983932495\n",
      "Alpha: 100.0, LR: 0.0001, WD: 0.01, PEHE: 1.5943455051040178, ATE: 0.2723808288574219, test loss 1.4173372983932495\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.3097113370895386\n",
      "Alpha: 100.0, LR: 0.001, WD: 0.01, PEHE: 1.6197318733521096, ATE: 0.4507761001586914, test loss 1.3097113370895386\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "Test set loss: 1.2961980104446411\n",
      "Alpha: 100.0, LR: 0.01, WD: 0.01, PEHE: 1.5957219509102138, ATE: 0.3783879280090332, test loss 1.2961980104446411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# TARNET grid search\n",
    "from itertools import product\n",
    "\n",
    "alpha_values = np.linspace(0, 100, 10)  \n",
    "weight_decay_values = [0, 1e-5, 1e-4, 1e-3, 1e-2] \n",
    "learning_rate_values = [1e-4, 1e-3, 1e-2]  \n",
    "\n",
    "losses = []\n",
    "\n",
    "# Perform grid search\n",
    "for alpha, weight_decay, learning_rate in product(alpha_values, weight_decay_values, learning_rate_values):\n",
    "    tarnet_model = TARNet(df=IHDP_data, alpha=alpha, lr=learning_rate, weight_decay=weight_decay)  \n",
    "\n",
    "    # Train model\n",
    "    loss_curve, test_loss = tarnet_model.fit(epochs=10)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    output, X, y, t, ite = tarnet_model.predict_test(use_ite=True)\n",
    "    PEHE_val, ATE_val, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "\n",
    "    # Evaluate on training set\n",
    "    output, X, y, t, ite = tarnet_model.predict_train(use_ite=True)\n",
    "    PEHE_train, ATE_train, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "\n",
    "    print(f\"Alpha: {alpha}, LR: {learning_rate}, WD: {weight_decay}, PEHE: {np.sqrt(PEHE_val)}, ATE: {ATE_val}, test loss {test_loss}\")\n",
    "\n",
    "    losses.append(pd.DataFrame({\n",
    "        'alpha': [alpha],\n",
    "        'learning_rate': [learning_rate],\n",
    "        'weight_decay': [weight_decay],\n",
    "        'PEHE_train': [PEHE_train],\n",
    "        'PEHE_val': [PEHE_val],\n",
    "        'ATE_train': [ATE_train],\n",
    "        'ATE_val': [ATE_val],\n",
    "        'test_pred_loss': [test_loss]\n",
    "    }))\n",
    "\n",
    "\n",
    "data_loss_curves = pd.concat(losses, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9496d04f-15c3-42e4-82e5-9c45c4f7cd8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>PEHE_train</th>\n",
       "      <th>PEHE_val</th>\n",
       "      <th>ATE_train</th>\n",
       "      <th>ATE_val</th>\n",
       "      <th>test_pred_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.611720</td>\n",
       "      <td>2.411800</td>\n",
       "      <td>0.124935</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>1.398115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.671570</td>\n",
       "      <td>2.417513</td>\n",
       "      <td>0.265672</td>\n",
       "      <td>0.086181</td>\n",
       "      <td>1.400956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.671364</td>\n",
       "      <td>2.423431</td>\n",
       "      <td>0.259223</td>\n",
       "      <td>0.089101</td>\n",
       "      <td>1.381279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.111111</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.685827</td>\n",
       "      <td>2.424901</td>\n",
       "      <td>0.294738</td>\n",
       "      <td>0.116388</td>\n",
       "      <td>1.378213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.754894</td>\n",
       "      <td>2.485909</td>\n",
       "      <td>0.323336</td>\n",
       "      <td>0.118872</td>\n",
       "      <td>1.467021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>88.888889</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>3.608867</td>\n",
       "      <td>3.110894</td>\n",
       "      <td>1.007816</td>\n",
       "      <td>0.840376</td>\n",
       "      <td>1.279725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>3.617663</td>\n",
       "      <td>3.123029</td>\n",
       "      <td>1.012179</td>\n",
       "      <td>0.848721</td>\n",
       "      <td>1.289603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>22.222222</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.681276</td>\n",
       "      <td>3.176316</td>\n",
       "      <td>1.042849</td>\n",
       "      <td>0.878982</td>\n",
       "      <td>1.317069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>33.333333</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.687129</td>\n",
       "      <td>3.183662</td>\n",
       "      <td>1.045756</td>\n",
       "      <td>0.883488</td>\n",
       "      <td>1.290289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>3.787010</td>\n",
       "      <td>3.268527</td>\n",
       "      <td>1.090590</td>\n",
       "      <td>0.927064</td>\n",
       "      <td>1.289441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          alpha  learning_rate  weight_decay  PEHE_train  PEHE_val  ATE_train   \n",
       "23    11.111111         0.0100       0.00010    2.611720  2.411800   0.124935  \\\n",
       "140  100.000000         0.0100       0.00001    2.671570  2.417513   0.265672   \n",
       "125   88.888889         0.0100       0.00001    2.671364  2.423431   0.259223   \n",
       "16    11.111111         0.0010       0.00000    2.685827  2.424901   0.294738   \n",
       "45    33.333333         0.0001       0.00000    2.754894  2.485909   0.323336   \n",
       "..          ...            ...           ...         ...       ...        ...   \n",
       "128   88.888889         0.0100       0.00010    3.608867  3.110894   1.007816   \n",
       "38    22.222222         0.0100       0.00010    3.617663  3.123029   1.012179   \n",
       "35    22.222222         0.0100       0.00001    3.681276  3.176316   1.042849   \n",
       "47    33.333333         0.0100       0.00000    3.687129  3.183662   1.045756   \n",
       "146  100.000000         0.0100       0.00100    3.787010  3.268527   1.090590   \n",
       "\n",
       "      ATE_val  test_pred_loss  \n",
       "23   0.034286        1.398115  \n",
       "140  0.086181        1.400956  \n",
       "125  0.089101        1.381279  \n",
       "16   0.116388        1.378213  \n",
       "45   0.118872        1.467021  \n",
       "..        ...             ...  \n",
       "128  0.840376        1.279725  \n",
       "38   0.848721        1.289603  \n",
       "35   0.878982        1.317069  \n",
       "47   0.883488        1.290289  \n",
       "146  0.927064        1.289441  \n",
       "\n",
       "[135 rows x 8 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loss_curves[data_loss_curves['alpha']!=0].sort_values(by='ATE_val', ascending=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "aedb36b6-07b7-48dc-a1ec-ef0f3ff0a77e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>PEHE_train</th>\n",
       "      <th>PEHE_val</th>\n",
       "      <th>ATE_train</th>\n",
       "      <th>ATE_val</th>\n",
       "      <th>test_pred_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.619623</td>\n",
       "      <td>2.403334</td>\n",
       "      <td>0.161393</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>1.399922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.802814</td>\n",
       "      <td>2.510095</td>\n",
       "      <td>0.387372</td>\n",
       "      <td>0.177797</td>\n",
       "      <td>1.441420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.801604</td>\n",
       "      <td>2.502777</td>\n",
       "      <td>0.396362</td>\n",
       "      <td>0.208815</td>\n",
       "      <td>1.418787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.853323</td>\n",
       "      <td>2.546407</td>\n",
       "      <td>0.436867</td>\n",
       "      <td>0.231728</td>\n",
       "      <td>1.447881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.891708</td>\n",
       "      <td>2.567605</td>\n",
       "      <td>0.473905</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>1.443585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.814991</td>\n",
       "      <td>2.491688</td>\n",
       "      <td>0.464903</td>\n",
       "      <td>0.284337</td>\n",
       "      <td>1.335938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.900833</td>\n",
       "      <td>2.547306</td>\n",
       "      <td>0.548157</td>\n",
       "      <td>0.367320</td>\n",
       "      <td>1.309769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.066806</td>\n",
       "      <td>2.681851</td>\n",
       "      <td>0.626659</td>\n",
       "      <td>0.425045</td>\n",
       "      <td>1.412304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.981058</td>\n",
       "      <td>2.606629</td>\n",
       "      <td>0.618273</td>\n",
       "      <td>0.442915</td>\n",
       "      <td>1.301263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>3.048521</td>\n",
       "      <td>2.661001</td>\n",
       "      <td>0.673499</td>\n",
       "      <td>0.506759</td>\n",
       "      <td>1.326275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.091058</td>\n",
       "      <td>2.687055</td>\n",
       "      <td>0.699814</td>\n",
       "      <td>0.520870</td>\n",
       "      <td>1.323906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>3.135351</td>\n",
       "      <td>2.718226</td>\n",
       "      <td>0.731633</td>\n",
       "      <td>0.553520</td>\n",
       "      <td>1.310831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.135966</td>\n",
       "      <td>2.736539</td>\n",
       "      <td>0.736158</td>\n",
       "      <td>0.576255</td>\n",
       "      <td>1.273609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.212577</td>\n",
       "      <td>2.791753</td>\n",
       "      <td>0.785990</td>\n",
       "      <td>0.622016</td>\n",
       "      <td>1.274963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>3.898038</td>\n",
       "      <td>3.359720</td>\n",
       "      <td>1.139230</td>\n",
       "      <td>0.974986</td>\n",
       "      <td>1.303441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  learning_rate  weight_decay  PEHE_train  PEHE_val  ATE_train   \n",
       "11    0.0         0.0100       0.00100    2.619623  2.403334   0.161393  \\\n",
       "6     0.0         0.0001       0.00010    2.802814  2.510095   0.387372   \n",
       "9     0.0         0.0001       0.00100    2.801604  2.502777   0.396362   \n",
       "12    0.0         0.0001       0.01000    2.853323  2.546407   0.436867   \n",
       "0     0.0         0.0001       0.00000    2.891708  2.567605   0.473905   \n",
       "13    0.0         0.0010       0.01000    2.814991  2.491688   0.464903   \n",
       "10    0.0         0.0010       0.00100    2.900833  2.547306   0.548157   \n",
       "3     0.0         0.0001       0.00001    3.066806  2.681851   0.626659   \n",
       "1     0.0         0.0010       0.00000    2.981058  2.606629   0.618273   \n",
       "14    0.0         0.0100       0.01000    3.048521  2.661001   0.673499   \n",
       "4     0.0         0.0010       0.00001    3.091058  2.687055   0.699814   \n",
       "7     0.0         0.0010       0.00010    3.135351  2.718226   0.731633   \n",
       "5     0.0         0.0100       0.00001    3.135966  2.736539   0.736158   \n",
       "2     0.0         0.0100       0.00000    3.212577  2.791753   0.785990   \n",
       "8     0.0         0.0100       0.00010    3.898038  3.359720   1.139230   \n",
       "\n",
       "     ATE_val  test_pred_loss  \n",
       "11  0.000250        1.399922  \n",
       "6   0.177797        1.441420  \n",
       "9   0.208815        1.418787  \n",
       "12  0.231728        1.447881  \n",
       "0   0.264963        1.443585  \n",
       "13  0.284337        1.335938  \n",
       "10  0.367320        1.309769  \n",
       "3   0.425045        1.412304  \n",
       "1   0.442915        1.301263  \n",
       "14  0.506759        1.326275  \n",
       "4   0.520870        1.323906  \n",
       "7   0.553520        1.310831  \n",
       "5   0.576255        1.273609  \n",
       "2   0.622016        1.274963  \n",
       "8   0.974986        1.303441  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loss_curves[data_loss_curves['alpha']==0].sort_values(by='ATE_val', ascending=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a7b2d7a9-14b3-4f79-81fb-10f5f2266871",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5836815032959866 0.19173002243041992\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5889854269925903 0.23306703567504883\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5842579183261716 0.16185712814331055\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.615482777103766 0.3581714630126953\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5983337607331778 0.2588949203491211\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5872528184104768 0.19365453720092773\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5950304011733176 0.23205137252807617\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5797234928245316 0.16268682479858398\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.586938851969841 0.17972040176391602\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.614034555346527 0.342984676361084\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5939660767328219 0.2476634979248047\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5861418644064682 0.2483348846435547\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6054609535195046 0.2807626724243164\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5933632474881692 0.26439952850341797\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5938647359799205 0.25750160217285156\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5870683518745274 0.1826167106628418\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5794212381035138 0.19677495956420898\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.596248762209419 0.2410588264465332\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5868300007783567 0.1950850486755371\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5756775412902815 0.14744186401367188\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.592094159595719 0.22881793975830078\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5924948443414662 0.20639610290527344\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5779746711061582 0.14816665649414062\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.590688869790335 0.2706785202026367\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5890809274690891 0.23540592193603516\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5766464710084684 0.12522506713867188\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5986997745310698 0.20485210418701172\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5841890666139875 0.18125295639038086\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5800007917909207 0.15410900115966797\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5803845536361794 0.15240812301635742\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.575972722930902 0.1497802734375\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5849847797661825 0.18576383590698242\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6006523709710714 0.27943849563598633\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.600516894412529 0.3094925880432129\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5953741586634094 0.27835941314697266\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5778506200986528 0.1761789321899414\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5841775534127147 0.21809625625610352\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5840488707632825 0.20441913604736328\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.572829549368455 0.13205528259277344\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5954381192746687 0.26628541946411133\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5800818972548452 0.1381983757019043\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5944166098338637 0.2672305107116699\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5846024329316426 0.20351934432983398\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5815594004819444 0.16175413131713867\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5960070765297785 0.2628312110900879\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6260529554595509 0.35817766189575195\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5884029223610925 0.22745370864868164\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.601126262520453 0.28554868698120117\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5973252977292218 0.2625155448913574\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5882401310466838 0.2117314338684082\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5940158846600951 0.2039947509765625\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5845059101864825 0.12136173248291016\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.575399632691828 0.19846677780151367\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5971284101643415 0.26135683059692383\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5932740641521017 0.2595357894897461\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6005177881932071 0.2575492858886719\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5890844532998358 0.2365255355834961\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5888446789854664 0.24509000778198242\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5792083043603815 0.17395496368408203\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5795604107574677 0.17096757888793945\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5960876673854667 0.24010181427001953\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5850219338761626 0.21864652633666992\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5902403540652306 0.20482730865478516\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5830701642755862 0.23412036895751953\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5872143646147807 0.23066329956054688\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5917070047483122 0.26662492752075195\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6003517598672046 0.30464935302734375\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5777548931966527 0.15770959854125977\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6066593108793636 0.2933669090270996\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5798401529601118 0.17682456970214844\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.586213637492084 0.20480060577392578\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5978573250558827 0.2694888114929199\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.576313905804478 0.1783456802368164\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5898385762498357 0.23636198043823242\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5834397815592296 0.13554716110229492\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5826091699774933 0.14140844345092773\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5846864623658956 0.227294921875\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6033021736025121 0.3178839683532715\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5888831683517541 0.21832895278930664\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5746591108260914 0.1512899398803711\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5829965919318174 0.1952071189880371\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5803335617559837 0.16231679916381836\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5880916604269808 0.21872997283935547\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.581063056721016 0.20447921752929688\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5803398226819505 0.16077280044555664\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5742245051655035 0.14766597747802734\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5909010162396309 0.24779510498046875\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.589962816583355 0.2255692481994629\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.58027095113202 0.14023351669311523\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.6092861854712657 0.34027910232543945\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5884277636439565 0.24222707748413086\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5869169170647404 0.2099761962890625\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.59162873860385 0.24679231643676758\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5691935789799063 0.07802963256835938\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5970504097050024 0.2902956008911133\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.579788011622721 0.13022184371948242\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5821105937134599 0.20879220962524414\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5833903185310536 0.20612764358520508\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5724944333219018 0.08442354202270508\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training\n",
      "1.5855771862815813 0.19120264053344727\n"
     ]
    }
   ],
   "source": [
    "# TARNET and CFRmmd results\n",
    "losses = []\n",
    "\n",
    "for alpha in range(0,100):\n",
    "    tarnet_model = TARNet(df=IHDP_data, alpha = 0, weight_decay=0,lr=0.0001, target_reg=True)\n",
    "    loss_curve = tarnet_model.fit(epochs=10)\n",
    "    output, X, y, t, ite = tarnet_model.predict_test(use_ite=True)\n",
    "    representation = output[1]\n",
    "    #tarnet_model.plot_representation_space(representation, t)\n",
    "    PEHE_val, ATE_val, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "    output, X, y, t, ite = tarnet_model.predict_train(use_ite=True)\n",
    "    representation = output[1]\n",
    "    PEHE_train, ATE_train, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "    print(np.sqrt(PEHE_val), ATE_val)\n",
    "    losses.append(pd.DataFrame({'index': [alpha],\n",
    "                    #'item':range(len(loss_curve)),\n",
    "                    #'curve': loss_curve,\n",
    "                    #'final_loss': loss_curve[-1],\n",
    "                    'PEHE_train': [PEHE_train],\n",
    "                    'PEHE_val': [PEHE_val],\n",
    "                    'ATE_train': [ATE_train],\n",
    "                    'ATE_val': [ATE_val]}))\n",
    "data_loss_curves_by_alpha = pd.concat(losses, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bee1bdad-8d51-499b-a2d3-af6769798d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEHE train:\n",
      "2.8340411806106567 0.005476878017574788\n",
      "PEHE val:\n",
      "2.5232702469825745 0.003141942994242172\n",
      "ATE train:\n",
      "0.4185618352890015 0.005930129062731158\n",
      "ATE val:\n",
      "0.21530826568603514 0.00572164198608509\n"
     ]
    }
   ],
   "source": [
    "#plt.figure(figsize=(10, 6))\n",
    "#sns.lineplot(data=data_loss_curves_by_alpha,x='item', y='curve',  palette='tab10') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "\n",
    "# plt.xlabel(\"Item\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Loss Curves for Different Values of Alpha\")\n",
    "# plt.show()\n",
    "\n",
    "print('PEHE train:')\n",
    "print(data_loss_curves_by_alpha['PEHE_train'].mean(), data_loss_curves_by_alpha['PEHE_train'].std()/10)\n",
    "\n",
    "print('PEHE val:')\n",
    "print(data_loss_curves_by_alpha['PEHE_val'].mean(), data_loss_curves_by_alpha['PEHE_val'].std()/10)\n",
    "\n",
    "\n",
    "print('ATE train:')\n",
    "print(data_loss_curves_by_alpha['ATE_train'].mean(), data_loss_curves_by_alpha['ATE_train'].std()/10)\n",
    "\n",
    "print('ATE val:')\n",
    "print(data_loss_curves_by_alpha['ATE_val'].mean(), data_loss_curves_by_alpha['ATE_val'].std()/10)\n",
    "\n",
    "\n",
    "# CFR_MMD\n",
    "# PEHE train:\n",
    "# 3.059446744244508 0.038647126992868625\n",
    "# PEHE val:\n",
    "# 2.6986790160940153 0.028957534513708215\n",
    "# ATE train:\n",
    "# 0.6111315934344975 0.0297056323985731\n",
    "# ATE val:\n",
    "# 0.4661187981114243 0.027116498278425293\n",
    "\n",
    "# targeted reg tarnet\n",
    "# PEHE train:\n",
    "# 2.8340411806106567 0.005476878017574788\n",
    "# PEHE val:\n",
    "# 2.5232702469825745 0.003141942994242172\n",
    "# ATE train:\n",
    "# 0.4185618352890015 0.005930129062731158\n",
    "# ATE val:\n",
    "# 0.21530826568603514 0.00572164198608509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1a792b78-8ddb-453c-8b63-94a7823ae24c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj4AAAHHCAYAAAC/R1LgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACay0lEQVR4nO2deXhURdb/v50IAQQCCSEgCYu7jg7OoI7oD4FxwR0NLqAzwqujrwpqRs28zohAXAbHDZdxdwbwjUETO8ozvq5hOsgoOi44IqAom+ygyKJCoLvr98flNt2du1TVrbt1n8/z9APp5d66detWfevUOacijDEGgiAIgiCIPKDA7wIQBEEQBEF4BQkfgiAIgiDyBhI+BEEQBEHkDSR8CIIgCILIG0j4EARBEASRN5DwIQiCIAgibyDhQxAEQRBE3kDChyAIgiCIvIGED0EQBEEQeQMJH4IgQseMGTMQiUSwcuXKwJVj2LBhGDZsmOdl8eu8BBE2SPgQRIh57733MGXKFGzdupX7Nz/88AMmT56Mo446Cvvvvz9KS0txzDHH4MYbb8S6detS35syZQoikQjKy8vx008/tTlO//79cc4552S8F4lETF/XXHONaZnOO+88dOrUCTt27DD9zmWXXYb27dvju+++477WXGPx4sWYMmWK74KPIMLMfn4XgCAIed577z3U1tZi3Lhx6Natm+339+zZg5NPPhlffPEFxo4di+uvvx4//PADFi1ahPr6elxwwQU44IADMn6zadMmPPHEE7j55pu5ynTaaafh8ssvb/P+oYceavqbyy67DP/4xz/w8ssvG/72p59+wuzZs3HGGWegtLQUv/3tbzF69GgUFRVxlclL3nrrLdeOvXjxYtTW1mLYsGHo37+/Z+cliFyChA9B5BGvvPIKFixYgOeffx6XXnppxme7du3C7t272/zmmGOOwX333YfrrrsOHTt2tD3HoYceit/85jdC5TrvvPPQpUsX1NfXGwqf2bNn48cff8Rll10GACgsLERhYaHQObyiffv2eXVegggbtNRFECFlypQpqKmpAQAMGDAgtaRktQyybNkyAMBJJ53U5rMOHTqga9eubd6fNGkSNm7ciCeeeEJNwQ3o2LEjqqqqMGfOHGzatKnN5/X19ejSpQvOO+88AMa+NR999BFGjBiBHj16oGPHjhgwYACuuOKK1OctLS2IRCJoaWnJOPbKlSsRiUQwY8aM1HufffYZxo0bhwMPPBAdOnRAr169cMUVV3Ats2X72vTv3990+U8vy6pVq3DdddfhsMMOQ8eOHVFaWoqLLroo4/pmzJiBiy66CAAwfPjwNscw8vHZtGkTrrzySpSXl6NDhw4YOHAgZs6caXj9999/P55++mkcdNBBKCoqwnHHHYcPP/zQ9noJImyQxYcgQkpVVRWWLl2KWbNmYdq0aejRowcAoKyszPQ3/fr1AwA899xzmDhxIiKRiO15hgwZgl//+te49957ce2119pafXbt2oVvv/22zftdu3a1tEpcdtllmDlzJhoaGjBhwoTU+1u2bMGbb76JMWPGmJ5706ZNOP3001FWVoZbb70V3bp1w8qVK9HU1GR7fUa8/fbbWL58Of7rv/4LvXr1wqJFi/D0009j0aJFeP/997nqTeehhx7CDz/8kPHetGnT8Omnn6K0tBQA8OGHH+K9997D6NGjUVFRgZUrV+KJJ57AsGHDsHjxYnTq1Aknn3wybrjhBjzyyCP405/+hCOOOAIAUv9ms3PnTgwbNgxff/01JkyYgAEDBqCxsRHjxo3D1q1bceONN2Z8v76+Hjt27MB///d/IxKJ4N5770VVVRWWL1+Odu3aiVQfQQQbRhBEaLnvvvsYALZixQqu7//000/ssMMOYwBYv3792Lhx49jf/vY3tnHjxjbfnTx5MgPANm/ezObOncsAsAcffDD1eb9+/djZZ5+d8RsApq9Zs2ZZli0ej7PevXuzwYMHZ7z/5JNPMgDszTffTL03ffr0jOt++eWXGQD24Ycfmh4/FosxACwWi2W8v2LFCgaATZ8+PaOespk1axYDwN555x3TcjDG2NChQ9nQoUNNy9HQ0MAAsDvuuMPyfPPnz2cA2HPPPZd6r7Gx0fAajM770EMPMQCsrq4u9d7u3bvZ4MGDWefOndn27dszrr+0tJRt2bIl9d3Zs2czAOwf//iH6bUQRBihpS6CyCM6duyIDz74ILVENmPGDFx55ZXo3bs3rr/+erS2thr+7uSTT8bw4cNx7733YufOnZbnGDlyJN5+++02r+HDh1v+rrCwEKNHj8b8+fMzlnjq6+tRXl6OU045xfS3umP3q6++ij179lieh4d0y5JuwTrhhBMAAJ988on0cRcvXowrrrgCI0eOxMSJEw3Pt2fPHnz33Xc4+OCD0a1bN+nzvfbaa+jVqxfGjBmTeq9du3a44YYb8MMPP2Du3LkZ37/kkkvQvXv31N9DhgwBACxfvlzq/AQRVEj4EEQOsmXLFmzYsCH12rZtW+qz4uJi3HvvvVi5ciVWrlyJv/3tbzjssMPw17/+FXfeeafpMadMmYINGzbgySeftDx3RUUFTj311Dav8vJy23Lrzsv19fUAgDVr1mDevHkYPXq0pTPz0KFDMWrUKNTW1qJHjx4YOXIkpk+fbirk7NiyZQtuvPFGlJeXo2PHjigrK8OAAQMAIKMuRdi+fTuqqqrQp08fPPfccxnLZTt37sSkSZNQWVmJoqIi9OjRA2VlZdi6dav0+VatWoVDDjkEBQWZ3by+NLZq1aqM9/v27Zvxty6Cvv/+e6nzE0RQIeFDEDlIVVUVevfunXpl+3Po9OvXD1dccQXeffdddOvWDc8//7zpMU8++WQMGzaMy+ojy6BBg3D44Ydj1qxZAIBZs2aBMZYSRGZEIhG89NJLmD9/PiZMmIC1a9fiiiuuwKBBg1L+NWZ+OYlEos17F198MZ555hlcc801aGpqwltvvYU33ngDAJBMJqWubdy4cVi3bh1eeeWVNk7k119/Pe6++25cfPHFaGhowFtvvYW3334bpaWl0ucTxUxYMsY8OT9BeAU5NxNEiDEbzB944IGMmXp2bp5sunfvjoMOOgiff/655femTJmCYcOG4amnnhIvLCeXXXYZbr/9dnz22Weor6/HIYccguOOO47rtyeccAJOOOEE3H333aivr8dll12GF154Ab/73e9SFozsZI/Zlo/vv/8ec+bMQW1tLSZNmpR6/6uvvpK+pnvuuQevvPIKmpqacPjhh7f5/KWXXsLYsWPxwAMPpN7btWtXm7KKOFX369cPn332GZLJZIbV54svvkh9ThD5CFl8CCLE7L///gDaDuaDBg3KWGY68sgjAQD/+c9/DCOuVq1ahcWLF+Owww6zPN/QoUMxbNgw/OUvf8GuXbvUXEQWunVn0qRJ+PTTT22tPYAmVrItE8cccwwApJa7+vXrh8LCQrzzzjsZ33v88ccz/tYtH9nHe+ihh7ivIZ3m5mZMnDgRt912G84//3zD7xQWFrY536OPPtrGGmV2v40466yzsGHDBrz44oup9+LxOB599FF07twZQ4cOFbsQgsgRyOJDECFm0KBBAIDbbrsNo0ePRrt27XDuueemBshs3n77bUyePBnnnXceTjjhBHTu3BnLly/H3//+d7S2tmLKlCm255w8ebKlo/LSpUtRV1fX5v3y8nKcdtpptscfMGAATjzxRMyePRsAuITPzJkz8fjjj+OCCy7AQQcdhB07duCZZ55B165dcdZZZwHQfJsuuugiPProo4hEIjjooIPw6quvtskb1LVrV5x88sm49957sWfPHvTp0wdvvfUWVqxYYVsOI8aMGYOysjIccsghberltNNOQ3l5Oc455xz87//+L4qLi3HkkUdi/vz5aG5uToW76xxzzDEoLCzEX/7yF2zbtg1FRUX49a9/jZ49e7Y579VXX42nnnoK48aNw8cff4z+/fvjpZdewrvvvouHHnoIXbp0kboeggg7JHwIIsQcd9xxuPPOO/Hkk0/ijTfeQDKZxIoVK0yFz6hRo7Bjxw689dZb+Oc//4ktW7age/fuOP7443HzzTfbRl4BWqK8oUOHtokK0tGjuLIZOnQol/ABNLHz3nvv4fjjj8fBBx9s+/2hQ4fi3//+N1544QVs3LgRxcXFOP744/H888+nnJIBzYqyZ88ePPnkkygqKsLFF1+M++67D0cddVTG8err63H99dfjscceA2MMp59+Ol5//XXbJUMjdAvb2LFj23wWi8VQXl6Ohx9+GIWFhXj++eexa9cunHTSSWhubsaIESMyvt+rVy88+eSTmDp1Kq688kokEgnEYjFD4dOxY0e0tLTg1ltvxcyZM7F9+3YcdthhmD59OsaNGyd8HQSRK0QYea4RBEEQBJEnkI8PQRAEQRB5AwkfgiAIgiDyBhI+BEEQBEHkDSR8CIIgCILIG0j4EARBEASRN5DwIQiCIAgib6A8Plkkk0msW7cOXbp0EUoPTxAEQRCEfzDGsGPHDhxwwAFtNudNh4RPFuvWrUNlZaXfxSAIgiAIQoLVq1ejoqLC9HMSPlnoadxXr17dZgdlgiAIgiCCyfbt21FZWWm7HQsJnyz05a2uXbuS8CEIgiCIkGHnpkLOzQRBEARB5A0kfAiCIAiCyBtI+BAEQRAEkTeQj48EiUQCe/bs8bsYhGLat29vGQJJEARBhB8SPgIwxrBhwwZs3brV76IQLlBQUIABAwagffv2fheFIAiCcAkSPgLooqdnz57o1KkTJTjMIfTElevXr0ffvn3p3hIEQeQoJHw4SSQSKdFTWlrqd3EIFygrK8O6desQj8fRrl07v4tDEARBuAA5NHCi+/R06tTJ55IQbqEvcSUSCZ9LQhAEQbgFCR9BaAkkd6F7SxAEkfvQUhdBEARhTCIBzJsHrF8P9O4NDBkCFBb6XSqCcARZfIjA0tLSgkgkQlF0BOEHTU1A//7A8OHApZdq//bvr71PECGGhE8esWHDBlx//fU48MADUVRUhMrKSpx77rmYM2eOsnMMGzYM1dXVyo5HEIElkQBaWoBZs7R/c8k3rKkJuPBCYM2azPfXrtXeJ/FDhBha6vIBP6zHK1euxEknnYRu3brhvvvuw9FHH409e/bgzTffxPjx4/HFF1+4W4A0GGNIJBLYbz9qfkRIaWoCbrwxUxhUVAAPPwxUVflXLhUkEtq1Mdb2M8aASASorgZGjqRlLyKUkMXHY/yyHl933XWIRCL497//jVGjRuHQQw/Fz372M9x00014//33AQDffPMNRo4cic6dO6Nr1664+OKLsXHjxtQxpkyZgmOOOQb/+7//i/79+6O4uBijR4/Gjh07AADjxo3D3Llz8fDDDyMSiSASiWDlypWpJavXX38dgwYNQlFREf71r3+htbUVN9xwA3r27IkOHTrg//2//4cPP/zQ3YogCKfkgjXEylo1b17ba0uHMWD1au17BBFCSPh4iF/95ZYtW/DGG29g/Pjx2H///dt83q1bNySTSYwcORJbtmzB3Llz8fbbb2P58uW45JJLMr67bNkyvPLKK3j11Vfx6quvYu7cubjnnnsAAA8//DAGDx6Mq666CuvXr8f69etRWVmZ+u2tt96Ke+65B0uWLMHPf/5z/OEPf0A0GsXMmTPxySef4OCDD8aIESOwZcsWdyqCIJxiZw0BNGtIkJe97GZf69fzHYf3ewQRMEj4eISf/eXXX38NxhgOP/xw0+/MmTMHCxcuRH19PQYNGoRf/epXeO655zB37twMK0wymcSMGTNw1FFHYciQIfjtb3+b8hEqLi5G+/bt0alTJ/Tq1Qu9evVCYZop/I477sBpp52Ggw46CEVFRXjiiSdw33334cwzz8SRRx6JZ555Bh07dsTf/vY39ZVAECoIuzWEZ/bVuzffsXi/5xa57GNFuAo5WXiESH85bJjaczMjtZXFkiVLUFlZmWGhOfLII9GtWzcsWbIExx13HACgf//+6NKlS+o7vXv3xqZNm7jKceyxx6b+v2zZMuzZswcnnXRS6r127drh+OOPx5IlS7iORxCeE2ZrCK/vztdfa/5Ka9cafzcS0T4fMsT1ImeQ7hz51VfA009rZdTJFR8rwnVI+HiEn/3lIYccgkgkosSBOXsrh0gkgmQyyfVbo2U2gggVItaQoOXA4Z19vfeeJiAuvFATOeniR0/y+dBD5tfixnUbOZNno1utXnqJxA9hCS11eYSf1uOSkhKMGDECjz32GH788cc2n2/duhVHHHEEVq9ejdWrV6feX7x4MbZu3YojjzyS+1zt27fn2vLhoIMOQvv27fHuu++m3tuzZw8+/PBDofMRhKcMGaJZFsyyfEciQGUl8O23wcuBIzL7qqrSBESfPpmfVVRYCws3ojfMlueyCYuPFeE7JHw8gre/dMt6/NhjjyGRSOD4449HNBrFV199hSVLluCRRx7B4MGDceqpp+Loo4/GZZddhk8++QT//ve/cfnll2Po0KEZS1R29O/fHx988AFWrlyJb7/91tQatP/+++Paa69FTU0N3njjDSxevBhXXXUVfvrpJ1x55ZWqLpsg1FJYqFlDgLYPs/736NHAxRf7H/WV7QPTsyff7/TZV1UVsHIlEIsB9fXavytWWIse1dEbVstzRgTdx4oIBCR8PIKnv7SyHjvlwAMPxCeffILhw4fj5ptvxlFHHYXTTjsNc+bMwRNPPIFIJILZs2eje/fuOPnkk3HqqafiwAMPxIsvvih0nltuuQWFhYU48sgjUVZWhm+++cb0u/fccw9GjRqF3/72t/jlL3+Jr7/+Gm+++Sa6d+/u9HIJwj2srCEvvqgJDb+jvowsL+PGAaWlYrOvwkLN6XDMGO1fq+UtN6I37JbnzAiijxURGCKMx/M1j9i+fTuKi4uxbds2dO3aNfX+rl27sGLFCgwYMAAdOnSQPr7RUnVlpSZ6aFnaX1TdYyJPMPJlmTdPExl2xGLqoxh0dMtLdtee7q9j5rsj6x/T0uLOdc+apQk3UdysXyKwmI3f2ZBzs8dUVWkJT4Pk80gQhAS6NSQdv6O+eCK3SkqADh3aRkQ5mX25dd2iTo9+RZwRoYKEjw8Y9ZcEQeQAfufA4Ync+u47oLlZ64hUzb7cum7dOdIstD4dL3wGiJyAfHwIgiBU4XcUA69FZdMmPt8dXty6bivnyGzsIs4IYi8kfAiCIFThdxSDXxYnN6/bypm8tpYv4owg0qClLoIgCJXoA7XR7u1uRzHYLQ3pPjAnnqg5JKt0NHTzukeOBIqLtTIDmpVKhaWKyEtI+BAEQaimqgo45xzg8ceBZcuAgw4CrrsOaN/e3fPqlherrMujR2vlyRYnKrZ7cCN6wygUdsYM2p6CkIbC2bNwO5ydCC55cY+Dto2CF/hxzUaDtZd7SZnlzRg9Grj/fuNQd2Cfj0xQ2olVaH56eQkCFM5OEEQ2fg/GfuDHNZsN1l7uJWVkeTnxRM3SY7dJaSIB3HST/+2Ed1PVkSNzX7wTSiGLTxZk8clfcvoe5+PM2Y9rTiS0jMlmIeW6j82KFd4P1rxJBo3wo524lRSRyFl4LT4U1UUQuY5b2wkEGb+umXcHdD/2knKSNNGPduJ3MkgiZyHhk+NEIhHL15QpU1w577hx43D++ee7cmwZZsyYgW7duvldDH8I8mDsFn5dc5AHa6ch7G7VWfZmqrqwchqab3ZcIu8hHx8/8NBxcH1aB/viiy9i0qRJ+PLLL1Pvde7cOfV/xhgSiQT224+aRU4R5MHYLfy6Zr8zN1shkgXZCpV1ZuWDNXIkX2i+UVLEfPRnI7gJjcVn6tSpOO6449ClSxf07NkT559/fsYADmg+GuPHj0dpaSk6d+6MUaNGYePGjT6V2ASjXZP799fed4FevXqlXsXFxYhEIqm/v/jiC3Tp0gWvv/46Bg0ahKKiIvzrX/9CMpnE1KlTMWDAAHTs2BEDBw7ESy+9lDpmIpHAlVdemfr8sMMOw8N68jIAU6ZMwcyZMzF79uyUZamlpQUrV65EJBJBQ0MDhgwZgo4dO+K4447D0qVL8eGHH+LYY49F586dceaZZ2Lz5s0Z1/Hss8/iiCOOQIcOHXD44Yfj8ccfT32mH7epqQnDhw9Hp06dMHDgQMyfPx8A0NLSgv/6r//Ctm3bXLd0BZIgD8Zu4dc122UwBrQd0v3YS4onySAPixersaDoPljZljndCXz2bLmkiHbHdamvJUIECwkjRoxg06dPZ59//jn79NNP2VlnncX69u3Lfvjhh9R3rrnmGlZZWcnmzJnDPvroI3bCCSewE088Ueg827ZtYwDYtm3bMt7fuXMnW7x4Mdu5c6f8RUSjjEUijGnzl32vSER7RaPyx+Zg+vTprLi4OPV3LBZjANjPf/5z9tZbb7Gvv/6afffdd+yuu+5ihx9+OHvjjTfYsmXL2PTp01lRURFraWlhjDG2e/duNmnSJPbhhx+y5cuXs7q6OtapUyf24osvMsYY27FjB7v44ovZGWecwdavX8/Wr1/PWltb2YoVKxiA1LEXL17MTjjhBDZo0CA2bNgw9q9//Yt98skn7OCDD2bXXHNNqpx1dXWsd+/eLBqNsuXLl7NoNMpKSkrYjBkzGGMs47ivvvoq+/LLL9mFF17I+vXrx/bs2cNaW1vZQw89xLp27Zoqz44dO9rUj5J7HETiccYqKozbnt7+Kiu17+UKfl5zNGp8zvRXbS1j9fWMxWLe13s0qtVNenkqKxlrbLSus+xXRYV8n6XfH7Njp98fs/IanVvkuETOYTZ+ZxMa4ZPNpk2bGAA2d+5cxhhjW7duZe3atWONjY2p7yxZsoQBYPPnz+c+rmvCJwAPpJnweeWVV1Lv7dq1i3Xq1Im99957Gb+98sor2ZgxY0yPPX78eDZq1KjU32PHjmUjR47M+I4uUJ599tnUe7NmzWIA2Jw5c1LvTZ06lR122GGpvw866CBWX1+fcaw777yTDR482PS4ixYtYgDYkiVLDK/diJwVPoztE93Zg5pHotsX/LrmeJyx0lI+8eBUQDgpYyzWVnyZ1ZlZnyVbj7EYX93EYsblbW01Lr/ocYmcglf4hNaZY9u2bQCAkpISAMDHH3+MPXv24NRTT0195/DDD0ffvn0xf/58nHDCCb6UM4WIs6XHoZnHHnts6v9ff/01fvrpJ5x22mkZ39m9ezd+8YtfpP5+7LHH8Pe//x3ffPMNdu7cid27d+OYY47hOt/Pf/7z1P/Ly8sBAEcffXTGe5s2bQIA/Pjjj1i2bBmuvPJKXHXVVanvxONxFBcXmx63994ljE2bNuHwww/nKldOU1UF3HIL8OCDmUsUBQVazhYrv4egJLMTxa+tI+bN03ZA58XL/D46hYXG/YxZnRmh+91ccw2wc6e2lxZv2xD1wUovb1OTeebp1lax4xJ5SSiFTzKZRHV1NU466SQcddRRAIANGzagffv2bSJ3ysvLsWHDBtNjtba2ojXtYdm+fbsrZQ6yg+n++++f+v8PP/wAAPi///s/9MnaFLCoqAgA8MILL+CWW27BAw88gMGDB6NLly6477778MEHH3Cdr127dqn/R/au1We/l0wmM8rzzDPP4Fe/+lXGcQqzOlij4+rHyQmcCJCmJuOMvYmE9v4JJxgPumF3EnVjCwU7RJ9hP5LxWbWl9DqbMwe46y7rY23eDPzmN9r/eduGrA+WXXJIXt+9XPJnI4QJpfAZP348Pv/8c/zrX/9yfKypU6eitrZWQalsCImD6ZFHHomioiJ88803GDp0qOF33n33XZx44om47rrrUu8tW7Ys4zvt27dHQkH4aHl5OQ444AAsX74cl112mfRxVJXHN5wIEKucNjpGg24QMhCrwMy64RYyz7CsxVdGDPO0Jb3OREUcb9vg3Uw13QmcJ5PzM89olqd168QjwYi8ITRRXToTJkzAq6++ilgshoqKitT7vXr1wu7du7F169aM72/cuBG9evUyPd4f//hHbNu2LfVavXq1OwW3i/aIRLS9dHx+ILt06YJbbrkFv//97zFz5kwsW7YMn3zyCR599FHMnDkTAHDIIYfgo48+wptvvomlS5fi9ttvx4cffphxnP79++Ozzz7Dl19+iW+//RZ79uyRLlNtbS2mTp2KRx55BEuXLsXChQsxffp0PPjgg9zH6N+/P3744QfMmTMH3377LX766Sfp8niO0ygVmZw2+ZT00Gm+l+zfn3iifWSXGSJCQyZCVLQtiYo43rbBE2GWHbHF047XrAGuvlrsuET+4ZHPkWOSySQbP348O+CAA9jSpUvbfK47N7/00kup97744ovgODcz5ruDqZlz8/fff5/xvWQyyR566CF22GGHsXbt2rGysjI2YsSIlCP5rl272Lhx41hxcTHr1q0bu/baa9mtt97KBg4cmDrGpk2b2GmnncY6d+7MALBYLJZyQl6wYIFlGYwckZ9//nl2zDHHsPbt27Pu3buzk08+mTU1NTHGmOFxv//++9R5da655hpWWlrKALDJkye3qZ9AOjercIqvr+dz+Ex3IM8XJ1GjiCERZ2Oz39fU8DsJy9SnTISoTFuyi45zei0iEVsi7VjkuETOkHNRXddeey0rLi5mLS0tqZDk9evXs59++in1nWuuuYb17duX/fOf/2QfffQRGzx4cCryhxdXhQ9j9EAGmEAKHxUCROYYMmIpbDhNL2H3+5oaa6EhKmB1ZMWwbFsSifSSaRtmEWbZOI0EoxD2nCfnhA8Aw9f06dNT39m5cye77rrrWPfu3VmnTp3YBRdcwNavXy90HteFD2P0QAaUQAofFQJEJqdNrlt8nFrSeH+fHnZdW7vvMxmhpSN7b5y0JaMJm9dtw0luJupz84KcEz5e4YnwIQJJIO+xEwGS3tnX1oots/LkoiktDe8A4lTYObGeOLX4ygoYp9est6e6OsbKyvxLDinqLuB0OZMIDTmfx4cg8gKZ6BfAOHKntFT7Nz3HjNs5bYKK0/QSsr9XEV4vGyEq25Z00qPjOnbUnKEjkcxjue1ALJqbKVciEwmlhC6qiyDyCpnoF7PInS1bNNFTWwvU1wOxGLBihXHHz5OE77vvwruju9P0Ek5+rwuIMWO0f0UFgmyEqExbMkMXIFm5vlBR4b6YqKoCVq7U2q9VO86nyERCCBI+gjCjh4jICQJ7b0UGGZ5cJ88+C1x8sfWgK2vRcBoa7hVO00v4mZ7CiYBRKVh4BYgb8IhHmTQORF5AS12c6FmBf/rpJ3Ts2NHn0hBusHv3bgBtM0IHAt4lElVbo8hYNMKU5VkXD7LLNU5/7xQn23GozGbtdXJIM4wSOQY4Wz7hLyR8OCksLES3bt1Se0h16tQptS0CEX6SySQ2b96MTp06Yb/9AvpY8Awyqjp7UX+QMPpSON3Ly+z3JSXADTdo4sJNnAiYoAgWFZgJ7rS9/Syh7SvyjggLrH3fH7Zv347i4mJs27YNXbt2zfiMMYYNGza0yQ5N5AYFBQUYMGAA2rdv73dR5Glp0TL42hGL2Q98upgBjC0auphJJLSMwWaWJl0krVgRzIy5TjdhTSSAu+/WLEBbtux7P6jWrlzCTHDrbbSkRLsnVuI9qO2SEMZq/E6HhE8WPBWXSCQcbcFABJP27dujoCDkbm+6CLGz1PB29kaz6crKTIuISrEVRuwG3yBau0TgEYZOxaNsuewEd0mJ5oRvthwZ9ntDZMArfAJq0w82hYWFwfQDIQjVvic8yyn57EvB40zu5a7rquHx2/LLt4vHn02PYnzmGbnlTCInIeFDELlEIqHNcm+8EairA779dt9nsp29nT+I09DwMKPKmTyI8PhtAf75dvEK6UMO0aLPvLZIEYGFhA9B5ApGM++yMuCyyzSLg1udPY8jdI8e2uctLbk16OSqtYvHkqV/7pe1S0Rw55IzN+GYkDs0EAQBwDxp4bff7nO6tRp8nOTfscorA2iD4ObNwG9+o/kC9e+vlTcXyFVrF48la80aTcxafcfNPDl+5lIiQg0JH4IIO04z1DY1aWJk+HDg0kvlxIlZYjwj9GUQr8WPmbhzIvpydfBVaaFyy9qlMhM1kVeQ8CGIsOMkQ62ZpUhGnKRn8q2r05a3zMoDeLtdgJm4+8MfnIm+XB18VVqo3LR2+bl1BhFaKJw9C95wOIJwHd4Q4VmztEHbjvp6LcV/+vHdyr8TpBB3MyddM2RCnRsbgeuuy3Qmzw77DxM8aRH69NE+W7fO/zw5foTTE4GDd/wmiw9BBBGR5SfeGfVXX2X+7eZeRkFx+rVaBjRD1CLV1ATcdFOm6CkrAx58MJyiB+CzZD38MPDII9bf8cra5XTjVyKvIOFDEEFDdPlJ9zOx45lnMgdyK8fUdGTESVCcfltarMWdGbyiz8qp/OKLw+3EzbOMREtNRAgh4UMQQULGUbmwkG9fojVr9g3kTU3A73/PVyYZcWLn9AtoVhE9xN0NX5+mJk18OMFK9Dl1Kg8DPDuw+7lLO0FIQHl8CCJIyCbEO+QQvuOvX8/v85K9EakIVhmkdfQQd0B9pl9Rvx4zrESfn8kL031aevbU3tu0yR3/Fp4cOJQnhwgRJHwIIkjI+sbwWmV69gTGjeMXBE58NMx2LzdCZaZfGb+ebHhEn19+TEaJKtPJh81RyZmZcAAtdRFEkJD1jeHNJwPw+byUlakRIdkh7mVlxt9TuTRkZ4mxg9cx1w8/JjOfonT8ypPkFSryThF5DQkfgggSsgnxePPJbNrEV45p09RZDPRlkD59tOUtM1Rl+uW1sJSUADU1bR3DeR1zvU5eyGvJyhX/IiNU5p0i8hYSPgQRJJwkxOOJsOG1PvBkYBbFq6Uh3mtsaADuvVfeMdfr5IUiliy3t4vwg3xwJic8gYQPQQQNJyHCdhE2fm6x4NXSEO816s64TnLAeBnOLSMIw7Y5qhVu5p0i8gpybiaIIFJVpe1qLePAaRVhYxVt5XbSOZ5d3GWjyNLx+hqd3CsRZARh2DZHtSIoSTGJ0EMWH4LIN/xKOufl0pDX1+hF5mCe3Eg6Yd0c1YqgJMUkQg/t1ZUF7dVFBAKjkGXVYcp+hQQbXZtb+1rlWtiz7twLmDs5y+w15hQv6pln/zCv9gYjAgnv+E3CJwsSPoQjVAwAZsn3/BjQ3CLXBImX2OXx8XpzVC9Eevq5jIRfLj0bhDQkfCQh4UNIo2IAcHPHdCJ38DJzsxV+iHQvLYZEqCDhIwkJH0IKVQNAS4uWkM2OWIy2CBCBLEzq8VOk0/0kDOAdvymqiyCcYpdfJBLR8ouMHGnfOVPkinq8XIrJJ/zcq4z2BiMcQFFdBOEUlflFKHJFLZTp1z1IpBMhhYQPQThF5QDgZ4LBXIMy/boLr/j+6it3y0EQgpDwIQinqLTSeL0NQi5DmX7dhTev0JQpZFkjAgUJH4JwimorjV8JBnMNWopxF12k88THkGWNCBAkfAh/SSS0SKZZs7R/w9g5umGlsdtzi7CH/KXcp6oKqK21/g5Z1oiAQcKH8I+mJi0cdvhw4NJLtX/79w+nWdwNK40X2yDkMuQv5Q2HHML3PbKsEQGBhA/hD7kYbUNWmmBB/lLeQJY1ImRQAsMsKIGhB1B2YsJLvMr0m69J9WgPLSIg8I7fZPEhvIeibQgv8cISl0vLtqKQZY0IGSR8CO+haBvCa9zyl0okgDvuAEaNyq1lW1EoEpEIEbRlBeE95BNAuIHXS012u6SLblfCC891+rHsVlWlXWc+LvcRoYKED+E9erSNnU8ARdsQvHi9H5fZprTZqN6viuc6/dybjPbQIkIALXUR3kM+AYRKvI4QtNoKwwy7ZVuefFY815mL0ZIEoRiK6sqCoro8xKtoGyJ38SNCsKVFc14WIRYzt4TwWGh4rrNPH02MrV1r/h2KriJyGIrqIoIP5b0hnOJHhKCI071dkkReCw3Pda5ZYy569O9QtCRBkI8P4TPkE0A4wY8IQVGne7NlW7vd49Mdo1WWn6IliTyHLD4EQYQXPyIEeXcltwvlFrFWqSw/RUsSeQ4JH4Igwosf+3FZOefr1NZqy7hWy7Yi1iqe66yo0Px88nFvslzY7JjwDBI+BEGEFzciBHkGUbOEfZWVQDQKTJpkf04RaxXPdT78MPDII9bfycVoyXzOmk3IwYgMtm3bxgCwbdu2+V0UgiB4iUYZq6hgTFsg0l6Vldr7To9TUWF+nHicsViMsfp67d94nP9c8bh27Egk83z6KxLRriH9mDzXqaouwkA0alx/kYj2MrpmJ/eMCDS84zeFs2dB4ewEEVKcZis2S0qoW0vc2HpBPyeQeV6rcwY1c7PXyKQy8DO5I+E6vOM3CZ8sSPgQRB7iRz4gHcpnJQdvPiU9h5IfwpbwFMrjQxAEwYsf+YB0KJ+VHCLO4XapAwAtdQA5RecFlMeHIAjCj3xA6VA+K3FEnMNFhC3dh5yHLD4EQeQuvGHOfuQDIpwhksrAb2FLBAoSPgRB5CYiYc5+5APykZxIeyOSyoCELZEGCR+CIHIP0V3K3cgHFFByKu2NWT6l7KzZeSZsCWsoqisLiuoiCA9wM9zaSYRWjkdY5WxgE097kkkdQIQKCmeXhIQPEVhyJTeL27lURMOcs8mVes7Cz4j9wJDjwjbf4R2/KaqLIMJAriReMzM56EtQKmbdMo6sKsROwAUTb2DTpEnAaacFrvhqqKrSdrsP8H0i3IcsPlmQxYdwhBuDn+j6RFAHYK9MDjKJ7ZyKyhAI01mzNJ8eXgJW/EyC2sYJX+Eev13dOCOE0F5dhDSi+zzxoO/nZLSXk9F+Tm6UQRWxmPl1pL9iMWfnEdkDS2avp2xUHMMDeKs/+xICUvx9BLmNuwHtLcYN7/hNwicLEj6EFG4NfiJiIegDcH0937XU1zs/l14X2fWRXheiotIIFcfwCDs9aPYKSPE1gt7GeRARMvkm8hzCO35TODtBOMXNdPi8/ipr1wY/Jb+XuVR4wpxVbFPh51YXgqRH7NtRgASGogWjMQsHrm7BvJYAJPrJhW0nRHIJiKZkILgh4UMQTnFz8OMVAZs3B38A9jqXit0eWCqy+YYsI7CuB0tKzL9zAZqwEv3RguGYhUvRguE47uL+/g+0IRKZhogImVwQeQGGhA9BOMXNwY9XLJSVuVcGVfiRJFDfA2vMGO3f9GOrsECFMCNwVRXQ0GD82QVowku4EH2QOTh32hIAK0PIRGYGokIm7CIv4JDwIQinuDn48YqF7CUdlWVQCW+mXS9QYYEKaUbgYcPaFrsACTyMGwGwNgNDBHsH52uuAZ5/3p99LkIoMlOICpkwi7wQQMKHIJyiD35mOB38eMSCkwHY642b7JagvEKFBUrmGAHYKMvI32cI5qESa8wHBca0JdXf/MaffS6CKDJ576WokAmzyAsDHjlbhwaK6iKkqKlxPybYLhqEJ5IpG4oaMa6DykqxOuA9RsDqO704o8EZded1JFV6u6+t3Xduv6O6RO6laCoHkZQMRAoKZ5eEhA8hjFmIrf6qqfG2LLyDeJhDg53kNjH6rYpcKbzCNGD1rRf7rT/FxISPFwOwUXsuLdVeToSqinKJ3EsZISMzkclzclL4zJ07l51zzjmsd+/eDAB7+eWXMz5PJpPs9ttvZ7169WIdOnRgp5xyClu6dKnQOUj4EEIEMY8LzyAexHLz4sRq4pfFJQz1LZvoJ91SoRI7cVFb609SP9l7qcoi67XICxE5KXxee+01dtttt7GmpiZD4XPPPfew4uJi9sorr7D//Oc/7LzzzmMDBgxgO3fu5D4HCR9CCK+yEasmrOV2YjXx0+LCW98TJ/qbnddscLZ7qUg6mU6QhaKTZ0dGyFDmZm5yUvikky18kskk69WrF7vvvvtS723dupUVFRWxWbNmcR+XhE+eoKoz8TIbsUrCWG4ng6HfAylvfesvH/x+9Efineoo21lmUVdeCOQgC3Onzw4JGdfIu8zNK1aswIYNG3Dqqaem3isuLsavfvUrzJ8/3/R3ra2t2L59e8aLyHFEsqfaEdboizCW20luE7/zoojWo8fZedMfiZMfqsL+m1fioh4x/PuGOqBHD/MfuhVJFeRwbt57+dVXxu9b5ZYiPCFnhM+GDRsAAOXl5Rnvl5eXpz4zYurUqSguLk69KisrXS0n4RCnocCq08AHMcQ2C8MqC0G52+BkMPR7IN1b3wwm9Z0NY9q/HmTnNXokkihE9LthOOHRy/De2KfAEGlbdreSTgLBFuZDhvDlzXrmGcqsHFByRvjI8sc//hHbtm1LvVavXu13kfwlADlGTHFqqXEjDbwf2YgFMKqy3r2Bl14OdrkNcTIY+j2QFhbi/TEPgwFIiogfl7Pz2j0SjGkWoFF4CWugPumkaXcTZGFeWAhcfbX999asoczKQcWjpTflIMvHZ9myZQwAW7BgQcb3Tj75ZHbDDTdwHzevfXwClmOkTdmcOqa66TfgdfQFh58AV5R9mKJGnOQ28Tkvin76CxBl30DQf8ZFPyveRwJgrABxNhQxNgb1bBhiLNrgrK5su5sgh3OH0UcuD8hb5+b7778/9d62bdvIuZmXgOYYYYypc0zl7awmTlSXH8YNOASqXZXpr4YGd8rtWlU4GQx9HEjTBYYuIGox0T0hzomoz7Uqncjd3QRVmLs1iSLHZ0fkpPDZsWMHW7BgAVuwYAEDwB588EG2YMECtmrVKsaYFs7erVs3Nnv2bPbZZ5+xkSNHUjg7D35HvNihqpMRmd6aCArf4RwxeC+1rEz9bXXdcOhkMHTwWydjkpHAKECcfYMKloB/2XllHgmnmky4uwmiGHDDghhki3tIyEnhE4vFGIA2r7FjxzLG9iUwLC8vZ0VFReyUU05hX375pdA58lL4BDl0lDF1ZmWZBG1BsHhll9+qrGVljNXVseaJMVaAuOe31TPDoerMzTY4HZPMHrELEGUJRNqKHwUVJpLHUiZnIc8jJ1IXQeluuFFpQWxsDH7/EwJyUvh4QV4Kn6CvV6vsKWUStPlt8dIRnJ5/gwp2AaKe3dagGw5lUSHmrASGod+Pw+UcEaEmm7NQVpwEvbsRQsVSXEMDY4WFuffg+AAJH0nyUvgEfQqm2qxs1FkF+fp1BB0ydEuCnfhRdVlBb0a2GJhIVIo5KwNBIeJsbm1MyXKOjFAzeiTcGotD306ycWJ9jEbD0/+EABI+kuSl8AnDTsCqHVPTO6uJnE6mfk9BJRwyEoiwVag0XfZSeVulZ/I++XCkn3ZhbZQlDUwkC2vtLWYiY5LbvrpOk1un34bGRnd8wcPQ3XgCbwQCb/8TRF8ojyHhI0leCh/Ggh06ml5GN0YNt6egqjokBw4ZQxEzHGBU3lapavTJoTP9tPv8bNpWUJLDYiaqid0cn1Q3ZbceuTB0N64jOpGxumnkGM0YI+EjjavCJ+iKPKiho+m4UYduTkFVd0iSDhlXdal3/bYKV6NPKRTST7svssq43pI2FjOnmlg1bvjPuNVtqehugt6lWiKydG3V/wQ5FYnHkPCRxDXh47YiV2lVCG1P4gA3pqBudUgSPkrx5pgnQVDc1eiTJ3T2aYcixlV/wwwsZi4WUxoRi08QHnWn7jGhNnKIWHzMLipXIwokIeEjiSvCx21F7lUPEISe0k1UWrzc7pD0e1FXx1iPHq6dR6ZpcVWjTx6u2acdDb5Z9xjUh2JZprXV2ikZ0D5/4YVwi4acMHLwLF0XFmrOVmbknKe4M0j4SKJc+Lg9AHrVA4R+esVJuqCYNk37V0bkedkhueQw4aRp2Wpkn2Kas0/La/GZWxsL/CowY84SEgZZNKS3p+bmHDJy2C1dNzRY/z6ncgM4h4SPJMqFj5sDoFdmzpyYXgmgQuR53SEp9s9yvWkFxOIjkj1Z1ODp9veNkN2CIsiiIazZJ7hx8uySxScDEj6SKBc+bg6ATho9by+bb2vIqkSeHx2SxMhp9hPXi+9TTLPRUpAb2ZNFtbMqg6rTLSjs7quUOHOg6MweR7e6VN+QrSPKDZABCR9JQmXxkRVVIr1sPs0oVIq8EHRIVs3AE4OVDzHNVltHqMqeLKqdVRpUnW5Bob8mTmzbNKXEmQNFJ5rmJhe7JC4oN0AKEj6SuObj48YAKCNKRHvZMKwhq3K6diMJigcdkszl2zWD2lqPBhePUyhYNWd91/TRqGfNE2P7KpKzguNxzf+kpMT8HNmPuxsGVatmJyIc0vWJlDhzqOhkrVcBmFN4TxhSkXgACR9JXI3qUj0AiooqmV426BYflU7Xbog8lzskmcvnaQYVFWr1uqV28DBaULg5c1awqB+Kfny3Hi+zZtfQwG8R0runxkYJcaZA0TnxV8qz8V4j16NuOSDhI4mneXy8ToEq08sGeclGtdO1W6OQSx2S7OXzXmZtrRq97ltAoEG9CzVnzgqW8UPRtbObBlWzZieSAzMSYaysTOKxUPAsOfFXykvhQ5DwkSWUmZt5RZUTn6CgrSG7sUbAm1dDDzH1cYbl5PJFmoFTve5bQKCF2uJqzpwVHG+NO4o4UqW1RZuibKQUd7ch0shMCh+PM9anj3g5ChFnF5XFWKJOO168NZ7vhpC8gYSPJKHdq4un53PSywZtDdnNNQK7qXAkwlhNja95jZxcvuhvnQac2GgH9QMRh9qybc6clbTg/uaUX9BQxGy3tjBbfXZiUJW1qMXj/PvzCrc1EbOiReF5fc30l5GT+trCioz91nIx/Rih4Yrw+emnn9i8efPYokWL2ny2c+dONnPmTLFSBpDQCh8enPayQVpDdnONoLHRPv2tWf2pNGNY1LeTy/dq9VK5NuVpfwJqy/JwnBW8c/9MT+ZvUGG6qaldVJeMQdWpRY33HpWWCrYXnkZWWmr7HIn4+ZhtNqunKtDvSx4GO6khSP2/CcqFz5dffsn69evHIpEIKygoYCeffDJbt25d6vMNGzawgoIC+RIHhJwRPnqIycSJ2qu5WXsviMtWMqgcVbMf6OZmcdGjWjXYTOOdXr4XzUCpNuU1a6hqF5zHSdoMsukvKwOpjEFVhUWNZ3W3AHF2XlfNqjUsy6rFFdWVdfAktF3vk2bCJ63wsWZrC1p6Ga02m01kbTbrqmtiCASCML456omhXPicf/757Oyzz2abN29mX331FTv77LPZgAED2KpVqxhjJHws8fpBiEaNZ1OlpdpnQVu2kkGV2cKoLqzikXlfTqLc9g4Y2YNqMm2UcWuJRGUzUKZNRcwaqtRWPM5+LDXP6Jw0ED1mg2xJyb55h80phboJVfVr5exstHSUbtWybS8GjWwVKtlE8K1hxZtjXFFovFuPDEVM2WPKe71BFAhCiJoVfRR+yoVPz5492WeffZb6O5lMsmuuuYb17duXLVu2jISPGV4/CNGofQcQjebGrMSp2UImHIf3JZvXaK+iMRtUk9inaFRYbdxqBjI5bazqw7Kuy8r27anGa62zGfHiccZ+V2qc0dnMqpD9GoaYsPVMvx+WW8Xt/dK7E/j8iniaYjTa1pHYbOlIt9gsrI3y5YxqiLNhWX5QvJvDsvp6rig03uONRr2Sx9S0En3x5HcRUbOiz8JPufDp0qULW7x4cZv3x48fzyoqKtg777xDwicbrx8E3lSnFRXhFDpGyJotnKaFdTiwmsI7jZ82jbH6eja3Nsb69skc+Pw23vFEDOmPRXW1jeASjWmuqJBwSDE/rZHFYzMslmjSXuNL6oXug1W9pcYOgy9Z+RWJNMV0zWi3dMRbj2aPGa+FRi+8Ud2Ulu4zbPtu8fHNk99lRMyKARB+yoXPcccdx5577jnDz8aPH8+6detGwicdPx4EkUEil/K5y5gtnKSFtfvcwX1N1IlnbUtWVLCFtdFAGO94jWjZvuOmk0LRLHbpJ3dgCks/bXpG56GIseHgsyrFm2NK660KUc3il/WBmV+RaFNMv2ZRYWKG2WMmsjmsjtFjrr83qy7OdpZVaMvBBsdz3cfHzUSvflrneZ+/urpACD/lwufPf/4zO/PMM00/v/baa1kkEuEvYUBRJnz8yHgsMkiEagc/F+Ctq+y1mspKLZTdJc/gBdNiYgO9ovOqgMeI1rmz4CXICFQ9Yih77UbAFGZ1WplBO7ue0sex1lb7epNx3hVtEunXLLIUZYXVY6Z8c1iTNTFPorrcijL122dIxALN8z2XJ9yUx0cSZcLHjz2u8tXiIwNvXTU3m6e/dcEzeFad9aBq5vsTBFO6k0y7ppfAE3Ykeu84sDtt1d5Bu42FwWZUNWo2ZpmR0y1NN2Ia1zXrSzkyTTH9mt22+OgvlZvDmlXwmsLKDGuYK0vBbkx0A7B0xB1FUVfHd/0uT7hJ+EgSaotPPvr4yKIiLEqBCdookt50JuxBe3JySU72Vkp/TZyYdW6RPRYUdrJ2zuPza8TEr4gvvaEg4Hi9O6He0WqIXsZCh1YtHZ7HrF9FXFsWFGh0lu0060NPMjerTo4VJJ8hnigKRUEFTiHhI4lyHx9VD4J+TLsnmDeqS+Z6wh4Flo3POY2MZv99+mirNFWSA5+Twd6pVd2pxSf7lXFumT0WFHSytoY9zudCxJfeLJrK1WtOuw7dYd7RUlTW8QoRN+0Ka2vFuhO/V38sC6aqP/Fj4myF1YNgFBKoYryTgISPJK5Edal4EESedrs8PjLX4XVP45XQsnqgXSyDlRVb/3+hxFKHbEeowqruZFXKrK/MOHc8zhZMi7ExqGMbUWZqjUggwnaWqetkVTQD3nHMzpfHlaVOg2dAd5h/pzrKdpYJLkUZHO/H0gr2u1LzyDPe7iQIqz+2BVSxBO6Hq4QdRg8CjxkzzFFd+YIneXxEHwSZp90sc7NM+b3uaVQJLd4Ry+yBdkns8VixS0szv1OAOFtbWGEY1ZP6UUWFdp8FR2iVVnU7rW8Vac5zbn08MLNG6O+9U+33CJgJ7zjG7Vuj6lnkeb5FniOzzbUimj/Ui5dwbOdhcr4grf5Y4qVS9tNXU8S1Iqx5fPKFwGVu9vNp9+PcqoSWE+HistiT9qtutFAVQFsrH+f1qu5j7aziMu46+rnTy2rkB7MKmiMrV1k9XL41quPsMPkCxNlVXSQcpWS9dVUrXpvljmQkwtYUVpomXIxEGLuqNMqSWWXaWVbB3qmOqgkcCsuSvRuuEqoR6cg8wlXhs3TpUvbUU0+xO++8k9XW1ma8wk7g9uryU/l7fW5VHbET4eKB2HMUAGGWyc2srBxCzQ2rutX4IuOuo587ezzIFg+FiPPdHo+Xb7PLbbaL+J5JJhaT7NfeBJaOBm9Vz7eI1zbaJhHUX7oVT2T/M6F2GljnIGa9jOSTD6ItAVyOc034PP3006ywsJCVl5ezgQMHsmOOOSb1+sUvfiFd4KAQOOHjZ+PiPffEiWpmHio6Yh7za/oWB9nldlnsRaPm4cvcp0jvJJubHQs1vwIQYzGt6Yie2/F44JOjiH5aq60gGKAk8zQXEn1Lm/G5lXO5I+2VvW0EIJ6nSLidBtk5yEqQuZQ2QwkBXI5zTfj07duX3XPPPdIFCzqBEz5hsPikP6hOUCHyREOLssvtotDknRgLjW2c1xtvjplaYPy0qsueW3o88NlR5A832zkvpzlCuT3TF+xbjOr8wh6cx0h7GVl8eH2bbsQ0y6Uyw1u3954HMgeWSh8rrwngcpxrwqdLly5s2bJl0gULOoETPkEelVR3yipEnswWB+nldkloioQzC1Uj5/WOL8mcZWfrPT+t6rLnlhoPfJxIxOMCQqG21vWZfrTBLlnmvr7FbHwew5vhGft8fAoNhAt3pmgY701m2VYCaJlgjPkuwpUQsOU414TPFVdcwZ544gnpggWdwAkfxoI5KrnxoKoQeTLJZNKP65LQ5C1WWZng7eQ8cPYs26jpSFlRFM1GPbPo+7h0HIsJbgXh4kxfb+Z20XHxxqjl+CwUhRaJsPk1UcPuROQ4Rj4/Vm3lg+rg+aIwxoIryEQJ0HKca8Lnz3/+M+vRowcbO3Ysu//++9nDDz+c8Qo7gRQ+jPnbuES9UZ08qE5FnpNkMnq5XRCaInv9CWFzvVa+EUYaTmSsjTca5HiRXPJUkX2Bq+weDzbpZZo4Ud1WEE4RiY6zqjLbfcsM2oVRd9KugPM4ae16e7dKNqsubhthz21l81pgBNA5WJqALMe5Jnz69+9v+howYIB0gYNCYIUPY/42rnic3xPV6YPqVOTJxkynl1ux0HR1vDW5Xt5oGJlzzq+xcNA1EIeiUV6i+on7GB4uHRuVyU4oqE6+aEb2mGsUWq8/Enbjs7nVaG/CRYPUzOntQQ9Tl9qqxabxxmI8da6FzHs+WOeKxSdAUB4fSQItfPzGywfVqciTiZnOLrdCoen6eGtwvfqsXUTvcZ2qgcNBN+1i7IJWnAbbCB/Dg6VjK0d2nuUltxF5lHm+a2Y1uqo0atum04WV8B5lnLvD24mqHR0ks9o7IYDOwWHHE+GTTCZZMpl0cojAQcLHgrA9qLpwqavTnGd8Lrfr4+3e6134p8xZu0qdKrp0YCdKzFIQ8d4Waf9QF5eOeRzZzYTC/BpvBl+RR5l39djMamTXvrKFVQHiyrZoyV7S2wzjBpeAllnac/ETMOfgFAFZuhLFVeEzc+ZMdtRRR7GioiJWVFTEjj76aPbcc89JFTRokPCxIagPqh0BKbfbrlrRKGMlJfwTZlG9J+Kgm6irFza6iY5tjoyQLnXuvGVKFwoXlcVYtMHbwUXkkZBdPQbsLYpGwspueSrbqmh17B490o/Zh9tS6RkBcg42LU9QEj3a4JrweeCBB1inTp3YH/7wBzZ79mw2e/ZsVlNTwzp16sQefPBB6QIHBVeFT0hVdBuC9qDyoqrcDu+jW81AMIEuA8Qvvb6e30F3wf3NjkWP3cDpxD/UrfsgkvfT765A5JGQWT02FZ0Gx85uu1ZLgknwT1aqq7WfeuJYLtuogjI2BDnRIweuOjfPnDmzzfszZsxg/fv3Fz1c4HBN+IRYRRsSlAdVFDd8hwJwH0XyBAGMFRYy1tAgfh4eZ1H99UP3PtzbDMiOQ7IWHzdvYxB9Vq2avVAkX9p39aTh2ZYa3Yo1DDHWryLO/YhFo/usM+nixyzijPde6fdDKJWADKKNKmh9aA7kFXJN+BQVFbGvvvqqzftLly5lRUVFoocLHK4In5CraFOC9uC6TYDvo2j6osZGufPofWMVRwROUnCPJZl+VsbtzO3bGDRXuOzxuABxdmGPmJbfxuFzm74EZiRSfiwVU5OtrW23dDHzHeKtQ/1+DHPT4iPaqII0gdL7cZn9YwKGa8LnZz/7Gbv77rvbvH/nnXeyo446SvRwgUO58HGiooMsLIL04HpBwGdDvMsrpQqCV/Q+voojAscuj5Du3CztehWPs7m1MTZmr4XB6Dzpli2vbmNAXMrajMeGUVMOn9tolLHflRqnN5C54GiUXxzzjsHRKGOFdpZK2Zsv2qiCNIGSWb8McF4h14TPSy+9xAoLC9mIESPYHXfcwe644w42YsQItt9++7GmpibpAgcF5cInSLZ4VUIqSA+uVwRx/UKieM3Nas6nN8/haOY6sdmO3HpIu5TrlcEPjbYzSH9svLyNfrvCZY/Hppujcjy3ll1HPM6STvfCyjrB72/gi0gUGYMzBZpCRSrSqII0gZJxCvSxj+PB1aiujz76iF122WXsl7/8JfvlL3/JLrvsMvbJJ59IFTRoKBc+Mt6Xdg3SICGYLaqEVJAeXC8JeJZVP5ZX4nHGFk3kqxejHblLS/eVR1iTmzwjRkkb08c05Y7HNgX302ibPh7b7X5u1UBsuw7Ogb9xfIzV1RnUg8EJdpa1FbAqxuB4nLGFtVH2Q4lCRSrSNwRlAiXqFBiSvp0SGEriu8WHt0GKiBaVFpqgPLheE4Lr9mV5hbNezCw+UtUVj1smADJaXtP77GY+A5Xto2Y6gIpOJtJzTU2bxlhdHYs3x1isOe5YLKWPx7IRTVxdB+fAny5+U9VkcoJkRBOwVSbix/EYrFKRivQNQZlAiToFhsSar1T4pB9k27Ztlq+w45qPD+9UXKRB8jRE1RYapw9ukP2WrOAVpDKhUgrxfHnFpn1b+fhI9++1tVxt0EhsGUUiifb5ynxaLPwr0pfsZFe407sSmYgm7q6jOcZ17Oz7UYi45vxs8v3k3raTvZt74MZgkT5edFnMrb6Stx9X3Ym43P8rFT4FBQVs48aNjDHGIpEIKygoaPPS3w87rkZ18UzFRRokj2hRbalwcjyny21+i6bGRr4OQrZciq7P82oyad88e4UJ9+/xOHeGRqPltYkTNW0qmoxPf9QaG9OdZMWey/TrXFgb1XxrTI6R2Ft/FyAqPdCnj8cyFh/uR71ZTvzyRlld2CPmyhisFN4+nlckNTa6GzzCe3MnTlTXiXgQEKNU+LS0tLA9e/ak/m/1Cjue5vExeoJFTZBZnVUbVJtWZZ1JnC63BSGKzM3lLrevz201ZFD+NYWVtksVDQ3Gl93QYFJcgefDbHmtooKxmhq5ZHxlZXIiIr16bP1t9r7SBYOEfzCLx/c9djIRTUJdh4T4FckAHgojMW8fbyeSamrcDx6x68f1xt7a6vxcjHkWEEM+PpL4nrmZp0Ea9jwmuDFYizqTOF1uc/rQqBr03Vqfl7w+7svySjRmFSjaEJfq341eqeJy3oPNKDVdXtPP39i4r7i8KUxEBmy9HWTfXm7htPeVLuDMHlOrW6x/ZrpRp0k7E+46DAphtVGuJ5mUvYb3oTQTSUYzAZG+UgSzflx1P+FhQIxrwuf1119n8+bNS/3917/+lQ0cOJCNGTOGbdmyRbykASMQe3WJhhladQxuhfuIOJM4EV8qRJOqQd8NESl5fUaX1bePltPGcMpvdFwPHCWiDVqyvPTkc2aWfKuXXty5tTGuH0xEre3xZF3rRAZso9vLLZz2vtKX7Iw0Nc8t1sfjd6qjbGcZ33Mr1XXE42zBtLbJBo1euuUrqTqvTlgwEkleL0HZ5fFR0U94GBjimvA56qij2P/93/8xxhj77LPPWPv27dkf//hHdsIJJ7Bx48bJlTZABEL4MKY1tD597EcDno7BrXAf3tmNE0uJU58ilYO+GyJS4vqMLssoMV2yTwVr7VrqLL+KE0zClOONUakVXUATd0mLe5AE2LcF5tYes2rlubV6RmGRDTSNrlOlxUdKNwtYQGW6Dt44gEiEsatKo/vyCKnsm8KKqNOxCouMUbpslf2Eh5Fsrgmf/fffn61YsYIxxtjkyZPZqFGjGGOMffzxx6y8vFy8pAEjMMKHMa2hmUWwiHYMfmZTcyJeZB8at8yrqkWk4PUZXZZZYjo7HxLLeneKjeh8p1p+D68XL7E20ccbo9xLV0bps8xurb4KEYnYbKCZ1g6Mbq9KHx8lk+ksIRRvjbNYc5w1T4yxRRPrWcuUGOvbJ1NI2nUdPEbrVDUZ9U1lZdruooF26nEBP8LM3bbI5ILFp3v37mzRokWMMcZOOukk9tRTTzHGGFuxYgXr2LGjRFGDRaCEj44q0eJXVJQTS4nsQ+O1I7KsiBQsZ/bXeQdR7tFfBRyic2eZeYg7z2t+jfU9kL39drc2XRwZ702V2Q7MymEmVvUXb1SX48m0wQV/V1DKNqM067oq2MLaqFDXYbWK0uZx0fum6uq21odc3gonGxkfz6BbZNxytzDANeFz7rnnpraraNeuHVuzZg1jjLE333yTHXLIIXKlDRCBFD6M+R/K7RRZS4nsQ+PFw6zifgheX/ZliS6bcI3+TuFUHRf2iAn179kDZ7zV/B446Wvtbm12hNZQxNj4knrN/8gghN2sHIb7Zu19pTsFW2lqR/reLHng3lf6ewlEtCU8QQGi12Vafkbzx8Vnf7TAwON0rPI59sIi41F2VdeEz6pVq9jZZ5/Nfv7zn7Nnn3029X51dTW7/vrrxUsaMAIrfHIBWUuJnd28pqbtbzw0r1rBpY8EOoXsyxJ1lOUe/Z3AKTo/qK6X6t95b52bfa2I7rUqRyH2OqRLZm5OF1ZGu5ib3mJeR5xs8VPhkk+Yh5E/ocDO6djoFXSLjAfuFhTOLgkJnzTcsDLJHrOmxrpTFA2h118uZloWCiiz6xT21luirp5d2COWymbLa/FpszElXJxFC4hOmf5dpJ9X0deqeAzcLEc0yliVgfXoG1SwKkSNzyHrXc6jOGUIyEQlUOg3nNdhLQQWGbdXLlwVPolEgn355Zds3rx5bO7cuRmvsEPCZy9BSBioIzsbFMm0rPiBlLLaW41sJruQ20UYJRBhm1DKvkFmhODOMhcd2wVnkNmXPXmy2n7eya1V+RjwpvHibAIZ+10lDZ3b2y5P6cd/d4IDS6Eb+0j5uYdV0N0Icsgi4zauCZ/58+ezAQMGpLapSH/RlhU5QlASBuq47eBcW6tU5Cm12u+9F0Y+F7rzq1WEkf4dfRlkDOrZRWVa5I6rOJhBxuPWmRyU9PMcbdRrlxMzcWOVyNduv6v0yko//nA0ywufXLL4BGmCZ0VDg/n9DZFFxm1cEz4DBw5kF110EVu8eDH7/vvv2datWzNeYSfvhU+QEgbqyM4GRXNiKOpQlPXhe++FWR6e9HBnI0fZ7Ky5nvuIOphBiugm4b6ao406egyMwsNtymclsqzaEO9+V3NrMx3JZYSPJz4+NlaN1p/ibNo0xiZM0FyiHO2oEBZnaqHwuPzGNeHTqVMn9tVXX0kXLOjkvfAJUsJAp2Vy4sdgO7qZo8xqz1l+PcGdbtVZNFGLMBLNvSICt9hwMIPk0U3COpuzjUo/BgYFWltYkSFAs8sn4WecevE6t48vqZf6nf6SjeoSwkbtzhwZZYWFmR8VFhrHNtgSFmdqu8COxkZ/yxcwXBM+w4cPZ6+//rp0wYKO68In6KbEoCUMTD+26Bq3TE4MrtHNGlUWn0Qd373I3oVcvzVuNTUvVwesrkFYZwu0UanHgGNZ0qh8TvQ5r3N79oatomkQsvMTSd0wHkzU7syR1gkvhcVPGJypwyLOAoRrwqepqYkdeeSRbPr06eyjjz5i//nPfzJeYcdV4ROG9eQgJgxkjG/tw6jTtfodb8cv6FDJo7cqKuz7qwXT+Oo0e1Bzs68OyuqA1Jgg0EaFm7PAsmR2+ZysyPLsd/VDadtkkTzbbuzsWsYW/UkLr5fOWCjTv2U9x60/xdtYerJfhYWCy15+OlPzEgZxFjBcEz7ZDs26UzM5N9sQlBHDDq8TBoomRDFb+7DqdM1+Z7YdiFnHIlBWuxxkpaX2t3xWnX3EltlgaojD2XiQJqBSY4JAG+URrxnXKrgsmV4+JxafSMR+v6uFtcbWEtHd2i1xsX+bNo2vLqZNEzhoGERFGMRZwHBN+KxcudLyFXZcET5BGjHMypc+IDY2ikfkyHQkMjNEK6uOVadr9DsRkSdR1miUsZIS80O3qcqsMsaa41wRW1zji4LZeJDGCqkxQfACRPJmOlmWlF2RzbjnFpMCq+MbZo+WSTDkYv82YQJffUyYIHBQr0LEnRCkBy4kUAJDSVwRPkFuwFYxtCIROaIdiaoZooooNDuRJ1nWxkZmaaLPKJrBfUhWVLDflUYNk9NlR2xZjlUm5U9mbahpB4/YKIC2uaVIRJMMUo+UxGDHmzfT6bKkfosKs7IvF+7Nvsz1OFpY9KyaeSp7tOxNcrl/c8Xiw5h3SftkCYM4CxiuCp/nnnuOnXjiiax3794pK8+0adPYK6+8InO4QOGK8AmqydJuQG9o4Fsa0Tvc6mrzBzS9I1E5Q1TR6VotoUmWNRrlKxbA2MJa8/uQRIRVIWo4IAIcG1jblD+BiOa4ylHXdlVtZD2wi2iSJR5nrG+feJstGrLL1CYxt8BgZ1R16dtCDEOM9auIs3hcfFkS0JY706t9fk2UrS3MPOHmgjK29JxqJSLStfx0Lvdvra1tJxDZ23O0K4jLhbYHPWlf0MVZwHBN+Dz++OOsR48e7K677mIdO3Zky5YtY4wxNn36dDZs2DC50gaIvLH4qBIfRh1Hdi+V3ZGorA9Vna7ZbFmirCLhyQWIsx9KrO/Dj6WV8qHpnOWfW2tf13ZLJka7jQsvyfESjbZJ3Kdns86upzZNmHOwy646I2H3DbRdy2Mxc5+Z7DpIf6VOaRIRlvFSoBpdifTzoH9Lt7wZ3YfvOzuom6BH2gZdnDEWmDp0TfgcccQR7OWXX2aMMda5c+eU8Fm4cCErLS0VL2nAcNXHJ0gmS1WWEjOLEWBujlA5Q3S705Uoq4izKm9Ycbw5JtevcJb/6i711jtn78VoArovQsj42MJO2HZwho1b3nqOjjq96qyEXRIRFm+MsooK4z2zspcl2zz2rQJKOYizfI/6t5oaxkYVGN+HnLeABERYGBKgaGXXhE+HDh1Sy1vpwmfp0qWsQ4cOEkUNFq5Hdflpskx/eHg3vjMTH04sRirFitudLm9Zm5tTPxEJTx5f4vIyqES0kV2fld3PyeaSkdKiHEt32UtKTqvOTtglobWxaEPc0E/HaAku/cXrH6RSRCjHi/4tHmfJPuYpAwJbN37jpmgKWLSyqxYf3ZcnXfg88sgj7Be/+IVEUdXz17/+lfXr148VFRWx448/nn3wwQfcv/U8j49XJkurtOcy4sOJeFEtVtzsdHlDbtLUgojFZ+7kZmf3gaP8P5SI+Z7wVFt6X/rShc4SLfLcAv1cMk7E6VUnMgbot553WwgWi0k9ZjIbhjZPjAVu4u96/xZEl4Gg46Y1JoDRyq4Jn2eeeYb16dOHvfDCC2z//fdns2bNYnfddVfq/37zwgsvsPbt27O///3vbNGiReyqq65i3bp1Yxs3buT6fU5mbraLy5VptE6Xq1SLFZWdbvY9amgwLqtJuXm0UmEhY+/eHLXejVNR57GwVtz3RMTFi1cYyFh8sm8r71YLo1FvGEgoOgZEo4yN4d3eYW9b15sPr1FVyOKTdn0qxzBluNm/BTVIJAjIpvlwQgCFqKtRXXV1dezggw9megLDPn36sGeffVaqoKo5/vjj2fjx41N/JxIJdsABB7CpU6dy/T7n9uoS8bTlfTDicf4YU9loKtlrddrpWoX3C4gUuwSG797CIUYVdVDxOGO/K+X3PeG9fXrTsssCLOvjY9Rv8y6rDUMso+qcjAFza/nOmV1Z3IbNVg6lnPXSRWSuu7ZkEMCBNhAY9Vl9+mhhgxx9lTQBFKKe5PH58ccfuS0pXtDa2soKCwtTztc6l19+OTvvvPMMf7Nr1y62bdu21Gv16tVcFRcaZNLCWokPXls+74Pl5gxR9Nh2o+OUKUIdr6mua+AUowqn89Go5nsybK/vyXA0s+FotvVDseqz0puWaEST3WWZ6XVekdWvIq4ue0JrK0sWFlpHXJnsmcBt2Ew5bFuLH7OlybxwbQlikIgKnPSBMtZ8g75KigAK0bxMYLh27VoGgL333nsZ79fU1LDjjz/e8DeTJ09mANq8ckb48KryiRPtHzzehywI01DRdQ2e0dEsDbOFWjDs0yQcplVWiVlYtpH1x6rPym5aRsc1sipl568xwqqKzERWcm+E1cLaaMbxHffPDg/AbdiMRi1TG1gtTXo8vvhHEIJEVOLEB0fGmm/RVwkTQCHqmvD59ttv2XXXXceOOOIIVlpayrp3757x8hMZ4UMWH85eU+QhE1mucsPiI7OuIWMZk61LlSZiwfqLN0b3CgTrQZWnzzKqsuzEcmaWJKdVJLLVguPqVnC/eG9TrFmrvwdQzTaiR8bx7ZYm88a1JQx5bXhw6oOjos9yqpYDJkRdEz5nnnkmO+SQQ9g999zDpk+fzmbMmJHx8hOZpa5sctbHx6kq533Ipk0Ti8ZSHXEgu67BO7iVlHhXl3adkmKrlr6Mom+TwLscJWNptxukeaqoAHHNMbi+XrOONTcbKgu/LT4ipNcpr4g0PH2Q876oIOzXpyIiSiRvhmxfxUOAhKhrwqdz587s008/lS6Y2xx//PFsQtpudYlEgvXp0yd/nZsZU6PKVTuyuRVxIDtI8f6uttZ5XaoQoy5atS4qi3FXv50Tt6xGEKoiGwHouLr3HiDpkUlftE7bnD5ACeXyChExpkJMy1p83LDGBESIuiZ8jj32WDZ//nzpgrnNCy+8wIqKitiMGTPY4sWL2dVXX826devGNmzYwPX7nBQ+jDlX5W4kHbQ6TlmZobOoLbICTWR0VDHDcSJGbeovGYmwnWWVbFZdPLMP4qybRJ3YmolI7hoRjcBVRZwC0Kn2n19j5lcEV0z6IjEERk7SbdqE4Ia0hCCiYlPFRJKnzyotVWONCYiwscM14fPvf/+b/frXv2YtLS3s22+/zfCPCYpYePTRR1nfvn1Z+/bt2fHHH8/ef/997t/mrPBhzFnjVenIxiuievQQf0CdCDSR0dGt0HmeTkkwG3Oq/+X8Hc++XdmkV0dt7b5qkxEZ3FUkuFwgW916s7gAUbYZbUOEd3UudUVQZDSx5jiLTY6x8SWZy14Z5edYyuTdkJYQwE2fQp7lbrs+y2lfFSILomvCZ+nSpezYY49lBQUFGa9IJMIKCgqkCxwUclr4OEWVI5vI2rToSOlUoHm9Xs3TKWV/p66Oq+70JHep29NgXTfpPj5OL9fNfJKpKpIYPETHgHQtoUWTwXi/LjetKQaV+UNJBVs4uYHFm9MuprnZNWErRUisBI6Q9dUR7aes6tLNPsvtJIiKcU34HHfccWzw4MHshRdeYLFYjLW0tGS8wg4JHxtUPGQia9My/hNOBVqQOmyj+i4r46q79EzJqWpsjLJkxDrfjiqXFder0YMEanpT5d2vS/lFRrX7ZZlDSH9xplsYX1K/r5hu3aQQWQkc4YWFmacu3biPKhywPcY14dOxY0f2xRdfSBcs6IRO+PgxSDs9p0w4kGjETBAtN6JYzbYs6sooyV16Nf5nMl++ncDnhfEg2krXVrwZo5VWWjzOfiw1F1uyr6GIacV0S5wE1UrgxjOqYuseq37Kr7qMx9Vk5/cY14TPkCFD2Ntvvy1dsKATKuET5lmVaMZRmVm7yo5O1NScfh9kyiGZnMwuyV11tWYY4AmVDnxeGA8SqOnainePMLtKE2kK3FtlpL2Se19mbUMXxO9UuzSg+mUlsKtYt/pKFeLbrOx+1aVItELAOgrXhE9DQwM78sgj2fTp09lHH33E/vOf/2S8wk5ohE9QZlVOxEU0yr1s4+uswqrTtLsPNTVyHa6IA3ja3zz7b/G+0qvcM8Oi6IlcTqCmjz0iO7RbFZW3KcTjjI0vkc/TYuSHpAviAsTZzjKXBlQPcx6lsKtYN/tKN8W3X3WpOjeFh7gmfPSNSdNf5NzsMUFZe1Uxi2ptbTN4+3ItZtgtN1ltBGh1TXYdLq8Jva6OsViMJerq2YU9YqzQIsldYSF/8Zzuai5d1zInamho04Z2llWyeOO+3znV54U2e4TZtVPRsTcWE1heM3h9i0x/H10QRyKMXVTGedxp08QrTKTdqsCuYhsa3O8r3RLfXm8CKmpl9rtvNsA14bNy5UrLV9gJhfBxcybAO0KonEW5PGuXRnK5SUmnIXGPrapRtGhuTpYNm5jsiQzE0kaUsVFozDDKORVu0ai2w71RLp/Uq7bW8H7KzFPq6+03ZLV6/RrNqQ1p9aVMvSo/qJawJPFWmJupKmQq1qlFWaQ/VO1T6LXFRzToJJ+iunKdUAgft2YCvCOEGxYnr52ReZDNjCryMuu0WlutO22TOjarxupqvuKUlGS6Jnlxm/v20Zx4hU+0VyyZ7TtWZbHkJ9Nvx+OMLay13kjU6HmRGb/035hvyGpdV9GGuPnjJNOuRSIieQMXnA6cKp9Po75SVDGrXg/2wIctA5E0I1Z9s49RsUqFz+zZs9nu3btT/7d6hZ1QCB83ZgIiM263ZiJBCiNnzNleOKo7XIFByKgaeW9Z+obwqm+zWROT8p/ZOyjwOPJaVaPUuBGP78vSyHFvZOYp6WOe0Yashk7MWec2fZxkoipFKszM9KjsBghWrEwjDooPpZfWcN4H3mo/Rp8DbpQKn0gkwjZu3Jj6v9mLfHw8QvVMQHRq7/Xas1/4YfHhcS6UsITJNBnVm8ibNTHeiKlFE9Pyz3Dem/RcRry3wNHFGFSmrIBsbNz3WXoU3jDE2Cg0trWSibQLXnEiW2FeBC7wVmxZmVjDD4oPpY5X1nCn40oAxCItdUkSCuHDmNqZgGjP7Ee0gR/wdASlpXKONTIdrt6JW+1hZmE1E20yKm+z1bF4nXiHIrZv8sipyvTs1VYvYX0uWDEy44mV0S9jyw4nFlLRsGXRCuPMMC49QeKt2MZG/xq+Xfl5759X1nDZcSUgYpGEjyShET6MqZsJiE7tvV57Tsfr5TCejsDkPsRvqdE2h8x2TnWrw+UwM4s0GZW32aqJ2Tnxpi9b6VXHm+PGFYuPhClMZDyxM/o1NAiW14r050l1wjovBARvxYo0fC8s2kHOwSYzrgRkMuyK8EkkEuxvf/sbO/vss9nPfvYzdtRRR7Fzzz2XzZw5kyWTSUcFDgqBFD5Wg70KISDTaP2IxPKrs+DpCLLug+5cauSfkR1qncJJhytgZhZpMqpus10TM3PiNUrIGIkw1q8izpIVFdoeWQYHdNPHJ95sczEmnTxvM/Jt4uzWErrbEyTegZq34bs9iAdgScgW0XElIO4PyoVPMplkZ599NotEIuyYY45ho0ePZpdccgn7+c9/ziKRCBs5cqTTMgeCwAkfu8FehfCJx63z0Zh1UF5GYvndWQjUc3ZRjbIkG+o12Q5X4WhpdJkqbjOPP62RSLRKyLiwNro3qstYLFVliSUVzSYa1aLQZHP62DUj3yfOqic0Xk2QVFqC3RRsAVkSUo7vDVdDufD5+9//zrp06cL++c9/tvlszpw5rEuXLmzmzJniJQ0YgRI+doO9bFZgo/PYNVgnoYtOO6UQdRYiqX/a9PuyHa6iTsdKY6swOvL401ptpZH92aw6Y1WmiyVdnKnS5+mPo5mFyumAHoiJs9MKy24QjY3WxwtaNCdj7gm2gAgE5fjp/pCGcuFz2mmnsalTp5p+fvfdd7PTTz+dv4QBJTDCR2QEdfJg8pyntFS+wapYngpLZxGPswXTrPe/su0LZDpcztEyUWc+WsoY1PSo7uxNwa1ur6w/rfGSYaYqS9TVswXTNEGkekXY6DExDDOvcGbxDExTl60ws+e9ocH4eLnm62JHIJStS/jh/pCFcuFTXl7OFixYYPr5J598wsrLy7kLGFQCI3ychFKLqGsnyyt2HaOq5Sm3OguVM02DTvIbVHDtm9WmahujbfdSsupwOe/hhT1ilk7MIs0pGjVfHeUJAGlubiuYrESPZl3J/CDpYYdqVsXZVqhYs7MZbUAmznKIPu9+L1/zoNoaFRhl6xJeuj8YoFz4tGvXjq1bt87087Vr17L27dvzlzCgBEb4qEjOxfPwyIgKnlmayuUpmc7CrsNSOdM06cDtdkq3qtr0AfXCHpqztCk2o6Xu6Fu4NyrKaTCZXdQR7+21miDq/9+3R5b9idxcMfFyoh6AibM4os97iJavlaA3zro68bxCYcPHpUvlwqegoIBt2rTJ9PMNGzZQAkOVOLH4iPTCqka97F5Z5cxGdBpsJ2pUzjRtOnCe6CLRqjVk74+zo5yyxZdRvyoyqIuuwNrdXqsJYjTK2IU9YlwnmlsbM7zljY1q+mCvJ+o+T5zFEa2gXLd8pMO7vhtoZRsOlAufSCTCzjrrLHbBBRcYvs466ywSPirhCYPxWlSIzNJUT5FF8nVYqQcjR0uza+CBswO/EdPa+P7IVq1VHWUvkZlFRaU3DZExSFSP82Z1NhMniTq+djSGI1EhIG/U82MJKog+v6aIPu+57OuSDo95VH8FWtmGA97xez9wMnbsWNvvXH755byHI+woLAQefhi48EIgEtEeDV4iEaCiAhgyxNl5IhHt34ce0r7X0gKsWWN+LMaA1auBefOA3r35ysr7vaoq4KWXgBtvzCxDRYVWvqoqIJHQPjeqK8a067nuOmDzZr5rGDbMvlzr13MV/yH8PvX/1ahANR7Gy6iSqlrTYlVV4ZWdI/Hkb+ahN9ZjPXpjHoYgiULLYg8ZolXj2rXGVZfenBoaeK52Hzy3t7DQ/JoK+vC1j3Xg+97atVpTf+klrcnwkv2YRFgCQ6DV8wb0xjw2BA89VIjCtlUtjVW9BA7R5111/xBErPojnbIyYNo0oE8f7QFT2YAIczwSYqEhMBYfHTObd02N+nwbdrZ1mTUR1VNkq2mwiuVB0ZmmxDn15af5NfvqVtUEWHYFwS7UXHQFU28+jq0UNu0oybGUqKrp6fX0u9K20Vw/liqIRAqViScL0ec91F7cewl8Uqb8g7askCRwwocx8wdMtSOA6gfZay9NN3drNkNySTKZ1bGr6iPjcS3B3jAYh9VbjSdmkVqlpZkpV3gvV9nttWhHSQ7ncZXjTbwxuncbEoOB2kmbVuVs76d4En3eQ+nFvRee+5Uvy3kBgoSPJIEUPlZ42dHJzNK89NLkVQ89eqidafJk5rMZfeNx6+TZugCxLVY02mbXbj2s3m484XWutrvcdKGkDJN2tLBWTvTIjDfRhjhbW8gXYSZ8bSqc7Q3qaOf+JWz5uFoWb/VIAIk+76Hz4mb+BHgQXJDwkSR0wsdrZGZpXokzXmHW0KB+pimbmW/v6KtE+NiE1V9VGrXMrWNX/IoKa2NjaamW0NA17W3QjpzEAEycyN8co1HGhiEmNZBZNn9VYd02TrTfFZRmLK3aF8wB6cdtbtZebmZ29xKR++X2cl6Y6s0jSPhIQsKHgyDP0kSiv1RfQ3pHJLjTtePJoU2HnEREyyps0jnynr+21vhy/ex3nRjcdEFnddv1qh0NuV3ZLVdEVFgFOFRrEsj0K/MiY3KQszLLEpTlft5cakF4QD2EhI8kJHw4yX6oWluD85Dxiho3OwbehDeNjYwxBe4ADgdQEfeoII5bRokfebYN4RmD9KodymvxaW5mLBZjH1TXs2EGZcg4nwo/EM57nwDYmsJKFn+hQV0eK6sb4vY5/ID3fk2cuK9faWhQO8niqVszYaQqsVVAIeEjCQkfCYI4swvCbKehwb6D3GvqdjzxdziAeh6tpRD9Vseuj7I1EWP/Jh7xY3ZdetUWwHpX9gQi7LuCUvZjSR/bMqTO1xxzeOOZmGoFWGtxD7mKELkhuZqVWSZyVKXg4Knb0lJ+86ff/bRiSPhIkpPCR0QEiAqGXJ3ZqUBAzQi5AxjdI4fKSXVGZq/QNbfZfl6824ZYXVd61Zrtyp7YG+mV2PviLUOsWYEfiMo0DipucC479co4lansC1Xf6xzrp0n4SJJzwkfEGiNqucnlmZ0KBK0wXO4AViZshwNoNMrfX06Y4L+lXK+vApv9vHi2Dcm6FRlkj3VGu7KvQgXbjFLhMtTXM84bb8HeArYJsXfychJineth3DJOZar6QpUpO3KwnybhI0lOCR8Ra4yM5SaXZ3YqkKgfS/cku3ukIKllba1Yn+mXpTxdc/P63gxFjPtWZBvVsgMBs32JhqNZqgypW+/U2T4aZUnAUvwkEGGbC8rcf2bzoV+QjeJ0es1uWPdy4X7shYSPJDkjfGTCLnm+m06uz+ycIhnOarjayHuPHDpSii55eWYpz6qUWPM+ywlvtNVoi/280m+FmVGtpsa8bkTLYHjr064x3qxdo5BLSDTKdnU2zomQyhZ+s3PLINe9CntWZh7S2+TEid70hU7yN+RBP03CR5KcET4isy7ZGVouz+xUOUerCmcVqWuHZRe15Ls+jhkokR9K9jkMi1p8rG6FnVGtsdE4U4FIGexuvaNYgXicfX5JLdsSKck4wJrCysxQdjdCrLMvwuocXkcXuR3s4GVfaFW3gJhzc9j76SxI+EiSM8JHxBoja7nJ1Zmd6ig1FTmDPLauyVjyXek3TZRIMs1hmCfaak1hJYs2xC1vBa9RrbW1bbPnKYPu42OXyFhFrEC8Nc4WTIuxdyfUswXTYm0zN3uRi8vsHEamMzfXTL2IOvW6L7S6f4GbuXgHCR9Jckb4eGHxYcyb2aPbpM8Ga2vdiVJzOuP0wbqmF3nCBPc1l2H1tLZq24uYnDBdTJhFW2n7akVYvDFqfS4mVsVGzd60DBGtDO9UR1OJjGfVacIkUdc2C7Vn45MXKR/MnKVUP19meBl16nVfaHX/eGcubvbTPqQUIeEjSc4IH5EZiNPZileZnN14kERMG37OjHy0rqlKLizSR/+uNMp2deVzxB22dwnLKNpKpB3yGtXq6szLfVVp273S9DKkh963KWdFBfe+Y6FdkfBa2fkRdRqkrPZGotOrsvmU242EjyQ5I3wYE5uBqAipFRUlIr9x40Eymw0GdeSxuUfxxqgrEyw3dLF+64xugW454Q3PHl+yz2m5AHF2UVmMvX+jtsQzqy7OXRe8Aq9Hj33NznBJyaBd69dplm9Ii8jiyzcUWh9Ur62WfvkgBiF5qhlelM3H3G4kfCTJKeHDmNgMxMvZimh+IdUPkmj4UlBGHpN7NL8m6uoES1YX29267I1Z7XLyGL3izbFUX97czNjkyYyVlIjXhUjATCTCNGdhjkrXj2t3bUmAbUKpbb6h0Fp8vI4CpahT7/E5txsJH0lyTvgw5m7mZhlEhIxbD5KTfBh+jzxZ9yjaEPdkgiWqi2W0Jfd+WAb3Pho13+Gety54/UKrzKxSBifSmxrvtd2OWj/GDPfJF4tPPuNznZPwkSQnhU+QEBUybj1IMhlQAzjy+OE2wauLZbQl9w7o+sXtFRg8q5a8dRGNMlZm4V5ka5XKOpHe1HivbTNKWKHVxqZhxWs/Nb/84oK81OU2PlvZeMfvAhCEl8ybB6xZY/45Y8Dq1dr3AGD9er7j8n5Pp3dvse9HItq/Dz0EFBaK/dZFRKvTKYWFwLBhwJgx2r9mVZFIAHPmiB9/PTjvS1kZ8NJLQFUVEgngxhu1a7WCty6qqoBp08w/H4J5qMQamHaeWSfSmxrvtfXAFlzQI7OQFRWpyw0vhYXAww9r/9efJx03ni+vz5dIAHfcAfTsCQwfDlx6qfZv//5AU5OacwQd3n5VtP9VDAkfwltEhYxbD9KQIdpokt0hmhHQkcctXeiEpiatr7/rLvHfzsMQrEYFkrC4L2Vlmtrbey908VeABIaiBaMxC0PRggIkDH/OUxd9+ph/1ht8lbl4znokEvua2r8wBN+hhOu35cn1qK0F6uuBWAxYsSJwTU+OqirtOcquYLeeL6/O19QElJcDkycDW7ZkfrZ2LXDhhfkhfvTGbkYkAlRWat/zE1fsTSGGlrpcRnTpyk1ztV0G1NrawJurg+bGIBIol+7czJMPx2y9p77eOET8G1QY74jOURdWS4giWZqzo9duRy3Xb4chFv6lLSu8Xg5y83w8u/sGcJncFVQ42jmAfHwkIeHjMjJCxs3EYEHKuyEBTyRSaakW7eTF2CKSEkm/dUa3YFzXKNvSme++LKw1DhFPpGV3Tj8Ebz3U1BiXXffxSXJkac6+zr594mwzSk1D9bN/mw9jZagR9eDPZUdqu1lPaSnl8QkqJHw8QEbIuClQQu6MyBuJ5Hb+MBFn5uxbp9+C6up9jsX6DujjS+rZ3NqY8X2Jx1mywtzROF1IAAJbPtiMZ6lcQ1mVbiS2snOFLqw13knd6Le5PlYqx+tnWdSDP1dD53kEYEWF6/eDhI8kJHw4UNG5yAiZkAsUN+FJQO22pZk3oGPiRONbJ5WuiXPgOa9rTOi6eQ57AaJsZ1lmpa9CpWkSwgwBE42yH0r4fpurY6Vy/MgWLBodmqsqNiBr7rzj937+eRcRoaSpSQuhSQ8lqqjQoidEHAWrqoCRIzXP1PXrNefkIUOsIyz0kCKiDXp1trQAF1/c1r8S0HqeSASorta+6ySYJZFoe+uy/csLkMAQzENvrMd69MY8DEEShTjllLbntorMsiw3p9d29K/rsZ9A8+Q57MuowivTRqLsi3l49q7Ma7Q9ZlUVPux8Dl4Z8TgOwjIsw0F4DNchjvZtfudzAEw4aGrSHIizG5DuWOxWYILIzQmCU69bBDHKwgpX5VcIIYuPBT6mIif48GLiZTax1rcC0rdmMHI2HlUQZY2NCsvN+cMLe6i3+OjlkSp7NMqSFW3rx2yJjLDAz2zBvOm+c71/DJnFh4RPFiR8TPA5FbljZJfJQra85nb+MDvtW1OzL6uxmbNxFaJtxgDpctsMPLqPT+FeZ2FRHx9X9vg1qcR0Hx+aSwjg96Br52TngVOv7/D4+HgwPpDwkYSEjwl+dy5OkF3792mHYSe4eZt4tG+/ijj7saTCImpJ82XpVxHP6AMdlXvvwGPnaCyqzV3Z49emEnWh1q8i7ryZhUy0S1Nd7a7a58Gorygp0VJi5Gq9Z2MWBqm/ampcLwIJH0lI+JgQ1g3/ZJfnQrqsF4+bp9FIn4DK9MU84kQkx026iHGcrilq7Gg8Cg1sKGJsNOrZUMRYAeJCok/5Hr+cCi/eLFBI3oIHXLRLEY8z1qOHA9XMcfwg7XMYpPNml4EsPuGFhI8JYbT4yC7PhXhZz03hw6N9L0UdVzu5FHVtNLLTdE2z6uIZImcUGg39jN6pFhv8lY59nBOID6odTCBCKtql4O2XysrEG30YxGNQyhiQ8YGEjyQkfEzwa8M/J8g+jAF5iGVws+g8x74R07gKcCOmGZbBSbqm9PJdYOFnlETm4K+Llbo6xqZN0/51beLMeYMuKovJnT/Eol0KXkt0dbXYccMgHu0SBnq5zBaQFQHapJRQi9WGf4DWrB98MFAbeEqHWIYtNDMNN4tut71ZJAIkupdxHSvRvcwwsreqCli5Utufqq5O2yx06lSgpEQLeecpXyESeBg3AmBtNiMsAAMi0GLjE4nUvmLDhwO/+Q3w+99r//LuLZlIaCkEZs3S/rUrI4YMwa4y873IkojgG1QiunmI3MayXu9a6ze84eQjR/If0y63ApBqP0oQbkQ2ZdSZPBno18+bPcJCsjlpClflVwghi48NVpnygmYGJouP8qLbLUfNreUrwNxa6wI48UcfxulnNLc25igKWbaM71Qb70WW7YwtNTkOyMzbM3jCyUUtXF4+/7KNSCRjtBcWqoCsCNBSlyQkfDhoaDBv3F6age0cKmQfxoA8xDJ4UXSjvrqsTFtNiDXH2+SnyRzcwbZ0sS6A01WGD6r5Bv/xJfVc44ZRfTkpYyxmnOcoO3Oz1Ljq1qAdBAdaM1Tv5eeVeHTSiEQyRnvVX7m5pyInJHwkIeFjQ1B8CHhnSrIPYwAeYlm8KHr63lrZQTW/K42ypKF/DUzz+KQf13Hz4hz8hyLGPXYYRaBZlbGiQtsY1kgn6L8vRLxNxJnjR8gN5RsUB1orVO7l54XFx2lDF90jzGl5efF502cSPpKQ8LHB62Ugo5mm6ExJ9mE06/Bra4M5803Di/7HyrfSyqJh1acraV4cg/8Ppfs2LuV5pU/uZcacbJ3gqjhVefAwOPnqqLJKeWE2ddrQeTNGmzViN/HROkjCRxISPjY43YlSBDPhYRWvbbV85TRzc20tY336WI9oAcLN/ocnbUeBiUXDqk9XtspgM/gvrDXeSJRn/BHdl9JMJ7gqTlUcPCjWXT9w22yqoqHbRXXxiqgcgoSPJCR8bBCZ7joRBaIPtdsPeZhmvh4gY/Xg6dOVGhQtBn+RCXP22C577UY6wdXJsdODh9jJXwluKlNVdWsVbGLV8EQJso9XGiR8JMkr4SPTmEVGDFlRwGNOkBlVZcnnma8JMlYPoz49uwm2tipeZbBo49EoXxPObr4yqwyh1AlhjRBTOUi7NeCrXE6LxzVrtMo+OJ0w+HjthYSPJHkjfJw0ZrtN+ZyKAhXmBJWjS77PfA1wcov0JqHv5p7dBGtqvPErtxM+paVaGY3GPZFHIOg6wRRV7d5La0GIBmnly2luWKhCZukm4SNJXggfkcZs1mnxmFhlRYETc4Ib1pewznxdhNfqYdan6+LGrAnW1PD34U4Ml3bCx8qlS/QRkHkUPEXU/AYwVljIWGOj+TG9FCIhG6QZY+rFimprV8gs3SR8JMl54SPSmO06rXhcc2JWLQqcOFG40cGRxccQuwmrmXhpbORrgq2tJn14Wuc+tzbG+vbJdJpWnf8N2OeoPQb1bBhiLNoQzy4Ka24Obfon82fdTKFmX5hRhXspREI4SKcIqv9MCPs9Ej6S5Lzw4W3MtbV8nZYbDwfP+rfRdNytfBEhTmjoNnYTVqM+XabJ6L97p7rtLuzfoCIj8R/PuCpiVDQKzV9bWMHijW1PEMr0T3YC5eabNcuOiKjwWoiEcJAWwg9xFEJLNwkfSXJe+PA25pISvk7LLVHAM4J47TsQuhHNG0RuQzzO2KhRYv2pLq6sNh5N3+qBp9nxjpPcm53aWKGkNbnbbZxHoJSViYsKr4VICAdpbvzyWwqhmCThI0nOCx8VjsPZDd4tUeBzFtDAlydkRKPWKZiMmpfetAoQZ9+goo0ASRciq9A2KaGT/G9250zC3Es7WVHBFtZGnekVLwY8lf1BuqjwWoiIDNJBXVoywk+/pRBaukn4SJLzwod3GUm003JLFAStkwpaeUKCSFqmdB8fvUkNRYzrx9nbUPDkfzMrF+85TS8iEjEPC5OtMNUDnoq8BOmiQsePDO88g7SRg1lQo7788lvKTtoaIks3CR9Jcl74MGZvoTHLCWHXaZEoIAyQScsUjWaOnaPBN0CPRr1lE83GKjn4GM5zWr6yfWN4BlkvBzxegVJWJjbz98NawONtH6aoLz+WmoweiNLStpPhgFq6SfhIkhfChzFrC00ITZyEO6jQsqKrKdXV2u/SjRGiFh+RJmp0jdEoY8OcWHysRIvdIOvlgCdiKRGd+fvhF2fWrxkljQp6n+b1cqGVlREIxR6FOSd87rrrLjZ48GDWsWNHVlxcbPidVatWsbPOOot17NiRlZWVsVtuuYXt2bNH6Dx5I3wYsx7VyJk371HlYiK6mqKP5+nj/z5/G+MBOt3HR1UTjTbE2dpC83M6Ej9Wg6zsgCerUnmfdZnlbD/84lSFEvqNHwI4TMLQgJwTPpMmTWIPPvggu+mmmwyFTzweZ0cddRQ79dRT2YIFC9hrr73GevTowf74xz8KnSevhI8d5Mybt6h0MRGx+KT3rdnGiH0RVpkFy47qUtlE441RltQjuIxmwU5eZgOWzIDnVKXyPuuy2SLtfuP2MnkQor5Er5FnjdjrJc8gCUMDck746EyfPt1Q+Lz22musoKCAbdiwIfXeE088wbp27cpaW1u5j0/CJwuzh9VLfx7yHfIU1ZM/kb2tssfZbGOEUU6dnWWVrP7CKJs4UUsiqLx5mIkC3VFWVgSZDbKiS82qVKpfz1mQotcmTnTn2mWvsabGurw1NWrKFwRhqIC8Ez633347GzhwYMZ7y5cvZwDYJ598Ynq8Xbt2sW3btqVeq1evJuFjh9dp6MMShZEjOJn8We1wYhVBVVpqfkuzm0AB4uyishh7/px6dmGPWEYIu2tNQ/bCZGfPvMtPYV+i8Cp6raFB7N6obEiy10gWH2HyTvhcddVV7PTTT89478cff2QA2GuvvWZ6vMmTJzMAbV4kfEzwMq9EGPfeyQFkJ392GtXo886dGfuv/9JC163I0B3NcdYyRds+YigyhY9I01Bm4DC6MNFMx7zHzV5+CvOA5ZVokwkrVNXHOLnGIDq5B1VA7yUUwud//ud/DEVH+mvJkiUZv1EtfPLO4uOkt/dydhn2mWyIkXUx4dGo8bgWHJKdGJx7gh2NsmRWuzDassKuaSg3JGY/VzJRUDzHzb6oMC9ReDWwyyZpVNHHOLlGv6K6QhzQEgrhs2nTJrZkyRLLV7Z/juqlrmxy2sfHaW/v5QwkVzOxhgDRyZ+IRnVkxNv742TWj422rLBqhp4ZEr0IDgizxcergd1pkkYndefkGoOSxydEAS2hED4y2Dk3b9y4MfXeU089xbp27cp27drFffycFT4qensvZyC856quJh8gFxCZ/PH2z/ru5TwCqQ026spoywqjZui5IdGrvbbCuEQRdIuPiv7MqcOcH/c2xBPJnBM+q1atYgsWLGC1tbWsc+fObMGCBWzBggVsx44djLF94eynn346+/TTT9kbb7zBysrKKJydMbne3u9cGE46qxCZZoMM7+SPV6NOnOig+XC2h/QtK4yOE2YDiSkySxRBGNy8GthFwgpVNwanDso5sPzkJTknfMaOHcuMfIBiaY1y5cqV7Mwzz2QdO3ZkPXr0YDfffDMlMGRMvLc3WxLTs596MQNpbLR3EFXhQEpYwjM+ikQK83zPcILNqa5Go97y1ofZJcYSo2e2rEyziBolJw2KldSrgV0m+k5VH+I0JD3ky09eknPCxytyUviI9PZ2S2L6fjdudlQiO1ryijnCNXgn7s3NDm4Zp7oahphlM8xJi4+OrlKrqxnr0cNY2AQxUtKrgd1sHyr9+t2oD1Uh6UGw0IUAEj6S5KTwUe2EYbTDsaqOiqejKCxk7IYb+MUc4To8E3dHKxs2P9Z9fMpK4qy21nxcCLNLDBd2+y1lbzYZlIvPHthbW90Z6M02ZnOrP8tppR08SPhIkpPCh2fZSHRK7tYMhLejmDaNOpSAwTN+SK9s6HHwBvc4aRDVZbVyE0i3CRXPk0y+miA+M34sxbnVn4VpbTUHrEokfCTJOeHDs2yk9/ZBeEh5y1BXl+NT93DC03cKT7CNfpD2WoXKNqHsdiImUG4TqgZ6p9FLQRiEg7gU54SwWHyC5PflABI+kuSU8OFdNmpo0L4fhIdUpAyBnLoTPHBPLi2EexJg93apzQhhF9G+gZjgqhzonear8XsQzsWkpSrXVt1qsDkkNkn4SJJTwkdUyATBAUJmg8bATN0JpdgMhEmD3D1BGsdtUT3QO7X4+C0sgjDxcgMVEzS3LDI5JjZ5x+8CELnL+vVi3yssBB5+WPt/JJL5Hf3vhx7SvucWomWoqgJWrgRiMaC+Xvt3xQrtfSLczJsHrFlj+nEEDH2xGkMwz/IwvI+BIYkE0NICzJql/ZtIODhYFjbXB8aA1au17/EwZAhQUdH2udGJRIDSUu1fv55vK3hv1Jw57twPt6iqAl56CejTJ/P9igrtfbu+qqkJuPDCtm1l7Vrt/aYm+bKpboMhgYRPLtO7t/j3nD6kTtAHmdZWYMoU/jIUFgLDhgFjxmj/+tVxE2rhHAh7w/p7vI9BG5qagP79geHDgUsv1f7t39/ZQJOO6MTEDp5Jw9NP+/d828F7o+66y5374SayE7REArjxRk2AZKO/V10tLwBVt8Gw4JEFKjTk1FKXk6Urrx0gjEy5ffpokTwqyhAIhw5CCIHcPcqt9F74Pbi1tMOz/BvE58HPXdSDitvLfzm2vEg+PpLklPBhLBwOwCoHGd48HSGMWMg7OIT7j6WVrBBxtc3bK78HN33qgihseGhsFBM+6fXkVu4fP3E70jYIfp0KIeEjSc4JH8aC7QCscpCxysyabzNFM8I2IHIId+XN28tZsN1WClbZGHMRJw7aZWW5N7nxoi1abakRsj6ShI8kOSl8GAvugKfqwZbZ5iJksxnHhNXyxaFslDZvr/NZ2eQpUnaPgtoHpKMqJN+vyY3qOnbbImPXb9rtIxYwSPhIkrPCx2t4OwAVg4zTjLUhWb92RNhzdXg5aPvh92CRmTr1Mtpw1O6Yep3V1oZD9KpKwujH5MatiYVb7gqq9hELECR8JCHhowCRDkDFIOO0swxCung3ybFcHa7jh9+DiHjnGUztrEhBFb12dS/7EhGpMiLb7YmFG+4KOebYzBgJH2lI+DhEtANQMcg4NY+H6MGWIgc7ONfxOihARLzz7MfBKxyCKHrt/J5kXryTGyOBUVJi7WvlleVEtdUzCFsUKYYSGBLeI5NzQkXSROlELXvPv3mz/O/DQL7m6nCC1/msROre7FkCrJ9Bs2MFLUGdWd2XlmqvdMrK+I7J00eYJQrcsgWYPBkoLzfOGWSXBBBQU8eq85XJ5HnLEUj4EOqQzQLqdJCxy1hrRSIBXHJJOJKgyZLHHZwjvMwKLlr3Zs8SzyBsRNBEr1Hdb9yovdLfW7PGPlt1ZaXWR1jBIxi/+w4YNaptX7F2Ld818X7PK3gyffPUXQjZz+8CEDmEE8tCVRUwcqTWca9frw0EQ4bwzWp0q9GFF2oPa3rnpf9dUAAkk+bHqK7Wzp+LWZ/1Dm7tWuOOPRLRPs/BDs4x+izbbezukRnZz5KsgAmi6DWr++z3rJ59gG8bDhHBmN1X8FqMg2ZZtus3AX+3MHERsvgQ6nBqWXBiyrWyGtXWWoueIJr7VRKEPdgIa6zukRXZz5KogMmFWb2KZUkRwZjdV/Aut/F+z0v83KLIR8jiQ6jDD8tCIpFpJVq2DHjvvUyrUUMD37GCZu5Xid7B3Xhj5sy2okITPTnawYUKs3tkhNmzJGI5shO92c8WrwXWD5xYjAFxwZjeV2SLBjN4v+c1TusujHjkbB0aKKrLIV5Gw/CGzVNU0z7CkMQuSPhRX/o5q6v3PTsyUV12UVFW4dBhTXYpi2gusPS+Igfz4YQVCmeXhISPArzYIkMkbD7H9qMhPCIIg7/ss2RWdp5Nf4OQ7NIPwcmTBsCsr7D6rR+5kvJ0gkPCRxISPopw88GTScgXhs1aieAQhMFfR/ZZkvldEJJd+ik4o1H5/f2CsidiEAS7T5DwkYSETwiQXboKSsdEBJsgDP5+4feycBAEp759SEmJeF/ht6UlCPXnI7zjd4QxxvzzMAoe27dvR3FxMbZt24auXbv6XRzCiFmzgEsvtf/ehAla3o10R70wOWwS/tDSAgwfbv+9WMybUHcv4X226uu16EuVJBJA//7mjt26Q/eKFd48s2HrK4JWfz7AO35TVBcRPngjMP76V+1VUaGFCldVeZeXhQgv+Zzp2s9klyIJUEWfYRkRE7a+ws36yzEojw8RPkQzNa9dqyXpyuXszIQ68jnT9ZAh1mHXbub9cUtwNjVplpDhwzVr1vDh2t+51h/ks2AXhIQPET5Ek73pq7lGexsRRDZ5nMofs2cDu3YZf2aU9yeR0JYGZ83S/nXyfLkhOM323/JiMqSybnjIZ8EuiiceRyGCnJtDhJGzsl9OmURuEZYoQJXOtHbh3KWlmdetOnpIddoJP53U/YisorQdFNUlCwmfkKF3/BMm8Amf+nq/S0yEhaBHAaocXHmS8FVU7Bs0o1Hr78rWkUrB6VeEmp+RVWER7C7BO37TUhcRbnQHxFGj+L5PZl6CFy93ZxdF9RIOzyada9Zo30skgKuvtv7u1VfLLe2I7B1lt5Tkh8+L1S7vXiy55+neW6JQOHsWFM4eUvRQTrt9wnI4lJPIE9wIWxYJY+/ZEzj1VPvvNjcDp5zCd/5s7KKwmpqM953TozcBf9ISBCUVQthC8RVB4exEfqE7PF94odbxp4sf2oGc8Bo3Bx43wpZFHGPnzOH7bkuLvPCxCiXXrV3ZExzd2qVbNvzYNDkokVVhC8X3GFrqItzB64gGgMy8hBhmbdRp23U7fNqNwTUskWwiS0lW0Z/pkyEg2JFphHo88TgKEeTc7ID0XaXLyryNaDAqR55t0EcIYOYYXFNj7zBs1b7cdGzVzztxojtOu7yOsc3NfOdvbpa/VjNkHJatnNSDHplGCEFRXZKQ8JHELrQ8T6IKiBDAswu3Wdu1GijdDJ8WSd2g+jzZkWzxuPlGnvqrtNSdwb2+nq8OsqM3jcSqWyLVrn3V1DitBcIEEj6SkPCRgHcgodkO4Tc8Ydtmbddu1+7aWnFrBA8iQk2lZcnKYupWOLsdqkLU3c7xU1NjfWyaALoChbMT3mC15p4NY/ucLgnCD3jCto1gDPjuO/PPAOCRR/iOJeJ7I/J8AWr82XTH2DFjtH+NnLKrqoBo1NifLhp1z59OlS+SiIO4KImE5i9kBWWR9xWK6iKcITOQ0F4xhF+41fashFE2Io6tvM/XxIlaBJWXYctVVcDIkd6GTauK3nQz+oo2Cw08JHwIZ8h0DBTRQPiF222vpAT4/ntjC41M+DTv83Xkkf4Mon6ETevRm0Z5fB56iM/a5Gb0VVBC2glTaKmLcIZIxxCUkFgif7FbKnHKjTdq/1qFT4tYRCg82hinWbXdDN+nexZ4SPgQzuAdSCiJIBEErHK7mBGJaK/SUvuB8rbb1OaSCkt+HT/g8UWy+i1Pjh+ZvoruWeAh4UM4g3cgoSSCRFAwS3RZWQnU1GhtNR297T79tPa33UCpco8vNwfofMethKd0zwIP7dWVBe3VJYnR3jllZcBll2kOkHmyVwwRIsy2lbDabsKonVdW8vuWyOLXefMBt7YXoXvmObzjNwmfLEj4OCBPN8Yj8gy/2jk9X+GD7pmnkPCRhIQPQRChgwZYgqDd2QmCIPICoyWVigrNz4SWVAiiDeTcTBAEoQqnO7uL0tSkJfPLTpi3dq32vqod4QkihyDhQxAEoYKmJqB/f2D4cODSS7V/+/d3T3xYbWehv0dbIxBEG2ipiyAIwggRv5mXXgIuuqjt+7rlxY1UDm5sjaBf89q1wObNWmRmnz7kM0TkFCR8CIIgshHxm2ls1JLoGcGYlrululpL66BSPKjeGsHomnXIZ4jIIWipiyAIIh0Rv5mmJuDii62Xk5zs9G3FV1/xfY9nawSza9ZZs4Z8hoicgcLZs6BwdoLIYxIJzS/HTADoG42uWKH9bfXdbOrrzS1DouhCxar7Ti+rlaXJ7prTqay0Px5B+ATv+E0WH4IgCB0Rvxm772ajalNKK6fmdBjj2xpB5DrcsFwRhMeQjw9BEISOar8ZHZWbUvIKldpaPp8c0WsR/T5BBAwSPgRBEDq8VhlR643KTSl5hcchh/B9T/RaVFmuCMInaKmLIAhCZ8gQzS8me1dtnUhkn/XG7ruAJnYaG9VGQ6kWZzzXoaPSckUQPkHChyAIQqewUAvbBtoKAf1v3Xpj9V2dWbM0J2QdFZmdRcQZD+nXYUUkotZyRRA+QcKHIAginaoqLeFgnz6Z71dUtE1EaPbdykogGs1Maqgqs7OIOONFv46KCuPPKyvdScIYRLzedoTwHApnz4LC2QmCACCWudnuu2bh57pQkREVRgkHKys10SMrUPI9czNt+BpqeMdvEj5ZkPAhCAKAmPCxOw5vbiDR46sqI+GOOCU8hYSPJCR8CIJQOvNvadGWteyIxfj31CLU4qY4JTyDEhgSBEHIILJlBQ9u5QYi1CGSuJIIPSR8CIIgdKyyIuvvVVeLOby6lRuIUAeJ07yChA9BEISOGzN/1eHnhHpInOYVJHwIgiB03Jj5uxF+TqiFxGleQcKHIAhCx62Zv0huIMJ7SJzmFRTVlQVFdRFEHqNH96xda+zn4zS6h8LPg40buZEIz6BwdklI+BBEnqNHdQGZ4ofyueQHJE5DC+/4TbuzEwRBpKMvSxnl8aGZf+5TWEj5lHKcUPj4rFy5EldeeSUGDBiAjh074qCDDsLkyZOxe/fujO999tlnGDJkCDp06IDKykrce++9PpWYIIhQU1UFrFypJRWsr9f+XbGCRA9B5AChsPh88cUXSCaTeOqpp3DwwQfj888/x1VXXYUff/wR999/PwDNxHX66afj1FNPxZNPPomFCxfiiiuuQLdu3XD11Vf7fAUEQYQOmvkTRE4SWh+f++67D0888QSWL18OAHjiiSdw2223YcOGDWjfvj0A4NZbb8Urr7yCL774gvu45ONDEARBEOEj57es2LZtG0pKSlJ/z58/HyeffHJK9ADAiBEj8OWXX+L777/3o4gEQRAEQQSMUAqfr7/+Go8++ij++7//O/Xehg0bUF5envE9/e8NGzaYHqu1tRXbt2/PeBEEQRAEkZv4KnxuvfVWRCIRy1f2MtXatWtxxhln4KKLLsJVV13luAxTp05FcXFx6lVZWen4mARBEARBBBNffXw2b96M7777zvI7Bx54YGr5at26dRg2bBhOOOEEzJgxAwUF+3Tb5Zdfju3bt+OVV15JvReLxfDrX/8aW7ZsQffu3Q2P39raitbW1tTf27dvR2VlJfn4EARBEESICEUen7KyMpSVlXF9d+3atRg+fDgGDRqE6dOnZ4geABg8eDBuu+027NmzB+3atQMAvP322zjssMNMRQ8AFBUVoaioSP4iCIIgCIIIDaHw8Vm7di2GDRuGvn374v7778fmzZuxYcOGDN+dSy+9FO3bt8eVV16JRYsW4cUXX8TDDz+Mm266yceSEwRBEAQRJEKRx+ftt9/G119/ja+//hoVFRUZn+krdcXFxXjrrbcwfvx4DBo0CD169MCkSZMohw9BEARBEClCm8fHLSiPD0EQBEGEj1D4+AQRXQdSWDtBEARBhAd93Laz55DwyWLHjh0AQGHtBEEQBBFCduzYgeLiYtPPaakri2QyiXXr1qFLly6IRCJ+F8d39PD+1atX09KfD1D9+wvVv39Q3ftLGOufMYYdO3bggAMOaBP5nQ5ZfLIoKCho40BNAF27dg1N489FqP79herfP6ju/SVs9W9l6dEJRTg7QRAEQRCECkj4EARBEASRN5DwISwpKirC5MmTKbu1T1D9+wvVv39Q3ftLLtc/OTcTBEEQBJE3kMWHIAiCIIi8gYQPQRAEQRB5AwkfgiAIgiDyBhI+BEEQBEHkDSR8CENWrlyJK6+8EgMGDEDHjh1x0EEHYfLkydi9e3fG9z777DMMGTIEHTp0QGVlJe69916fSpx73H333TjxxBPRqVMndOvWzfA733zzDc4++2x06tQJPXv2RE1NDeLxuLcFzVEee+wx9O/fHx06dMCvfvUr/Pvf//a7SDnJO++8g3PPPRcHHHAAIpEIXnnllYzPGWOYNGkSevfujY4dO+LUU0/FV1995U9hc4ypU6fiuOOOQ5cuXdCzZ0+cf/75+PLLLzO+s2vXLowfPx6lpaXo3LkzRo0ahY0bN/pUYjWQ8CEM+eKLL5BMJvHUU09h0aJFmDZtGp588kn86U9/Sn1n+/btOP3009GvXz98/PHHuO+++zBlyhQ8/fTTPpY8d9i9ezcuuugiXHvttYafJxIJnH322di9ezfee+89zJw5EzNmzMCkSZM8Lmnu8eKLL+Kmm27C5MmT8cknn2DgwIEYMWIENm3a5HfRco4ff/wRAwcOxGOPPWb4+b333otHHnkETz75JD744APsv//+GDFiBHbt2uVxSXOPuXPnYvz48Xj//ffx9ttvY8+ePTj99NPx448/pr7z+9//Hv/4xz/Q2NiIuXPnYt26daiqqvKx1ApgBMHJvffeywYMGJD6+/HHH2fdu3dnra2tqff+53/+hx122GF+FC9nmT59OisuLm7z/muvvcYKCgrYhg0bUu898cQTrGvXrhn3hBDn+OOPZ+PHj0/9nUgk2AEHHMCmTp3qY6lyHwDs5ZdfTv2dTCZZr1692H333Zd6b+vWrayoqIjNmjXLhxLmNps2bWIA2Ny5cxljWl23a9eONTY2pr6zZMkSBoDNnz/fr2I6hiw+BDfbtm1DSUlJ6u/58+fj5JNPRvv27VPvjRgxAl9++SW+//57P4qYV8yfPx9HH300ysvLU++NGDEC27dvx6JFi3wsWbjZvXs3Pv74Y5x66qmp9woKCnDqqadi/vz5PpYs/1ixYgU2bNiQcS+Ki4vxq1/9iu6FC2zbtg0AUv38xx9/jD179mTU/+GHH46+ffuGuv5J+BBcfP3113j00Ufx3//936n3NmzYkDHoAkj9vWHDBk/Ll49Q/bvDt99+i0QiYVi3VK/eotc33Qv3SSaTqK6uxkknnYSjjjoKgFb/7du3b+NjGPb6J+GTZ9x6662IRCKWry+++CLjN2vXrsUZZ5yBiy66CFdddZVPJc8NZOqfIAjCbcaPH4/PP/8cL7zwgt9FcZ39/C4A4S0333wzxo0bZ/mdAw88MPX/devWYfjw4TjxxBPbOC336tWrjXe//nevXr3UFDjHEK1/K3r16tUm0ojq3zk9evRAYWGhYdumevUWvb43btyI3r17p97fuHEjjjnmGJ9KlXtMmDABr776Kt555x1UVFSk3u/Vqxd2796NrVu3Zlh9wv4skPDJM8rKylBWVsb13bVr12L48OEYNGgQpk+fjoKCTAPh4MGDcdttt2HPnj1o164dAODtt9/GYYcdhu7duysvey4gUv92DB48GHfffTc2bdqEnj17AtDqv2vXrjjyyCOVnCMfad++PQYNGoQ5c+bg/PPPB6AtA8yZMwcTJkzwt3B5xoABA9CrVy/MmTMnJXS2b9+ODz74wDTakeCHMYbrr78eL7/8MlpaWjBgwICMzwcNGoR27dphzpw5GDVqFADgyy+/xDfffIPBgwf7UWQ1+O1dTQSTNWvWsIMPPpidcsopbM2aNWz9+vWpl87WrVtZeXk5++1vf8s+//xz9sILL7BOnTqxp556yseS5w6rVq1iCxYsYLW1taxz585swYIFbMGCBWzHjh2MMcbi8Tg76qij2Omnn84+/fRT9sYbb7CysjL2xz/+0eeSh58XXniBFRUVsRkzZrDFixezq6++mnXr1i0jgo5Qw44dO1JtGwB78MEH2YIFC9iqVasYY4zdc889rFu3bmz27Nnss88+YyNHjmQDBgxgO3fu9Lnk4efaa69lxcXFrKWlJaOP/+mnn1Lfueaaa1jfvn3ZP//5T/bRRx+xwYMHs8GDB/tYaueQ8CEMmT59OgNg+ErnP//5D/t//+//saKiItanTx92zz33+FTi3GPs2LGG9R+LxVLfWblyJTvzzDNZx44dWY8ePdjNN9/M9uzZ41+hc4hHH32U9e3bl7Vv354df/zx7P333/e7SDlJLBYzbOdjx45ljGkh7bfffjsrLy9nRUVF7JRTTmFffvmlv4XOEcz6+OnTp6e+s3PnTnbdddex7t27s06dOrELLrggYwIcRiKMMeahgYkgCIIgCMI3KKqLIAiCIIi8gYQPQRAEQRB5AwkfgiAIgiDyBhI+BEEQBEHkDSR8CIIgCILIG0j4EARBEASRN5DwIQiCIAgibyDhQxCEp0QiEbzyyit+F8OSlpYWRCIRbN261e+iEAShGBI+BEE4Zty4cand5du1a4fy8nKcdtpp+Pvf/45kMpnx3fXr1+PMM8/0qaR8nHjiiVi/fj2Ki4tdPc8777yDc889FwcccEAoBCFB5AIkfAiCUMIZZ5yB9evXY+XKlXj99dcxfPhw3HjjjTjnnHMQj8dT3+vVqxeKiop8LKk97du3R69evRCJRFw9z48//oiBAwfisccec/U8BEHsg4QPQRBKKCoqQq9evdCnTx/88pe/xJ/+9CfMnj0br7/+OmbMmJH6XrplY+XKlYhEImhoaMCQIUPQsWNHHHfccVi6dCk+/PBDHHvssejcuTPOPPNMbN68OeN8zz77LI444gh06NABhx9+OB5//PHUZ/pxm5qaMHz4cHTq1AkDBw7E/PnzU99ZtWoVzj33XHTv3h37778/fvazn+G1114DYLzUFY1G8bOf/QxFRUXo378/HnjggYzy9O/fH3/+859xxRVXoEuXLujbty+efvppyzo788wzcdddd+GCCy4QqWqCIBxAwocgCNf49a9/jYEDB6Kpqcnye5MnT8bEiRPxySefYL/99sOll16KP/zhD3j44Ycxb948fP3115g0aVLq+88//zwmTZqEu+++G0uWLMGf//xn3H777Zg5c2bGcW+77Tbccsst+PTTT3HooYdizJgxKevT+PHj0drainfeeQcLFy7EX/7yF3Tu3NmwfB9//DEuvvhijB49GgsXLsSUKVNw++23Zwg6AHjggQdw7LHHYsGCBbjuuutw7bXX4ssvv5SoOYIgXMPvXVIJggg/Y8eOZSNHjjT87JJLLmFHHHFE6m8A7OWXX2aMMbZixQoGgD377LOpz2fNmsUAsDlz5qTemzp1KjvssMNSfx900EGsvr4+4zx33nknGzx4sOlxFy1axACwJUuWMMYYO/roo9mUKVMMy6zvGP79998zxhi79NJL2WmnnZbxnZqaGnbkkUem/u7Xrx/7zW9+k/o7mUyynj17sieeeMLwHNmk1wtBEO5BFh+CIFyFMWbrK/Pzn/889f/y8nIAwNFHH53x3qZNmwBofjHLli3DlVdeic6dO6ded911F5YtW2Z63N69ewNA6jg33HAD7rrrLpx00kmYPHkyPvvsM9PyLVmyBCeddFLGeyeddBK++uorJBIJw/NFIhH06tUrdT6CIIIBCR+CIFxlyZIlGDBggOV32rVrl/q/LpKy39Ojw3744QcAwDPPPINPP/009fr888/x/vvv2x5XP87vfvc7LF++HL/97W+xcOFCHHvssXj00UdlL7PN+bLLTRBEMCDhQxCEa/zzn//EwoULMWrUKGXHLC8vxwEHHIDly5fj4IMPznjZCaxsKisrcc0116CpqQk333wznnnmGcPvHXHEEXj33Xcz3nv33Xdx6KGHorCwUPpaCILwnv38LgBBELlBa2srNmzYgEQigY0bN+KNN97A1KlTcc455+Dyyy9Xeq7a2lrccMMNKC4uxhlnnIHW1lZ89NFH+P7773HTTTdxHaO6uhpnnnkmDj30UHz//feIxWI44ogjDL97880347jjjsOdd96JSy65BPPnz8df//rXjEgyGX744Qd8/fXXqb9XrFiBTz/9FCUlJejbt6+jYxMEYQwJH4IglPDGG2+gd+/e2G+//dC9e3cMHDgQjzzyCMaOHYuCArXG5d/97nfo1KkT7rvvPtTU1GD//ffH0Ucfjerqau5jJBIJjB8/HmvWrEHXrl1xxhlnYNq0aYbf/eUvf4mGhgZMmjQJd955J3r37o077rgD48aNc3QdH330EYYPH576WxdtY8eObRMxRhCEGiKMMeZ3IQiCIAiCILyAfHwIgiAIgsgbSPgQBEEQBJE3kPAhCIIgCCJvIOFDEARBEETeQMKHIAiCIIi8gYQPQRAEQRB5AwkfgiAIgiDyBhI+BEEQBEHkDSR8CIIgCILIG0j4EARBEASRN5DwIQiCIAgibyDhQxAEQRBE3vD/ATMQz+/r7TwyAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tarnet_model.plot_representation_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cb38272a-311c-4267-be3a-d155bd93cf84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output, X, y, t, ite = tarnet_model.predict_test(use_ite=True)\n",
    "representation = output[1]\n",
    "tarnet_model.plot_representation_space(representation, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7871cca0-5f48-4610-b5e8-c0c3d6f6a646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5538282464013116 0.06150197982788086\n"
     ]
    }
   ],
   "source": [
    "PEHE, ATE, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "print(np.sqrt(PEHE), ATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2f64f1c7-a568-4bd0-8483-cfa4aca1d85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.629025608144813 0.2355022430419922\n"
     ]
    }
   ],
   "source": [
    "output, X, y, t, ite = tarnet_model.predict_train(use_ite=True)\n",
    "representation = output[1]\n",
    "PEHE, ATE, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "print(np.sqrt(PEHE), ATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d57a41f3-dcaa-4fde-9747-56f3dd433655",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 6.155004024505615\n",
      "Test set loss: 2.7863714694976807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.6567292213439941\n",
      "Test set loss: 1.444069743156433\n",
      "Test set loss: 1.35111403465271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3270419836044312\n",
      "Test set loss: 1.3154139518737793\n",
      "Test set loss: 1.323034405708313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.2953487634658813\n",
      "Test set loss: 1.321461796760559\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 6.00504732131958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 2.645247220993042\n",
      "Test set loss: 1.6738425493240356\n",
      "Test set loss: 1.4531618356704712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3712800741195679\n",
      "Test set loss: 1.3228964805603027\n",
      "Test set loss: 1.306727647781372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.298737645149231\n",
      "Test set loss: 1.3223223686218262\n",
      "Test set loss: 1.292893648147583\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 5.574468612670898\n",
      "Test set loss: 2.1865556240081787\n",
      "Test set loss: 1.344727635383606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.356195092201233\n",
      "Test set loss: 1.3303041458129883\n",
      "Test set loss: 1.3019163608551025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3352227210998535\n",
      "Test set loss: 1.2978324890136719\n",
      "Test set loss: 1.3262581825256348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.302923560142517\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 6.065164089202881\n",
      "Test set loss: 2.6827871799468994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.7021926641464233\n",
      "Test set loss: 1.4527133703231812\n",
      "Test set loss: 1.3875890970230103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3116605281829834\n",
      "Test set loss: 1.3281577825546265\n",
      "Test set loss: 1.3177855014801025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3075202703475952\n",
      "Test set loss: 1.3201395273208618\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 5.423362731933594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 2.2740426063537598\n",
      "Test set loss: 1.3961119651794434\n",
      "Test set loss: 1.4297049045562744\n",
      "Test set loss: 1.3251880407333374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3293581008911133\n",
      "Test set loss: 1.3126769065856934\n",
      "Test set loss: 1.3491501808166504\n",
      "Test set loss: 1.3325332403182983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3298802375793457\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 7.193230628967285\n",
      "Test set loss: 2.7983641624450684\n",
      "Test set loss: 1.6517342329025269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.5415406227111816\n",
      "Test set loss: 1.3448094129562378\n",
      "Test set loss: 1.3465981483459473\n",
      "Test set loss: 1.3410204648971558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.326128602027893\n",
      "Test set loss: 1.3054686784744263\n",
      "Test set loss: 1.3138784170150757\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 5.357516288757324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 2.060082197189331\n",
      "Test set loss: 1.3856751918792725\n",
      "Test set loss: 1.3855239152908325\n",
      "Test set loss: 1.3273075819015503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3100568056106567\n",
      "Test set loss: 1.3418645858764648\n",
      "Test set loss: 1.3282604217529297\n",
      "Test set loss: 1.3412163257598877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.31174898147583\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 6.347592353820801\n",
      "Test set loss: 2.5395851135253906\n",
      "Test set loss: 1.508913516998291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.4369324445724487\n",
      "Test set loss: 1.3214300870895386\n",
      "Test set loss: 1.310503602027893\n",
      "Test set loss: 1.339876651763916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.306033730506897\n",
      "Test set loss: 1.3095104694366455\n",
      "Test set loss: 1.3059673309326172\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 5.939021587371826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 2.578199625015259\n",
      "Test set loss: 1.631147861480713\n",
      "Test set loss: 1.481423258781433\n",
      "Test set loss: 1.3214048147201538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.312140703201294\n",
      "Test set loss: 1.3544561862945557\n",
      "Test set loss: 1.3139495849609375\n",
      "Test set loss: 1.3141114711761475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3132212162017822\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 7.847517967224121\n",
      "Test set loss: 3.2624521255493164\n",
      "Test set loss: 1.6887593269348145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.4916150569915771\n",
      "Test set loss: 1.3376998901367188\n",
      "Test set loss: 1.3006819486618042\n",
      "Test set loss: 1.3252711296081543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.2988886833190918\n",
      "Test set loss: 1.3142240047454834\n",
      "Test set loss: 1.3091130256652832\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 5.413539886474609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 2.0846774578094482\n",
      "Test set loss: 1.3988796472549438\n",
      "Test set loss: 1.3751020431518555\n",
      "Test set loss: 1.3090075254440308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3000973463058472\n",
      "Test set loss: 1.33940589427948\n",
      "Test set loss: 1.2939176559448242\n",
      "Test set loss: 1.3272833824157715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.3022938966751099\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 5.609108924865723\n",
      "Test set loss: 2.626157760620117\n",
      "Test set loss: 1.578872799873352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.5019850730895996\n",
      "Test set loss: 1.3293523788452148\n",
      "Test set loss: 1.3460439443588257\n",
      "Test set loss: 1.3237919807434082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.396158218383789\n",
      "Test set loss: 1.3393192291259766\n",
      "Test set loss: 1.3344097137451172\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "Test set loss: 6.173935413360596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 2.524379253387451\n",
      "Test set loss: 1.4690076112747192\n",
      "Test set loss: 1.4097106456756592\n",
      "Test set loss: 1.3526458740234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 1.310604214668274\n",
      "Test set loss: 1.3230433464050293\n",
      "Test set loss: 1.3042397499084473\n",
      "Test set loss: 1.3409228324890137\n",
      "Test set loss: 1.3197436332702637\n",
      "done training\n",
      "0.7210378308999239 0.11936050653457642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([150])) that is different to the input size (torch.Size([150, 150])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "for alpha in [0,0.0001,0.001,0.01,0.1,1,2,5,6,7,8,10,100]:\n",
    "    tarnet_model = TARNet(df=IHDP_data, alpha = alpha)\n",
    "    loss_curve, val_loss_curve = tarnet_model.fit(epochs=10)\n",
    "    output, X, y, t, ite = tarnet_model.predict_test(use_ite=True)\n",
    "    representation = output[1]\n",
    "    #tarnet_model.plot_representation_space(representation, t)\n",
    "    PEHE_val, ATE_val, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "    output, X, y, t, ite = tarnet_model.predict_train(use_ite=True)\n",
    "    representation = output[1]\n",
    "    PEHE_train, ATE_train, _, _ = tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "    print(np.sqrt(PEHE), ATE)\n",
    "    losses.append(pd.DataFrame({'alpha': alpha,\n",
    "                    'item':range(len(loss_curve)),\n",
    "                    'curve': loss_curve,\n",
    "                    'curve_val': val_loss_curve\n",
    "                    }))\n",
    "data_loss_curves_by_alpha = pd.concat(losses, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "059e6a2d-926e-4ea7-8f95-139b5ec875ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>item</th>\n",
       "      <th>curve</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.987094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.188901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.572817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.394949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.348908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  item      curve\n",
       "0    0.0     0  16.987094\n",
       "1    0.0     1   3.188901\n",
       "2    0.0     2   1.572817\n",
       "3    0.0     3   1.394949\n",
       "4    0.0     4   1.348908"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loss_curves_by_alpha.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c9eaf55f-0ec7-4aac-a9a1-c3acd933fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "#sns.lineplot(data=data_loss_curves_by_alpha,x='item', y='curve', hue='alpha') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "sns.lineplot(data=data_loss_curves_by_alpha,x='item', y='curve_val', hue='alpha')\n",
    "plt.xlabel(\"Item\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Validation Curves for Different Values of Alpha\")\n",
    "plt.legend(title=\"Alpha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e5344bd0-f546-4fa1-90b2-297c4d3f78f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>PEHE_train</th>\n",
       "      <th>PEHE_val</th>\n",
       "      <th>ATE_train</th>\n",
       "      <th>ATE_val</th>\n",
       "      <th>test_pred_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.891708</td>\n",
       "      <td>2.567605</td>\n",
       "      <td>0.473905</td>\n",
       "      <td>0.264963</td>\n",
       "      <td>1.443585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.981058</td>\n",
       "      <td>2.606629</td>\n",
       "      <td>0.618273</td>\n",
       "      <td>0.442915</td>\n",
       "      <td>1.301263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.212577</td>\n",
       "      <td>2.791753</td>\n",
       "      <td>0.785990</td>\n",
       "      <td>0.622016</td>\n",
       "      <td>1.274963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.066806</td>\n",
       "      <td>2.681851</td>\n",
       "      <td>0.626659</td>\n",
       "      <td>0.425045</td>\n",
       "      <td>1.412304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.091058</td>\n",
       "      <td>2.687055</td>\n",
       "      <td>0.699814</td>\n",
       "      <td>0.520870</td>\n",
       "      <td>1.323906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  learning_rate  weight_decay  PEHE_train  PEHE_val  ATE_train   \n",
       "0    0.0         0.0001       0.00000    2.891708  2.567605   0.473905  \\\n",
       "1    0.0         0.0010       0.00000    2.981058  2.606629   0.618273   \n",
       "2    0.0         0.0100       0.00000    3.212577  2.791753   0.785990   \n",
       "3    0.0         0.0001       0.00001    3.066806  2.681851   0.626659   \n",
       "4    0.0         0.0010       0.00001    3.091058  2.687055   0.699814   \n",
       "\n",
       "    ATE_val  test_pred_loss  \n",
       "0  0.264963        1.443585  \n",
       "1  0.442915        1.301263  \n",
       "2  0.622016        1.274963  \n",
       "3  0.425045        1.412304  \n",
       "4  0.520870        1.323906  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loss_curves.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f85c1960-bbfb-4085-8c66-a0a4f8013ddf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212/524223701.py:15: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(data=data,x='alpha', y='PEHE_train', palette='tab10',label='PEHE Train') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
      "/tmp/ipykernel_212/524223701.py:16: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(data=data,x='alpha', y='PEHE_val', palette='tab10',label='PEHE Val') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
      "/tmp/ipykernel_212/524223701.py:18: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(data=data,x='alpha', y='ATE_train', palette='tab10',label='ATE Train') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
      "/tmp/ipykernel_212/524223701.py:19: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(data=data,x='alpha', y='ATE_val', palette='tab10',label='ATE Val') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
      "/tmp/ipykernel_212/524223701.py:21: UserWarning: Ignoring `palette` because no `hue` variable has been assigned.\n",
      "  sns.lineplot(data=data,x='alpha', y='test_pred_loss', palette='tab10',label='Test Pred Loss') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(data=data_loss_curves_by_alpha,x='item', y='curve', hue='alpha', palette='tab10') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "\n",
    "# plt.xlabel(\"Item\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Loss Curves for Different Values of Alpha\")\n",
    "# plt.legend(title=\"Alpha\")\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data = data_loss_curves#[data_loss_curves_by_alpha['alpha']<101].drop_duplicates(subset = ['alpha','final_loss','PEHE_train','PEHE_val','ATE_train','ATE_val'])\n",
    "sns.lineplot(data=data,x='alpha', y='PEHE_train', palette='tab10',label='PEHE Train') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "sns.lineplot(data=data,x='alpha', y='PEHE_val', palette='tab10',label='PEHE Val') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "\n",
    "sns.lineplot(data=data,x='alpha', y='ATE_train', palette='tab10',label='ATE Train') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "sns.lineplot(data=data,x='alpha', y='ATE_val', palette='tab10',label='ATE Val') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "\n",
    "sns.lineplot(data=data,x='alpha', y='test_pred_loss', palette='tab10',label='Test Pred Loss') # data_loss_curves_by_alpha['alpha'].isin([0,1,5,8])\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Loss for Different Values of Alpha\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "da20e498-e8d9-44c8-94f8-c9cdef56d0f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212/1916191653.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['AGE'] = (X['AGE'] - X['AGE'].mean()) / X['AGE'].std()\n",
      "/tmp/ipykernel_212/1916191653.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['RSBP'] = (X['RSBP'] - X['RSBP'].mean()) / X['RSBP'].std()\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6237208081868276\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([3811, 52]), torch.Size([3811]), torch.Size([3811])\n",
      "starting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.26946133375167847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.25808343291282654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.2878308892250061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.2592775523662567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.26028844714164734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.25396624207496643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.2570561170578003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.2519339323043823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set loss: 0.2520916759967804\n",
      "Test set loss: 0.2517569363117218\n",
      "done training\n",
      "0.7316135269091874 0.17204049229621887 tensor(-0.0640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([35])) that is different to the input size (torch.Size([35, 35])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([953])) that is different to the input size (torch.Size([953, 953])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Run on the other data:\n",
    "IST_data = pd.read_csv('IST_observational.csv')\n",
    "\n",
    "# Convert to 1/0\n",
    "IST_data['DALIVE'] = IST_data['DALIVE'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "IST_data['DASP14'] = IST_data['DASP14'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "IST_data['DLH14'] = IST_data['DLH14'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "IST_data['DMH14'] = IST_data['DMH14'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "IST_data['DHH14'] = IST_data['DHH14'].apply(lambda x: 1 if x=='Y' else 0)\n",
    "\n",
    "# Treatment variable\n",
    "IST_data['treatment_asp'] = (IST_data['DASP14'])>0\n",
    "IST_data['treatment_hep'] = (IST_data['DLH14'] + IST_data['DMH14'] + IST_data['DHH14'])>0\n",
    "IST_data['treatment'] = IST_data['treatment_asp'] | IST_data['treatment_hep']\n",
    "IST_data['treatment'] = IST_data['treatment'].apply(lambda x: 1 if x else 0)\n",
    "IST_data['treatment_asp'] = IST_data['treatment_asp'].apply(lambda x: 1 if x else 0)\n",
    "IST_data['treatment_hep'] = IST_data['treatment_hep'].apply(lambda x: 1 if x else 0)\n",
    "IST_data = IST_data.drop(['DASP14', 'DLH14', 'DMH14','DHH14'], axis=1)\n",
    "\n",
    "# Outcome variable\n",
    "IST_data['event'] = 1 - IST_data['DALIVE']\n",
    "IST_data = IST_data.drop(['DALIVE'], axis=1)\n",
    "\n",
    "IST_data_covariates = IST_data\n",
    "# Data cleaning\n",
    "covariates_to_use = ['HOSPNUM', 'AGE','RCONSC','SEX','RSLEEP','RATRIAL','RCT','RVISINF','RHEP24',\n",
    "                     'RASP3','RSBP','RDEF1','RDEF2','RDEF3','RDEF4','RDEF5','RDEF6','RDEF7','RDEF8',\n",
    "                     'DAYLOCAL','event','treatment']\n",
    "X = IST_data_covariates[covariates_to_use]\n",
    "X['AGE'] = (X['AGE'] - X['AGE'].mean()) / X['AGE'].std()\n",
    "X['RSBP'] = (X['RSBP'] - X['RSBP'].mean()) / X['RSBP'].std()\n",
    "X = pd.get_dummies(X, columns=['RCONSC'], prefix='RCONSC')\n",
    "X = pd.get_dummies(X, columns=['SEX'], prefix='SEX')\n",
    "X = pd.get_dummies(X, columns=['RSLEEP'], prefix='RSLEEP')\n",
    "X = pd.get_dummies(X, columns=['RDEF1'], prefix='RDEF1')\n",
    "X = pd.get_dummies(X, columns=['RDEF2'], prefix='RDEF2')\n",
    "X = pd.get_dummies(X, columns=['RDEF3'], prefix='RDEF3')\n",
    "X = pd.get_dummies(X, columns=['RDEF4'], prefix='RDEF4')\n",
    "X = pd.get_dummies(X, columns=['RDEF5'], prefix='RDEF5')\n",
    "X = pd.get_dummies(X, columns=['RDEF6'], prefix='RDEF6')\n",
    "X = pd.get_dummies(X, columns=['RDEF7'], prefix='RDEF7')\n",
    "X = pd.get_dummies(X, columns=['RDEF8'], prefix='RDEF8')\n",
    "X = pd.get_dummies(X, columns=['RVISINF'], prefix='RVISINF')\n",
    "X = pd.get_dummies(X, columns=['RHEP24'], prefix='RHEP24')\n",
    "X = pd.get_dummies(X, columns=['RASP3'], prefix='RASP3')\n",
    "X = pd.get_dummies(X, columns=['RATRIAL'], prefix='RATRIAL')\n",
    "X = pd.get_dummies(X, columns=['RCT'], prefix='RCT')\n",
    "X = pd.get_dummies(X, columns=['DAYLOCAL'], prefix='DAYLOCAL')\n",
    "covariate_cols = ['HOSPNUM', 'AGE', 'RSBP', 'event', 'RCONSC_D', 'RCONSC_F', 'RCONSC_U',\n",
    "       'SEX_F', 'SEX_M', 'RSLEEP_N', 'RSLEEP_Y', 'RDEF1_C', 'RDEF1_N',\n",
    "       'RDEF1_Y', 'RDEF2_C', 'RDEF2_N', 'RDEF2_Y', 'RDEF3_C', 'RDEF3_N',\n",
    "       'RDEF3_Y', 'RDEF4_C', 'RDEF4_N', 'RDEF4_Y', 'RDEF5_C', 'RDEF5_N',\n",
    "       'RDEF5_Y', 'RDEF6_C', 'RDEF6_N', 'RDEF6_Y', 'RDEF7_C', 'RDEF7_N',\n",
    "       'RDEF7_Y', 'RDEF8_C', 'RDEF8_N', 'RDEF8_Y', 'RVISINF_N', 'RVISINF_Y',\n",
    "       'RHEP24_N', 'RHEP24_Y', 'RASP3_N', 'RASP3_Y', 'RATRIAL_N', 'RATRIAL_Y',\n",
    "       'RCT_N', 'RCT_Y', 'DAYLOCAL_1', 'DAYLOCAL_2', 'DAYLOCAL_3',\n",
    "       'DAYLOCAL_4', 'DAYLOCAL_5', 'DAYLOCAL_6', 'DAYLOCAL_7']\n",
    "\n",
    "tarnet_model = TARNet(df=X,covariate_cols=covariate_cols,treatment_col='treatment',label_col='event', alpha = 0)\n",
    "tarnet_model.fit(epochs=10)\n",
    "output, X, y, t, _ = tarnet_model.predict_test()\n",
    "PEHE, ATE, _, ATE_pred= tarnet_model.compute_PEHE_ATE_metrics(output[2], output[3], t)\n",
    "print(np.sqrt(PEHE), ATE, ATE_pred)\n",
    "# cfr_model = TARNet(df=X,covariate_cols=covariate_cols,treatment_col='treatment',label_col='event', alpha = 1)\n",
    "# cfr_model.fit(epochs=10)\n",
    "# output, X, y, t, _ = cfr_model.predict_test()\n",
    "# PEHE, ATE, _, ATE_pred= cfr_model.compute_PEHE_ATE_metrics(output[2], output[3], t)\n",
    "# print(np.sqrt(PEHE), ATE, ATE_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae2ae5-3f6b-4d9a-a5ca-a6a2c80a067a",
   "metadata": {},
   "source": [
    "### 2.4 NeurIPS Reviewer for a Day: Reviewing & Reproducing Recent Research on ML-Based Causal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a8eb418c-a5ed-4ce9-bf29-ab0891f467d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dragonnet(nn.Module):\n",
    "    def __init__(self, df, covariate_cols=['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10',\n",
    "                                           'X11','X12','X13','X14','X15','X16','X17','X18','X19','X20',\n",
    "                                           'X21','X22','X23','X24','X25'],\n",
    "                                           treatment_col='T', label_col='Y',ite_label='ITE', target_reg=False,\n",
    "                                           lr=0.001, alpha=1, beta = 1, weight_decay=0): \n",
    "        # default alpha and beta from paper directly\n",
    "        # epsilon is learned\n",
    "        super(Dragonnet, self).__init__() \n",
    "        \n",
    "        # Data parameters\n",
    "        self.df = df\n",
    "        self.covariate_cols = covariate_cols\n",
    "        self.treatment_col = treatment_col\n",
    "        self.label_col = label_col\n",
    "        self.ite_label = ite_label\n",
    "        self.lr = lr\n",
    "        self.df, self.test_df = train_test_split(self.df, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Loss hyperparameters\n",
    "        self.target_reg = target_reg\n",
    "        self.alpha = alpha\n",
    "        self.epsilon=nn.Parameter(torch.tensor(1.0))\n",
    "        self.beta = beta\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        self.u = max(1e-6, min(1 - 1e-6, sum(self.df[self.treatment_col].values) / len(self.df[self.treatment_col].values)))\n",
    "        print(f'u: {self.u}')\n",
    "        self.input_dim = len(covariate_cols)\n",
    "        self.output_dim = 1 # for each arm we predict a single value, Y_hat\n",
    "        self.hidden_dim = 200\n",
    "        \n",
    "        # Device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(self.device)\n",
    "        self.to(self.device)\n",
    "\n",
    "        # Layers:\n",
    "        # \"CFR is implemented as a feed-forward\n",
    "        # neural network with 3 fully-connected exponential-linear\n",
    "        # layers for the representation and 3 for the hypothesis. Layer\n",
    "        # sizes were 200 for all layers used for Jobs and 200 and 100\n",
    "        # for the representation and hypothesis used for IHDP.\"\"\n",
    "        \n",
    "        self.representation_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ELU(),\n",
    "        )\n",
    "        self.control_arm = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        )\n",
    "        self.propensity_arm = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "        self.treatment_arm = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.BatchNorm1d(self.hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim)\n",
    "            \n",
    "        )\n",
    "        # The model is trained using Adam's (Kingma & Ba, 2014). \n",
    "        self.optimizer = optim.Adam(\n",
    "                               list(self.representation_layers.parameters())+\n",
    "                               list(self.control_arm.parameters())+\n",
    "                               list(self.propensity_arm.parameters())+\n",
    "                               list(self.treatment_arm.parameters())+\n",
    "                               [self.epsilon], lr=self.lr, weight_decay=self.weight_decay)\n",
    "        # optimizer_representation = optim.Adam(list(self.representation_layers.parameters()), lr=lr)\n",
    "        # optimizer_control = optim.Adam(list(self.control_arm.parameters()), lr=lr)\n",
    "        # optimizer_treatment = optim.Adam(list(self.treatment_arm.parameters()), lr=lr)\n",
    "    \n",
    "        \n",
    "        \n",
    "        # For continuous data we use mean squared loss and for binary data, we'd use log-loss.\n",
    "        self.prediction_loss = nn.MSELoss()\n",
    "        self.propensity_loss = nn.BCELoss()\n",
    "\n",
    "        \n",
    "\n",
    "        # Ignore regularization for now\n",
    "        # self.regularizing_term = self.lambda_ * torch.norm(self.weights, p=2) \n",
    "        \n",
    "        # loss = self.hypothesis_loss + self.regularizing_term + self.IPM_penalty_loss\n",
    "\n",
    "    def forward(self, X, t):\n",
    "\n",
    "        representation = self.representation_layers(X)\n",
    "        control_out = self.control_arm(representation)\n",
    "        treatment_out = self.treatment_arm(representation)\n",
    "        propensity = self.propensity_arm(representation)\n",
    "        y_pred = t * treatment_out + (1 - t) * control_out\n",
    "        \n",
    "        return y_pred, representation, control_out, treatment_out, propensity\n",
    "        \n",
    "    def fit(self, epochs=10, batch_size=64):\n",
    "        # Set to training mode\n",
    "        self.representation_layers.train()\n",
    "        self.treatment_arm.train()\n",
    "        self.control_arm.train()\n",
    "        self.propensity_arm.train()\n",
    "\n",
    "        # Get data\n",
    "        losses = []\n",
    "        print('data:')\n",
    "        \n",
    "        X = torch.tensor(self.df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.df[self.label_col].values, dtype=torch.float32)\n",
    "        t = torch.tensor(self.df[self.treatment_col].values, dtype=torch.float32)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "        \n",
    "        print(f'data shapes: {X.shape}, {y.shape}, {t.shape}')\n",
    "        \n",
    "        print('starting training')\n",
    "        for epoch in range(epochs):\n",
    "            epoch_losses = []\n",
    "            print(epoch)\n",
    "\n",
    "            # Shuffle data\n",
    "            indices = torch.randperm(len(X))\n",
    "            X = X[indices]\n",
    "            y = y[indices]\n",
    "            t = t[indices]\n",
    "\n",
    "            batch_size = 64\n",
    "            # Batch data\n",
    "            for i in range(0, len(X), batch_size):\n",
    "                X_batch = X[i:i + batch_size]\n",
    "                y_batch = y[i:i + batch_size]\n",
    "                t_batch = t[i:i + batch_size]\n",
    "\n",
    "                try:\n",
    "                    # Zero gradients\n",
    "                    self.optimizer.zero_grad()\n",
    "                    # optimizer_representation.zero_grad()\n",
    "                    # optimizer_control.zero_grad()\n",
    "                    # optimizer_treatment.zero_grad()\n",
    "\n",
    "                    y_pred, representation, _, _, propensity = self.forward(X_batch, t_batch)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print('error')\n",
    "\n",
    "                # Calculate weights\n",
    "                weights = (t_batch / (2 * self.u)) + ((1 - t_batch) / (2 * (1 - self.u)))\n",
    "                # print(weights)\n",
    "                \n",
    "                # Calculate prediction loss\n",
    "                loss = torch.mean(weights * self.prediction_loss(y_pred, y_batch))\n",
    "                #print(f'loss_prediction: {loss}')\n",
    "                \n",
    "                # control_condition = (t_batch==0)\n",
    "                \n",
    "                # representation_control = representation[control_condition]\n",
    "                # representation_treatment = representation[~control_condition]\n",
    "\n",
    "                #loss_pred = loss_y0 + loss_y1  # Prediction loss\n",
    "\n",
    "                # Propensity loss\n",
    "                print(propensity.shape)\n",
    "                loss_propensity = self.alpha * self.propensity_loss(propensity.squeeze(), t_batch)\n",
    "                loss += loss_propensity\n",
    "\n",
    "                if self.target_reg:\n",
    "                    target = y_batch - y_pred + self.epsilon*(t_batch/ propensity.squeeze() + (1-t_batch)/(1-propensity.squeeze()))\n",
    "                    loss_target = self.beta * torch.mean(target)\n",
    "                    loss+= loss_target\n",
    "                \n",
    "                #loss_total = loss_pred + loss_ipm\n",
    "                # Backpropagate both prediction loss (through all layers) and IPM loss (through representation layers)\n",
    "                loss.backward()  # Prediction loss affects all layers\n",
    "                \n",
    "                # optimizer_representation.step()  # Update representation layers (affects both prediction and MMD)\n",
    "                # optimizer_control.step()  # Update control prediction head\n",
    "                # optimizer_treatment.step()  # Update treatment prediction head\n",
    "                self.optimizer.step()\n",
    "                epoch_losses.append(loss.item())\n",
    "            \n",
    "            avg_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "            \n",
    "            losses.append(avg_loss)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f'Epoch: {epoch}, Loss: {loss.item()}')\n",
    "        print('done training')\n",
    "        return losses\n",
    "        \n",
    "            \n",
    "    def predict_train(self, use_ite=False):\n",
    "        X = torch.tensor(self.df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.df[self.label_col].values, dtype=torch.float32)\n",
    "        t = torch.tensor(self.df[self.treatment_col].values, dtype=torch.float32)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "        if use_ite:\n",
    "            ite = torch.tensor(self.df[self.ite_label].astype(float).values, dtype=torch.float32)\n",
    "        else:\n",
    "            ite = None\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # No gradients needed for prediction\n",
    "            return self.forward(X,t), X, y, t, ite\n",
    "    \n",
    "    def predict_test(self, use_ite=False):\n",
    "        X = torch.tensor(self.test_df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.test_df[self.label_col].values, dtype=torch.float32)\n",
    "        t = torch.tensor(self.test_df[self.treatment_col].values, dtype=torch.float32)\n",
    "        X = X.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        t = t.to(self.device)\n",
    "        if use_ite:\n",
    "            ite = torch.tensor(self.test_df[self.ite_label].astype(float).values, dtype=torch.float32)\n",
    "        else:\n",
    "            ite = None\n",
    "        self.eval()  # Set model to evaluation mode\n",
    "        with torch.no_grad():  # No gradients needed for prediction\n",
    "            return self.forward(X,t), X, y, t, ite\n",
    "    \n",
    "    # plot the t-sne\n",
    "    def plot_representation_space(self, representation=None, t=None, n_components=2):\n",
    "        \"\"\"Plot the representation space\"\"\"\n",
    "        \n",
    "        if representation is None:\n",
    "            representation = torch.tensor(self.df[self.covariate_cols].astype(float).values, dtype=torch.float32)\n",
    "            t = torch.tensor(self.df[self.treatment_col].values, dtype=torch.float32)\n",
    "        # Index on what is control versus treatment\n",
    "        representation_control = representation[t == 0]\n",
    "        representation_treatment = representation[t == 1]\n",
    "\n",
    "        # Run separate t-SNE on control and treatment representations\n",
    "        tsne_control = TSNE(n_components=n_components, random_state=42)\n",
    "        X_tsne_control = tsne_control.fit_transform(representation_control.detach().numpy())\n",
    "        \n",
    "        tsne_treatment = TSNE(n_components=n_components, random_state=42)\n",
    "        X_tsne_treatment = tsne_treatment.fit_transform(representation_treatment.detach().numpy())\n",
    "\n",
    "        # Plot t-SNE\n",
    "        plt.scatter(X_tsne_control[:, 0], X_tsne_control[:, 1], color='blue', label='Control')\n",
    "        plt.scatter(X_tsne_treatment[:, 0], X_tsne_treatment[:, 1], color='red', label='Treatment')\n",
    "        plt.title(\"t-SNE Visualization\")\n",
    "        plt.xlabel(\"Dimension 1\")\n",
    "        plt.ylabel(\"Dimension 2\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def compute_PEHE_ATE_metrics(self, control_output, treatment_output, t, ite=None):\n",
    "        \"\"\"Compute comparison metrics\"\"\"\n",
    "        ite_pred = treatment_output - control_output \n",
    "        if ite is not None:\n",
    "            ite_true = ite \n",
    "        else:\n",
    "            ite_true = torch.where(t == 1, y, -y)\n",
    "        #print(ite_pred, ite_true)\n",
    "        pehe = torch.mean((ite_pred - ite_true) ** 2)\n",
    "        #print(pehe)\n",
    "    \n",
    "        ate_pred = torch.mean(ite_pred)  \n",
    "        ate_true = torch.mean(ite_true)  \n",
    "        ate_error = torch.abs(ate_pred - ate_true)\n",
    "        \n",
    "        return pehe.item(), ate_error.item(), ite_pred, ate_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8506f2a6-49b7-4618-8563-0ff0b5540214",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 40.99491882324219\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.33403968811035\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 3.3410329818725586\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.63753128051758\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 35.324920654296875\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 3.5291588306427\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 44.85654067993164\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 30.456602096557617\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 3.5334410667419434\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 42.52046203613281\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.190120697021484\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 4.966221809387207\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.50538635253906\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.535511016845703\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 6.159971714019775\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n"
     ]
    }
   ],
   "source": [
    "# dragonnet grid search\n",
    "\n",
    "from itertools import product\n",
    " \n",
    "weight_decay_values = [0, 1e-5, 1e-4, 1e-3, 1e-2] \n",
    "learning_rate_values = [1e-4, 1e-3, 1e-2]  \n",
    "\n",
    "losses = []\n",
    "\n",
    "# Perform grid search\n",
    "for weight_decay, learning_rate in product(weight_decay_values, learning_rate_values):\n",
    "    dragonnet = Dragonnet(df=IHDP_data, lr=learning_rate, weight_decay=weight_decay, target_reg=True)  \n",
    "\n",
    "    # Train model\n",
    "    dragonnet.fit(epochs=10)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    output, X, y, t, ite = dragonnet.predict_test(use_ite=True)\n",
    "    PEHE_val, ATE_val, _, _ = dragonnet.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "\n",
    "    # Evaluate on training set\n",
    "    output, X, y, t, ite = dragonnet.predict_train(use_ite=True)\n",
    "    PEHE_train, ATE_train, _, _ = dragonnet.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "\n",
    "    # print(f\"Alpha: {alpha}, LR: {learning_rate}, WD: {weight_decay}, PEHE: {np.sqrt(PEHE_val)}, ATE: {ATE_val}, test loss {test_loss}\")\n",
    "\n",
    "    losses.append(pd.DataFrame({\n",
    "        'learning_rate': [learning_rate],\n",
    "        'weight_decay': [weight_decay],\n",
    "        'PEHE_train': [PEHE_train],\n",
    "        'PEHE_val': [PEHE_val],\n",
    "        'ATE_train': [ATE_train],\n",
    "        'ATE_val': [ATE_val]\n",
    "    }))\n",
    "\n",
    "\n",
    "data_loss_curves = pd.concat(losses, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "88827f88-8603-402c-b327-5e731619c6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>PEHE_train</th>\n",
       "      <th>PEHE_val</th>\n",
       "      <th>ATE_train</th>\n",
       "      <th>ATE_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.748847</td>\n",
       "      <td>2.553946</td>\n",
       "      <td>0.106567</td>\n",
       "      <td>0.037287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.786715</td>\n",
       "      <td>2.553660</td>\n",
       "      <td>0.295499</td>\n",
       "      <td>0.082283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.735129</td>\n",
       "      <td>2.487037</td>\n",
       "      <td>0.302767</td>\n",
       "      <td>0.150809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.662169</td>\n",
       "      <td>2.612303</td>\n",
       "      <td>0.022047</td>\n",
       "      <td>0.295017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.641895</td>\n",
       "      <td>2.589763</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.321918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.940913</td>\n",
       "      <td>2.584604</td>\n",
       "      <td>0.565357</td>\n",
       "      <td>0.377377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.664600</td>\n",
       "      <td>2.648667</td>\n",
       "      <td>0.064270</td>\n",
       "      <td>0.379113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.678971</td>\n",
       "      <td>2.656550</td>\n",
       "      <td>0.108154</td>\n",
       "      <td>0.389064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.072323</td>\n",
       "      <td>2.690761</td>\n",
       "      <td>0.641393</td>\n",
       "      <td>0.469834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.873941</td>\n",
       "      <td>2.957601</td>\n",
       "      <td>0.464016</td>\n",
       "      <td>0.680925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>15.415280</td>\n",
       "      <td>16.633175</td>\n",
       "      <td>3.574198</td>\n",
       "      <td>3.763518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15.578398</td>\n",
       "      <td>17.149412</td>\n",
       "      <td>3.596171</td>\n",
       "      <td>3.830995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>16.652323</td>\n",
       "      <td>18.129812</td>\n",
       "      <td>3.740446</td>\n",
       "      <td>3.952727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>17.862411</td>\n",
       "      <td>19.329435</td>\n",
       "      <td>3.901103</td>\n",
       "      <td>4.104767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>19.322285</td>\n",
       "      <td>21.013742</td>\n",
       "      <td>4.083274</td>\n",
       "      <td>4.304215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  weight_decay  PEHE_train   PEHE_val  ATE_train   ATE_val\n",
       "14         0.0100       0.01000    2.748847   2.553946   0.106567  0.037287\n",
       "8          0.0100       0.00010    2.786715   2.553660   0.295499  0.082283\n",
       "5          0.0100       0.00001    2.735129   2.487037   0.302767  0.150809\n",
       "7          0.0010       0.00010    2.662169   2.612303   0.022047  0.295017\n",
       "1          0.0010       0.00000    2.641895   2.589763   0.000568  0.321918\n",
       "11         0.0100       0.00100    2.940913   2.584604   0.565357  0.377377\n",
       "4          0.0010       0.00001    2.664600   2.648667   0.064270  0.379113\n",
       "10         0.0010       0.00100    2.678971   2.656550   0.108154  0.389064\n",
       "2          0.0100       0.00000    3.072323   2.690761   0.641393  0.469834\n",
       "13         0.0010       0.01000    2.873941   2.957601   0.464016  0.680925\n",
       "12         0.0001       0.01000   15.415280  16.633175   3.574198  3.763518\n",
       "0          0.0001       0.00000   15.578398  17.149412   3.596171  3.830995\n",
       "9          0.0001       0.00100   16.652323  18.129812   3.740446  3.952727\n",
       "3          0.0001       0.00001   17.862411  19.329435   3.901103  4.104767\n",
       "6          0.0001       0.00010   19.322285  21.013742   4.083274  4.304215"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target_reg\n",
    "data_loss_curves.sort_values(by='ATE_val', ascending=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "aea68138-7ecb-4f91-b5ad-94929b99ac27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>PEHE_train</th>\n",
       "      <th>PEHE_val</th>\n",
       "      <th>ATE_train</th>\n",
       "      <th>ATE_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.691592</td>\n",
       "      <td>2.482581</td>\n",
       "      <td>0.178858</td>\n",
       "      <td>0.037118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.737004</td>\n",
       "      <td>2.476910</td>\n",
       "      <td>0.338932</td>\n",
       "      <td>0.179798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>2.645748</td>\n",
       "      <td>2.507511</td>\n",
       "      <td>0.052837</td>\n",
       "      <td>0.208738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>2.663659</td>\n",
       "      <td>2.544196</td>\n",
       "      <td>0.055027</td>\n",
       "      <td>0.211157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>2.813295</td>\n",
       "      <td>2.546569</td>\n",
       "      <td>0.358686</td>\n",
       "      <td>0.213195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>2.662688</td>\n",
       "      <td>2.549766</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>0.221489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.691850</td>\n",
       "      <td>2.595268</td>\n",
       "      <td>0.016544</td>\n",
       "      <td>0.258100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>3.013364</td>\n",
       "      <td>2.635822</td>\n",
       "      <td>0.613148</td>\n",
       "      <td>0.432428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>3.054376</td>\n",
       "      <td>2.685264</td>\n",
       "      <td>0.665096</td>\n",
       "      <td>0.509448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.344254</td>\n",
       "      <td>2.884808</td>\n",
       "      <td>0.742758</td>\n",
       "      <td>0.546526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>14.805971</td>\n",
       "      <td>15.948372</td>\n",
       "      <td>3.486936</td>\n",
       "      <td>3.669092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>15.077332</td>\n",
       "      <td>16.306612</td>\n",
       "      <td>3.525885</td>\n",
       "      <td>3.715842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>16.385458</td>\n",
       "      <td>17.602499</td>\n",
       "      <td>3.707380</td>\n",
       "      <td>3.888931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>18.472038</td>\n",
       "      <td>19.865328</td>\n",
       "      <td>3.978317</td>\n",
       "      <td>4.170593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>19.521587</td>\n",
       "      <td>20.757887</td>\n",
       "      <td>4.107737</td>\n",
       "      <td>4.276001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    learning_rate  weight_decay  PEHE_train   PEHE_val  ATE_train   ATE_val\n",
       "13         0.0010       0.01000    2.691592   2.482581   0.178858  0.037118\n",
       "11         0.0100       0.00100    2.737004   2.476910   0.338932  0.179798\n",
       "10         0.0010       0.00100    2.645748   2.507511   0.052837  0.208738\n",
       "7          0.0010       0.00010    2.663659   2.544196   0.055027  0.211157\n",
       "14         0.0100       0.01000    2.813295   2.546569   0.358686  0.213195\n",
       "4          0.0010       0.00001    2.662688   2.549766   0.070423  0.221489\n",
       "1          0.0010       0.00000    2.691850   2.595268   0.016544  0.258100\n",
       "5          0.0100       0.00001    3.013364   2.635822   0.613148  0.432428\n",
       "8          0.0100       0.00010    3.054376   2.685264   0.665096  0.509448\n",
       "2          0.0100       0.00000    3.344254   2.884808   0.742758  0.546526\n",
       "12         0.0001       0.01000   14.805971  15.948372   3.486936  3.669092\n",
       "3          0.0001       0.00001   15.077332  16.306612   3.525885  3.715842\n",
       "6          0.0001       0.00010   16.385458  17.602499   3.707380  3.888931\n",
       "9          0.0001       0.00100   18.472038  19.865328   3.978317  4.170593\n",
       "0          0.0001       0.00000   19.521587  20.757887   4.107737  4.276001"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not target reg\n",
    "data_loss_curves.sort_values(by='ATE_val', ascending=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "a3459fc4-e2a0-49ce-9d95-24ac73ce86cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 33.654624938964844\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6174218196930614 0.2679758071899414\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 23.599328994750977\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5802291590458888 0.15849781036376953\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.485633850097656\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5971706557127352 0.03435945510864258\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.412944793701172\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6466692077498708 0.44339942932128906\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.900293350219727\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.601008398454548 0.27762579917907715\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 33.67662048339844\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5995303776090166 0.28893208503723145\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.32426452636719\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6244045046761018 0.35909032821655273\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.33047866821289\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6228772750729243 0.3731198310852051\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.618911743164062\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6079636097771093 0.3222994804382324\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 38.57720947265625\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6292671517345434 0.3406705856323242\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.754098892211914\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.580595669668474 0.14039945602416992\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.49427032470703\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.589358618948491 0.13507461547851562\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.3894157409668\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5726767434889817 0.13425731658935547\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.486663818359375\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5994513763163278 0.21364998817443848\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.542821884155273\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6247191553247593 0.422011137008667\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.039670944213867\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5956299857253327 0.20445537567138672\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 30.107757568359375\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5897248994609685 0.145050048828125\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.2912540435791\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6148041194782907 0.28200459480285645\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.85556411743164\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6085118321537044 0.24070358276367188\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.327674865722656\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6285610793795913 0.29694175720214844\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.793970108032227\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6083107549765885 0.1610429286956787\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.2862548828125\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5899885331945975 0.07353782653808594\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.89826202392578\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.598654735790038 0.12653589248657227\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.186790466308594\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6266722511107052 0.33493494987487793\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.11940002441406\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5900055524141303 0.07986259460449219\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.290283203125\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6243126956253084 0.29235291481018066\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.910879135131836\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6175170415248838 0.35022544860839844\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.94973373413086\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5877306342609963 0.13845539093017578\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.392269134521484\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5938706445844628 0.17930221557617188\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.97879409790039\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6184779376723228 0.29043102264404297\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 37.69749069213867\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.604268017164023 0.24292325973510742\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 33.42753601074219\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5988990035424542 0.29639530181884766\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.09165573120117\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6662264798930404 0.5095350742340088\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 30.235164642333984\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6057892639548141 0.3043954372406006\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.681001663208008\n",
      "1\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6050279295205474 0.12261056900024414\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.335739135742188\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.639482445462623 0.45694518089294434\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 35.35589599609375\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6242201474373197 0.33037662506103516\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.30057144165039\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5905615383596323 0.08682537078857422\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.916587829589844\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5697441780722343 0.02465057373046875\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.117374420166016\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5911227993044506 0.2049391269683838\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.393587112426758\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5842764287679199 0.015158653259277344\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.284852981567383\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6030493556686254 0.26340508460998535\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 24.586669921875\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5829234680259945 0.15619659423828125\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.280899047851562\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.596954266098135 0.1880054473876953\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.79305076599121\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.587581290018559 0.01224374771118164\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.612491607666016\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6089870392660859 0.2252674102783203\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.250009536743164\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6365810873546904 0.4118690490722656\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 24.896835327148438\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5808387311978334 0.11217784881591797\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 33.82717514038086\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6195811373014735 0.27841734886169434\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.64905548095703\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5995633185047742 0.23098397254943848\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.72942543029785\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6320242553385742 0.32074809074401855\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.92757225036621\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6096051986648303 0.2260451316833496\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 22.779685974121094\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5729824161892672 0.05968618392944336\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.624156951904297\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5887103715541855 0.17910361289978027\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.282684326171875\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6090292698134279 0.252885103225708\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.696353912353516\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6130628091558425 0.28173303604125977\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.787527084350586\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5926399104821056 0.2134873867034912\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.826875686645508\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5741362064955948 0.07591819763183594\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.37253189086914\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.591086387044081 0.0703582763671875\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 24.902820587158203\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5727570897010625 0.1056528091430664\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 22.22942352294922\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5795428261694486 0.18284225463867188\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.72996711730957\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5982575346018617 0.1611320972442627\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 41.30600357055664\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6437748780199115 0.44959115982055664\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 33.494808197021484\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5811031680482097 0.029874801635742188\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 33.018638610839844\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.599137270314172 0.24236345291137695\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.25481033325195\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6347678126385452 0.3694572448730469\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.166385650634766\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6282681832348853 0.09319353103637695\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.32076644897461\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6129421958522396 0.3184385299682617\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.42029571533203\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6307495080180159 0.373976469039917\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.276779174804688\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5790268993007086 0.08828306198120117\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.660903930664062\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5762987050359996 0.10529136657714844\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 32.10664749145508\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.614469741599175 0.30992770195007324\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.205692291259766\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5988025237307124 0.10514402389526367\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 35.85493087768555\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5897086271183538 0.23824143409729004\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.332490921020508\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.630753089959169 0.3755319118499756\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.054012298583984\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5774515055655083 0.07378387451171875\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.50569725036621\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6061121632848796 0.3290421962738037\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.221073150634766\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5864251801033795 0.1657707691192627\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.947463989257812\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6285025190053402 0.40434741973876953\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.263452529907227\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5983640413380733 0.17075014114379883\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.71184539794922\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6162389654858242 0.23934268951416016\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.05575180053711\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5779665876895568 0.13140058517456055\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.92743682861328\n",
      "1\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5973932847271233 0.30185508728027344\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.06846809387207\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6166706088434246 0.28130459785461426\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 35.876224517822266\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.67174850413143 0.5115573406219482\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.13318634033203\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.579606522202327 0.1086282730102539\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 26.60041046142578\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6050579352929828 0.3159945011138916\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 34.13821792602539\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6319707133386145 0.33077454566955566\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 27.4157772064209\n",
      "1\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6270832499733228 0.3876621723175049\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.795148849487305\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5950547655563119 0.22084760665893555\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.485843658447266\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5946765525063844 0.22908592224121094\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 31.45623016357422\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5870866042016896 0.09357452392578125\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 30.595579147338867\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5912987801505851 0.21288299560546875\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.851482391357422\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5752225567234774 0.021503448486328125\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 25.069114685058594\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5943498417608897 0.29689788818359375\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.9691104888916\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.5801499471856524 0.06955432891845703\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 30.508132934570312\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6242724036840708 0.36457085609436035\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 28.871448516845703\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.604687800124158 0.25560760498046875\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 33.06924057006836\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6025886783671721 0.2779405117034912\n",
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 29.01963996887207\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "1.6409281132752318 0.19887876510620117\n"
     ]
    }
   ],
   "source": [
    "# Dragonnet \\pm target_reg results\n",
    "losses = []\n",
    "\n",
    "for alpha in range(0,100):\n",
    "    dragon_model = Dragonnet(df=IHDP_data,lr=0.001, weight_decay=0.001,target_reg=True)\n",
    "    loss_curve = dragon_model.fit(epochs=10)\n",
    "    output, X, y, t, ite = dragon_model.predict_test(use_ite=True)\n",
    "    representation = output[1]\n",
    "    #tarnet_model.plot_representation_space(representation, t)\n",
    "    PEHE_val, ATE_val, _, _ = dragon_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "    output, X, y, t, ite = dragon_model.predict_train(use_ite=True)\n",
    "    representation = output[1]\n",
    "    PEHE_train, ATE_train, _, _ = dragon_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "    print(np.sqrt(PEHE_val), ATE_val)\n",
    "    losses.append(pd.DataFrame({'index': [alpha],\n",
    "                    #'item':range(len(loss_curve)),\n",
    "                    #'curve': loss_curve,\n",
    "                    #'final_loss': loss_curve[-1],\n",
    "                    'PEHE_train': [PEHE_train],\n",
    "                    'PEHE_val': [PEHE_val],\n",
    "                    'ATE_train': [ATE_train],\n",
    "                    'ATE_val': [ATE_val]}))\n",
    "data_loss_curves_by_alpha = pd.concat(losses, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "53faa7fd-db82-448d-bd91-c5991b9651d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEHE train:\n",
      "2.6805123901367187 0.0035316549048086945\n",
      "PEHE val:\n",
      "2.5747467422485353 0.006824631164962641\n",
      "ATE train:\n",
      "0.10230266809463501 0.006469843239704169\n",
      "ATE val:\n",
      "0.22802986860275268 0.01191052115048386\n"
     ]
    }
   ],
   "source": [
    "print('PEHE train:')\n",
    "print(data_loss_curves_by_alpha['PEHE_train'].mean(), data_loss_curves_by_alpha['PEHE_train'].std()/10)\n",
    "\n",
    "print('PEHE val:')\n",
    "print(data_loss_curves_by_alpha['PEHE_val'].mean(), data_loss_curves_by_alpha['PEHE_val'].std()/10)\n",
    "\n",
    "\n",
    "print('ATE train:')\n",
    "print(data_loss_curves_by_alpha['ATE_train'].mean(), data_loss_curves_by_alpha['ATE_train'].std()/10)\n",
    "\n",
    "print('ATE val:')\n",
    "print(data_loss_curves_by_alpha['ATE_val'].mean(), data_loss_curves_by_alpha['ATE_val'].std()/10)\n",
    "\n",
    "# # Dragonnet\n",
    "# PEHE train:\n",
    "# 2.6851692366600037 0.004922063091041307\n",
    "# PEHE val:\n",
    "# 2.526539189815521 0.005687062305165922\n",
    "# ATE train:\n",
    "# 0.1289555287361145 0.008504041445361255\n",
    "# ATE val:\n",
    "# 0.15762019872665406 0.009567426961130061\n",
    "\n",
    "# targeted reg  lr=0.01, weight_decay=0.01\n",
    "# PEHE train:\n",
    "# 3.348403968811035 0.041312828859681724\n",
    "# PEHE val:\n",
    "# 2.9457097482681274 0.03138265938218834\n",
    "# ATE train:\n",
    "# 0.6878573417663574 0.026678254831769627\n",
    "# ATE val:\n",
    "# 0.5086178970336914 0.02602220537772217\n",
    "\n",
    "# PEHE train: lr=0.001, weight_decay=0.01\n",
    "# 2.6921644949913026 0.004846111401487302\n",
    "# PEHE val:\n",
    "# 2.612568447589874 0.009969611789811216\n",
    "# ATE train:\n",
    "# 0.10850232124328613 0.007548813325763119\n",
    "# ATE val:\n",
    "# 0.2810556554794312 0.013563754069221987\n",
    "\n",
    "# PEHE train: lr=0.001, weight_decay=0.001,target_reg=True)\n",
    "# 2.6805123901367187 0.0035316549048086945\n",
    "# PEHE val:\n",
    "# 2.5747467422485353 0.006824631164962641\n",
    "# ATE train:\n",
    "# 0.10230266809463501 0.006469843239704169\n",
    "# ATE val:\n",
    "# 0.22802986860275268 0.01191052115048386\n",
    "# Dragonnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "02ad8083-4491-463f-9656-b3839f72d9cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u: 0.6884422110552764\n",
      "cpu\n",
      "data:\n",
      "data shapes: torch.Size([597, 25]), torch.Size([597]), torch.Size([597])\n",
      "starting training\n",
      "0\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "Epoch: 0, Loss: 21.587852478027344\n",
      "1\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "2\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 21])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "3\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "4\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "5\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "6\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "7\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "8\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "9\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([21, 1])\n",
      "done training\n",
      "Training:\n",
      "1.6586865909878221 0.34525489807128906\n",
      "Test:\n",
      "1.56905850116499 0.06744194030761719\n"
     ]
    }
   ],
   "source": [
    "dragon_model = Dragonnet(df=IHDP_data,lr=0.0001, weight_decay=0.00001,target_reg=False)\n",
    "dragon_model.fit(epochs=10)\n",
    "output, X, y, t, ite = dragon_model.predict_train(use_ite=True)\n",
    "PEHE, ATE, _, _ = dragon_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "print('Training:')\n",
    "print(np.sqrt(PEHE), ATE)\n",
    "output, X, y, t, ite = dragon_model.predict_test(use_ite=True)\n",
    "PEHE, ATE, _, _ = dragon_model.compute_PEHE_ATE_metrics(output[2], output[3], t, ite)\n",
    "print('Test:')\n",
    "print(np.sqrt(PEHE), ATE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
